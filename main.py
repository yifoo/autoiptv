#!/usr/bin/env python3
"""
ç”µè§†ç›´æ’­æºæ”¶é›†è„šæœ¬ - å¸¦é»‘ç™½åå•çš„IPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ
ä¸»ç¨‹åºå…¥å£
"""

import os
import sys
import time
import concurrent.futures
from pathlib import Path

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
from config.config_loader import load_config, load_sources_from_file
from utils.black_white_list import load_whitelist, load_blacklist, save_to_blacklist, is_in_whitelist, get_beijing_time
from utils.speed_test import test_url_speed, is_ipv6_url
from utils.m3u_processor import fetch_m3u, parse_channels, merge_channels
from utils.channel_cleaner import clean_channel_name
from config.categories import categorize_channel, get_channel_sort_key
from outputs.m3u_generator import generate_multi_source_m3u
from outputs.json_generator import generate_json_file

def print_header():
    """æ‰“å°è„šæœ¬å¤´éƒ¨ä¿¡æ¯"""
    print("=" * 70)
    print("ç”µè§†ç›´æ’­æºæ”¶é›†è„šæœ¬ v10.0 - æ–°å¢å¹¿æ’­å’ŒMVåˆ†ç±»ç‰ˆ")
    print("åŠŸèƒ½ï¼šæ”¯æŒé…ç½®é»‘åå•/ç™½åå•/æµ‹é€Ÿå¼€å…³ï¼Œç™½åå•è‡ªåŠ¨åŠ å…¥ï¼ŒIPv6ä¼˜å…ˆï¼Œæ™ºèƒ½æµ‹é€Ÿè¿‡æ»¤")
    print("ç‰¹ç‚¹ï¼šæ–°å¢è°ƒé¢‘å¹¿æ’­å’Œæ­Œæ›²MVåˆ†ç±»ï¼Œæ›´å®Œå–„çš„é¢‘é“åˆ†ç±»ç³»ç»Ÿ")
    print("æ’­æ”¾å™¨ï¼šæ”¯æŒPotPlayerã€VLCã€TiviMateã€Kodiç­‰å¤šæºåˆ‡æ¢åŠŸèƒ½")
    print("=" * 70)

def test_urls_with_progress(urls, blacklist, whitelist_data, config):
    """å¹¶å‘æµ‹è¯•URLé€Ÿåº¦ï¼Œæ˜¾ç¤ºè¿›åº¦ï¼Œè€ƒè™‘ç™½åå•"""
    if not config['ENABLE_SPEED_TEST']:
        print("âš¡ æµ‹é€ŸåŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡é€Ÿåº¦æµ‹è¯•")
        return {}, set(), {}
    
    results = {}
    slow_urls = set()
    detailed_results = {}
    
    print(f"âš¡ å¼€å§‹æ™ºèƒ½é€Ÿåº¦æµ‹è¯•")
    print(f"ğŸ“Š é…ç½®: è¿æ¥è¶…æ—¶={config['CONNECT_TIMEOUT']}s, æµæµ‹è¯•è¶…æ—¶={config['STREAM_TIMEOUT']}s")
    print(f"ğŸ“Š éœ€è¦æµ‹è¯• {len(urls)} ä¸ªURL")
    
    # è¿‡æ»¤æ‰å·²ç»åœ¨é»‘åå•ä¸­çš„URLï¼ˆå¦‚æœé»‘åå•å¯ç”¨ä¸”ç™½åå•ä¸è¦†ç›–ï¼‰
    urls_to_test = []
    skipped_blacklisted = 0
    whitelist_override_count = 0
    
    for url in urls:
        # æ£€æŸ¥æ˜¯å¦åœ¨ç™½åå•ä¸­
        is_whitelisted = config['ENABLE_WHITELIST'] and is_in_whitelist(url, whitelist_data, config)
        
        # æ£€æŸ¥æ˜¯å¦åœ¨é»‘åå•ä¸­
        is_blacklisted = config['ENABLE_BLACKLIST'] and (url in blacklist)
        
        if is_whitelisted and config['WHITELIST_OVERRIDE_BLACKLIST']:
            # ç™½åå•è¦†ç›–é»‘åå•ï¼Œå³ä½¿URLåœ¨é»‘åå•ä¸­ä¹Ÿæµ‹è¯•
            urls_to_test.append(url)
            if is_blacklisted:
                whitelist_override_count += 1
        elif not is_blacklisted:
            # URLä¸åœ¨é»‘åå•ä¸­ï¼Œæ­£å¸¸æµ‹è¯•
            urls_to_test.append(url)
        else:
            # URLåœ¨é»‘åå•ä¸­ä¸”ä¸åœ¨ç™½åå•ä¸­ï¼Œè·³è¿‡
            skipped_blacklisted += 1
    
    print(f"ğŸ” å®é™…éœ€è¦æµ‹è¯• {len(urls_to_test)} ä¸ªURL")
    if skipped_blacklisted > 0:
        print(f"   è·³è¿‡äº† {skipped_blacklisted} ä¸ªé»‘åå•ä¸­çš„URL")
    if whitelist_override_count > 0:
        print(f"   ç™½åå•è¦†ç›–äº† {whitelist_override_count} ä¸ªé»‘åå•URL")
    
    if not urls_to_test:
        print("âœ… æ‰€æœ‰URLéƒ½åœ¨é»‘åå•ä¸­ï¼Œè·³è¿‡é€Ÿåº¦æµ‹è¯•")
        return results, slow_urls, detailed_results
    
    # æŒ‰URLç±»å‹åˆ†ç»„ï¼ˆM3U8ä¼˜å…ˆæµ‹è¯•ï¼‰
    m3u8_urls = []
    other_urls = []
    whitelist_m3u8 = []
    whitelist_other = []
    
    for url in urls_to_test:
        is_whitelisted = config['ENABLE_WHITELIST'] and is_in_whitelist(url, whitelist_data, config)
        
        if '.m3u8' in url.lower():
            if is_whitelisted:
                whitelist_m3u8.append(url)
            else:
                m3u8_urls.append(url)
        else:
            if is_whitelisted:
                whitelist_other.append(url)
            else:
                other_urls.append(url)
    
    print(f"  M3U8æµåª’ä½“æº: {len(m3u8_urls)} ä¸ªæ™®é€š, {len(whitelist_m3u8)} ä¸ªç™½åå•")
    print(f"  å…¶ä»–ç±»å‹æº: {len(other_urls)} ä¸ªæ™®é€š, {len(whitelist_other)} ä¸ªç™½åå•")
    
    # åˆå¹¶æµ‹è¯•åˆ—è¡¨ï¼šç™½åå•ä¼˜å…ˆ
    test_order = whitelist_m3u8 + m3u8_urls + whitelist_other + other_urls
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æµ‹è¯•
    with concurrent.futures.ThreadPoolExecutor(max_workers=config['MAX_WORKERS']) as executor:
        # æäº¤æ‰€æœ‰æµ‹è¯•ä»»åŠ¡
        future_to_url = {executor.submit(test_url_speed, url, config): url for url in test_order}
        
        # è¿›åº¦ç»Ÿè®¡
        completed = 0
        total = len(test_order)
        start_time = time.time()
        
        for future in concurrent.futures.as_completed(future_to_url):
            completed += 1
            url = future_to_url[future]
            
            try:
                result = future.result()
                detailed_results[url] = result
                
                if result['success']:
                    score = result['score']
                    results[url] = score
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨ç™½åå•ä¸­
                    is_whitelisted = config['ENABLE_WHITELIST'] and is_in_whitelist(url, whitelist_data, config)
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæ…¢é€Ÿæºï¼ˆç™½åå•å¯å¿½ç•¥ï¼‰
                    if score < config['MIN_SPEED_SCORE'] and not (is_whitelisted and config['WHITELIST_IGNORE_SPEED_TEST']):
                        slow_urls.add(url)
                        speed_desc = f"è¯„åˆ†ä½({score:.2f})"
                    else:
                        speed_desc = f"è¯„åˆ†{score:.2f}"
                    
                    # æ ‡è®°ç™½åå•
                    if is_whitelisted:
                        speed_desc = f"âœ…ç™½åå• {speed_desc}"
                    
                    # æ¯æµ‹è¯•5ä¸ªURLæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                    if completed % 5 == 0 or completed == total:
                        elapsed = time.time() - start_time
                        avg_time = elapsed / completed if completed > 0 else 0
                        remaining = (total - completed) * avg_time if avg_time > 0 else 0
                        
                        print(f"  â³ {completed}/{total} ({completed/total*100:.1f}%) "
                              f"ç”¨æ—¶:{elapsed:.1f}s å‰©ä½™:{remaining:.0f}s "
                              f"æœ€æ–°:{speed_desc} {url[:50]}...")
                else:
                    # å¤±è´¥æƒ…å†µï¼šç™½åå•å¯å¿½ç•¥å¤±è´¥
                    is_whitelisted = config['ENABLE_WHITELIST'] and is_in_whitelist(url, whitelist_data, config)
                    if not (is_whitelisted and config['WHITELIST_IGNORE_SPEED_TEST']):
                        slow_urls.add(url)
                    
                    error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                    if is_whitelisted:
                        print(f"  âš ï¸  ç™½åå•å¤±è´¥: {url[:60]}... - {error_msg}")
                    else:
                        print(f"  âŒ å¤±è´¥: {url[:60]}... - {error_msg}")
                    
            except Exception as e:
                url = future_to_url[future]
                # ç™½åå•å¯å¿½ç•¥å¼‚å¸¸
                is_whitelisted = config['ENABLE_WHITELIST'] and is_in_whitelist(url, whitelist_data, config)
                if not (is_whitelisted and config['WHITELIST_IGNORE_SPEED_TEST']):
                    slow_urls.add(url)
                
                detailed_results[url] = {
                    'success': False,
                    'error': f"æµ‹è¯•å¼‚å¸¸: {str(e)}",
                    'score': 0.0
                }
                
                if is_whitelisted:
                    print(f"  âš ï¸  ç™½åå•æµ‹è¯•å¼‚å¸¸: {url[:60]}... - {str(e)[:50]}")
                else:
                    print(f"  âš ï¸  å¼‚å¸¸: {url[:60]}... - {str(e)[:50]}")
    
    # ç»Ÿè®¡ç»“æœ
    fast_urls = len(results)
    print(f"\nâœ… é€Ÿåº¦æµ‹è¯•å®Œæˆ")
    print(f"  å¿«é€Ÿæº: {fast_urls} ä¸ª (è¯„åˆ†â‰¥{config['MIN_SPEED_SCORE']})")
    print(f"  æ…¢é€Ÿæº: {len(slow_urls)} ä¸ª (è¯„åˆ†<{config['MIN_SPEED_SCORE']}æˆ–å¤±è´¥)")
    
    # æ˜¾ç¤ºè¯„åˆ†åˆ†å¸ƒ
    if results:
        scores = list(results.values())
        avg_score = sum(scores) / len(scores) if scores else 0
        max_score = max(scores) if scores else 0
        min_score = min(scores) if scores else 0
        
        print(f"  è¯„åˆ†ç»Ÿè®¡: å¹³å‡{avg_score:.2f}, æœ€é«˜{max_score:.2f}, æœ€ä½{min_score:.2f}")
        
        # è¯„åˆ†åˆ†æ®µç»Ÿè®¡
        score_ranges = {
            "ä¼˜ç§€(0.9-1.0)": sum(1 for s in scores if s >= 0.9),
            "è‰¯å¥½(0.7-0.9)": sum(1 for s in scores if 0.7 <= s < 0.9),
            "ä¸€èˆ¬(0.5-0.7)": sum(1 for s in scores if 0.5 <= s < 0.7),
            "è¾ƒå·®(0.0-0.5)": sum(1 for s in scores if s < 0.5)
        }
        
        print(f"  è¯„åˆ†åˆ†å¸ƒ:")
        for desc, count in score_ranges.items():
            if count > 0:
                percentage = count / len(scores) * 100
                print(f"    {desc}: {count}ä¸ª ({percentage:.1f}%)")
    
    return results, slow_urls, detailed_results

def add_whitelist_channels(whitelist_data, config):
    """æ·»åŠ ç™½åå•é¢‘é“åˆ°é¢‘é“åˆ—è¡¨"""
    if not config['ENABLE_WHITELIST'] or not config['WHITELIST_AUTO_ADD']:
        return []
    
    whitelist_channels = []
    
    if 'channels' in whitelist_data and whitelist_data['channels']:
        print(f"\nğŸ“‹ è‡ªåŠ¨æ·»åŠ ç™½åå•é¢‘é“...")
        for channel_info in whitelist_data['channels']:
            url = channel_info['url']
            name = channel_info['name']
            group = channel_info['group']
            logo = channel_info['logo']
            quality = channel_info['quality']
            is_whitelist = channel_info.get('is_whitelist', True)
            
            # æ¸…ç†é¢‘é“åç§°
            clean_name = clean_channel_name(name)
            
            # åˆ›å»ºé¢‘é“å¯¹è±¡
            channel = {
                'original_name': name,
                'clean_name': clean_name,
                'url': url,
                'group': group,
                'logo': logo,
                'quality': quality,
                'source': 'whitelist',
                'extinf_line': f'#EXTINF:-1 tvg-name="{clean_name}" group-title="{group}" tvg-logo="{logo}",{clean_name}',
                'is_whitelist': is_whitelist
            }
            
            whitelist_channels.append(channel)
            print(f"  âœ… æ·»åŠ ç™½åå•é¢‘é“: {clean_name} - {url[:50]}...")
    
    return whitelist_channels

def fetch_whitelist_streams(whitelist_data, config):
    """è·å–ç™½åå•ä¸­çš„M3Uæ–‡ä»¶æµ"""
    if not config['ENABLE_WHITELIST']:
        return []
    
    whitelist_channels = []
    
    # æ£€æŸ¥ç™½åå•ä¸­çš„M3Uæ–‡ä»¶URL
    print(f"\nğŸ“¡ æ£€æŸ¥ç™½åå•ä¸­çš„M3Uæ–‡ä»¶...")
    for url in whitelist_data.get('urls', []):
        # æ£€æŸ¥æ˜¯å¦æ˜¯M3Uæ–‡ä»¶
        if any(ext in url.lower() for ext in ['.m3u', '.m3u8']):
            print(f"  å¤„ç†ç™½åå•M3Uæ–‡ä»¶: {url[:60]}...")
            try:
                content = fetch_m3u(url)
                if content:
                    channels = parse_channels(content, f"whitelist:{url}")
                    # æ ‡è®°è¿™äº›é¢‘é“ä¸ºç™½åå•é¢‘é“
                    for channel in channels:
                        channel['is_whitelist'] = True
                    whitelist_channels.extend(channels)
                    print(f"    âœ… è§£æåˆ° {len(channels)} ä¸ªé¢‘é“")
                else:
                    print(f"    âŒ æ— æ³•è·å–å†…å®¹")
            except Exception as e:
                print(f"    âŒ å¤„ç†å¤±è´¥: {e}")
    
    return whitelist_channels

def main():
    """ä¸»å‡½æ•°"""
    print_header()
    
    # 1. åŠ è½½é…ç½®å’Œæºåˆ—è¡¨
    config = load_config()
    sources = load_sources_from_file()
    
    if not sources:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®æºï¼Œè¯·æ£€æŸ¥sources.txtæ–‡ä»¶")
        return
    
    # 2. åŠ è½½é»‘åå•å’Œç™½åå•
    print("ğŸ“‹ åŠ è½½é»‘åå•å’Œç™½åå•...")
    blacklist = load_blacklist(config)
    whitelist_data = load_whitelist(config)
    
    # æ˜¾ç¤ºä¼˜å…ˆçº§è¯´æ˜
    if config['ENABLE_WHITELIST'] and config['ENABLE_BLACKLIST']:
        if config['WHITELIST_OVERRIDE_BLACKLIST']:
            print("âš ï¸  ä¼˜å…ˆçº§: ç™½åå• > é»‘åå•ï¼ˆç™½åå•URLå°†ä¸ä¼šè¢«é»‘åå•è¿‡æ»¤ï¼‰")
        else:
            print("âš ï¸  ä¼˜å…ˆçº§: é»‘åå• > ç™½åå•ï¼ˆé»‘åå•ä¸­çš„URLå³ä½¿ä¹Ÿåœ¨ç™½åå•ä¸­ä¹Ÿä¼šè¢«è¿‡æ»¤ï¼‰")
    
    # ä¸»æ”¶é›†è¿‡ç¨‹
    print("ğŸš€ å¼€å§‹é‡‡é›†ç”µè§†ç›´æ’­æº...")
    
    all_channels = []
    success_sources = 0
    failed_sources = []
    
    # 3. æ”¶é›†æ‰€æœ‰é¢‘é“çš„åŸå§‹æ•°æ®
    print("\nğŸ“¡ å¼€å§‹æ”¶é›†é¢‘é“æ•°æ®...")
    for idx, source_url in enumerate(sources, 1):
        print(f"\n[{idx}/{len(sources)}] å¤„ç†: {source_url}")
        
        content = fetch_m3u(source_url)
        if not content:
            failed_sources.append(source_url)
            print("   âŒ æ— æ³•è·å–å†…å®¹ï¼Œè·³è¿‡")
            continue
        
        channels = parse_channels(content, source_url)
        
        # ç»Ÿè®¡é¢‘é“åç§°å˜åŒ–
        changed_count = 0
        for channel in channels:
            if channel['original_name'] != channel['clean_name']:
                changed_count += 1
        
        print(f"   âœ… è§£æåˆ° {len(channels)} ä¸ªé¢‘é“ ({changed_count}ä¸ªå·²ç²¾ç®€)")
        
        if changed_count > 0 and len(channels) <= 10:
            for channel in channels[:5]:
                if channel['original_name'] != channel['clean_name']:
                    print(f"      '{channel['original_name']}' -> '{channel['clean_name']}'")
        
        all_channels.extend(channels)
        success_sources += 1
        
        # é¿å…è¯·æ±‚è¿‡å¿«
        if idx < len(sources):
            time.sleep(1)
    
    # 4. æ·»åŠ ç™½åå•é¢‘é“
    if config['ENABLE_WHITELIST'] and config['WHITELIST_AUTO_ADD']:
        # æ·»åŠ ç™½åå•å®šä¹‰çš„é¢‘é“
        whitelist_defined_channels = add_whitelist_channels(whitelist_data, config)
        if whitelist_defined_channels:
            all_channels.extend(whitelist_defined_channels)
            print(f"âœ… æ·»åŠ äº† {len(whitelist_defined_channels)} ä¸ªç™½åå•å®šä¹‰çš„é¢‘é“")
        
        # è·å–ç™½åå•ä¸­çš„M3Uæ–‡ä»¶æµ
        whitelist_stream_channels = fetch_whitelist_streams(whitelist_data, config)
        if whitelist_stream_channels:
            all_channels.extend(whitelist_stream_channels)
            print(f"âœ… æ·»åŠ äº† {len(whitelist_stream_channels)} ä¸ªç™½åå•M3Uæ–‡ä»¶ä¸­çš„é¢‘é“")
    
    # 5. æå–æ‰€æœ‰å”¯ä¸€çš„URLè¿›è¡Œé€Ÿåº¦æµ‹è¯•
    print("\nğŸ“Š æå–æ‰€æœ‰å”¯ä¸€URL...")
    all_urls = set()
    for channel in all_channels:
        all_urls.add(channel['url'])
    
    print(f"   å‘ç° {len(all_urls)} ä¸ªå”¯ä¸€URL")
    
    # 6. è¿›è¡Œæ™ºèƒ½é€Ÿåº¦æµ‹è¯•
    print("\nâš¡ å¼€å§‹æ™ºèƒ½é€Ÿåº¦æµ‹è¯•...")
    speed_test_results, slow_urls, detailed_results = test_urls_with_progress(
        all_urls, blacklist, whitelist_data, config
    )
    
    # 7. ä¿å­˜å¤±è´¥å’Œä½è´¨é‡URLåˆ°é»‘åå•
    if slow_urls and config['ENABLE_BLACKLIST'] and config['ENABLE_SPEED_TEST']:
        # åˆ†æå¤±è´¥åŸå› 
        error_types = {}
        for url in slow_urls:
            result = detailed_results.get(url, {})
            error = result.get('error', 'è¯„åˆ†è¿‡ä½')
            error_types[error] = error_types.get(error, 0) + 1
        
        print(f"\nğŸ“Š å¤±è´¥åŸå› åˆ†æ:")
        for error, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
            print(f"  {error}: {count}ä¸ª")
        
        reason = "è¯„åˆ†è¿‡ä½æˆ–è¿æ¥å¤±è´¥"
        if error_types:
            main_error = max(error_types.items(), key=lambda x: x[1])[0]
            reason = f"ä¸»è¦å¤±è´¥åŸå› : {main_error}"
        
        print(f"\nğŸ“ å‘ç° {len(slow_urls)} ä¸ªä½è´¨é‡æºï¼Œä¿å­˜åˆ°é»‘åå•...")
        save_to_blacklist(slow_urls, config, reason)
    elif slow_urls:
        print(f"\nâš ï¸  å‘ç° {len(slow_urls)} ä¸ªä½è´¨é‡æºï¼Œä½†é»‘åå•æˆ–æµ‹é€ŸåŠŸèƒ½å·²ç¦ç”¨ï¼Œä¸ä¿å­˜")
    
    # 8. è¿‡æ»¤æ‰é»‘åå•ä¸­çš„é¢‘é“
    print("\nğŸš« è¿‡æ»¤é»‘åå•ä¸­çš„é¢‘é“...")
    filtered_channels = []
    blacklisted_count = 0
    whitelisted_count = 0
    
    for channel in all_channels:
        url = channel['url']
        is_whitelisted = config['ENABLE_WHITELIST'] and is_in_whitelist(url, whitelist_data, config)
        is_blacklisted = config['ENABLE_BLACKLIST'] and (url in blacklist or url in slow_urls)
        
        # åº”ç”¨ç™½åå•è§„åˆ™
        if is_whitelisted and config['WHITELIST_OVERRIDE_BLACKLIST']:
            # ç™½åå•è¦†ç›–é»‘åå•ï¼Œå³ä½¿URLåœ¨é»‘åå•ä¸­ä¹Ÿä¿ç•™
            filtered_channels.append(channel)
            whitelisted_count += 1
            if is_blacklisted:
                print(f"   âœ… ç™½åå•è¦†ç›–: {channel['clean_name']} - é»‘åå•URLè¢«ä¿ç•™")
        elif not is_blacklisted:
            # ä¸åœ¨é»‘åå•ä¸­ï¼Œæ­£å¸¸ä¿ç•™
            filtered_channels.append(channel)
        else:
            # åœ¨é»‘åå•ä¸­ä¸”ä¸åœ¨ç™½åå•ä¸­ï¼Œè¿‡æ»¤æ‰
            blacklisted_count += 1
    
    print(f"   åŸå§‹é¢‘é“æ•°: {len(all_channels)}")
    print(f"   è¿‡æ»¤åé¢‘é“æ•°: {len(filtered_channels)}")
    print(f"   é»‘åå•è¿‡æ»¤æ•°: {blacklisted_count}")
    if whitelisted_count > 0:
        print(f"   ç™½åå•ä¿ç•™æ•°: {whitelisted_count}")
    
    if len(filtered_channels) == 0:
        print("\nâŒ æ‰€æœ‰é¢‘é“éƒ½è¢«é»‘åå•è¿‡æ»¤ï¼Œé€€å‡º")
        return
    
    # 9. åˆå¹¶åŒåç”µè§†å°
    print("\nğŸ”„ æ­£åœ¨åˆå¹¶åŒåç”µè§†å°...")
    merged_channels = merge_channels(filtered_channels, detailed_results)
    print(f"   åˆå¹¶å: {len(merged_channels)} ä¸ªå”¯ä¸€ç”µè§†å°")
    
    # 10. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    multi_source_count = sum(1 for c in merged_channels.values() if len(c['sources']) > 1)
    single_source_count = len(merged_channels) - multi_source_count
    ipv6_channel_count = sum(1 for c in merged_channels.values() if any(s.get('is_ipv6', False) for s in c['sources']))
    whitelist_channel_count = sum(1 for c in merged_channels.values() if any(s.get('is_whitelist', False) for s in c['sources']))
    high_quality_channel_count = sum(1 for c in merged_channels.values() if any(s.get('speed_score', 0) >= 0.7 for s in c['sources']))
    
    print(f"   å¤šæºç”µè§†å°: {multi_source_count} ä¸ª")
    print(f"   å•æºç”µè§†å°: {single_source_count} ä¸ª")
    print(f"   å«IPv6æºç”µè§†å°: {ipv6_channel_count} ä¸ª")
    print(f"   å«ç™½åå•æºç”µè§†å°: {whitelist_channel_count} ä¸ª")
    if config['ENABLE_SPEED_TEST']:
        print(f"   å«é«˜è´¨é‡æºç”µè§†å°: {high_quality_channel_count} ä¸ª")
    
    # 11. æŒ‰åˆ†ç±»ç»„ç»‡é¢‘é“
    categories = {}
    for channel in merged_channels.values():
        category = channel['category']
        if category not in categories:
            categories[category] = []
        categories[category].append(channel)
    
    # ç¡®å®šåˆ†ç±»é¡ºåº
    fixed_categories = ["å¤®è§†", "å«è§†", "æ™¯åŒºé¢‘é“", "å°‘å„¿å°", "ç»¼è‰ºå°", 
                       "æ¸¯æ¾³å°", "ä½“è‚²å°", "å½±è§†å°", "è°ƒé¢‘å¹¿æ’­", "æ­Œæ›²MV", "å…¶ä»–å°"]
    
    province_categories = []
    other_categories = []
    for category in categories.keys():
        if category in fixed_categories:
            continue
        elif any(province in category for province in [
            "åŒ—äº¬å¸‚", "å¤©æ´¥å¸‚", "æ²³åŒ—çœ", "å±±è¥¿çœ", "å†…è’™å¤è‡ªæ²»åŒº",
            "è¾½å®çœ", "å‰æ—çœ", "é»‘é¾™æ±Ÿçœ", "ä¸Šæµ·å¸‚", "æ±Ÿè‹çœ",
            "æµ™æ±Ÿçœ", "å®‰å¾½çœ", "ç¦å»ºçœ", "æ±Ÿè¥¿çœ", "å±±ä¸œçœ",
            "æ²³å—çœ", "æ¹–åŒ—çœ", "æ¹–å—çœ", "å¹¿ä¸œçœ", "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
            "æµ·å—çœ", "é‡åº†å¸‚", "å››å·çœ", "è´µå·çœ", "äº‘å—çœ",
            "è¥¿è—è‡ªæ²»åŒº", "é™•è¥¿çœ", "ç”˜è‚ƒçœ", "é’æµ·çœ", "å®å¤å›æ—è‡ªæ²»åŒº",
            "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº", "å°æ¹¾çœ", "é¦™æ¸¯", "æ¾³é—¨"
        ]):
            province_categories.append(category)
        else:
            other_categories.append(category)
    
    province_categories.sort()
    final_category_order = fixed_categories + province_categories + other_categories
    
    # ç¡®ä¿æ¯ä¸ªåˆ†ç±»éƒ½å­˜åœ¨ï¼ˆå³ä½¿ä¸ºç©ºï¼‰
    for category in final_category_order:
        if category not in categories:
            categories[category] = []
    
    # 12. ç”Ÿæˆæ–‡ä»¶
    timestamp = get_beijing_time()
    print(f"\nğŸ“… å½“å‰åŒ—äº¬æ—¶é—´: {timestamp}")
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    Path("categories").mkdir(exist_ok=True)
    Path("merged").mkdir(exist_ok=True)
    
    # 13. ç”Ÿæˆå¤šæºåˆå¹¶ç‰ˆM3U
    print("\nğŸ“„ ç”Ÿæˆ live_sources.m3uï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ - PotPlayer/VLCæ ¼å¼ï¼‰...")
    generate_multi_source_m3u(
        merged_channels, categories, final_category_order, 
        timestamp, "live_sources.m3u", config,
        sources, success_sources, failed_sources, mode="multi"
    )
    
    # 14. ç”Ÿæˆå¤šæºåˆ†ç¦»ç‰ˆM3U
    print("\nğŸ“„ ç”Ÿæˆ merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3uï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆ†ç¦»ç‰ˆ - TiviMate/Kodiæ ¼å¼ï¼‰...")
    generate_multi_source_m3u(
        merged_channels, categories, final_category_order,
        timestamp, "merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3u", config,
        sources, success_sources, failed_sources, mode="separate"
    )
    
    # 15. ç”Ÿæˆç²¾ç®€ç‰ˆM3U
    print("\nğŸ“„ ç”Ÿæˆ merged/ç²¾ç®€ç‰ˆ.m3uï¼ˆIPv6ä¼˜å…ˆå•æºç²¾ç®€ç‰ˆï¼‰...")
    generate_multi_source_m3u(
        merged_channels, categories, final_category_order,
        timestamp, "merged/ç²¾ç®€ç‰ˆ.m3u", config,
        sources, success_sources, failed_sources, mode="single"
    )
    
    # 16. ç”Ÿæˆåˆ†ç±»M3Uæ–‡ä»¶
    print("\nğŸ“„ ç”Ÿæˆåˆ†ç±»æ–‡ä»¶ï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶æ ¼å¼ï¼‰...")
    for category in final_category_order:
        cat_channels = categories[category]
        if cat_channels:
            try:
                # å¯¹é¢‘é“è¿›è¡Œæ’åº
                sorted_channels = sorted(
                    cat_channels,
                    key=lambda x: get_channel_sort_key(x['clean_name'], category)
                )
                
                # åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å
                safe_category_name = category.replace('/', '_').replace('\\', '_')
                filename = f"categories/{safe_category_name}.m3u"
                
                with open(filename, "w", encoding="utf-8") as f:
                    f.write("#EXTM3U\n")
                    f.write(f"# {category}é¢‘é“åˆ—è¡¨ï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆï¼‰\n")
                    f.write(f"# æ›´æ–°æ—¶é—´(åŒ—äº¬æ—¶é—´): {timestamp}\n")
                    f.write(f"# ç”µè§†å°æ•°é‡: {len(cat_channels)}\n")
                    f.write(f"# è¯´æ˜: æ¯ä¸ªç”µè§†å°åŒ…å«å¤šä¸ªæºï¼ŒIPv6æºä¼˜å…ˆï¼ŒPotPlayeræŒ‰Alt+Wåˆ‡æ¢\n")
                    if config['ENABLE_SPEED_TEST']:
                        f.write(f"# å·²è¿‡æ»¤ä½è´¨é‡æºï¼ˆè¯„åˆ† < {config['MIN_SPEED_SCORE']}ï¼‰\n")
                    f.write(f"# é…ç½®æ–‡ä»¶: config.txt\n")
                    f.write(f"# é»‘åå•åŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_BLACKLIST'] else 'ç¦ç”¨'}\n")
                    f.write(f"# ç™½åå•åŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_WHITELIST'] else 'ç¦ç”¨'}\n")
                    f.write(f"# æµ‹é€ŸåŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_SPEED_TEST'] else 'ç¦ç”¨'}\n\n")
                    
                    for channel in sorted_channels:
                        # é€‰æ‹©ä¸»logoï¼ˆç¬¬ä¸€ä¸ªéç©ºçš„logoï¼‰
                        main_logo = channel['logos'][0] if channel['logos'] else ""
                        source_count = len(channel['sources'])
                        
                        # ç»Ÿè®¡IPv6æºæ•°é‡
                        ipv6_count = sum(1 for s in channel['sources'] if s.get('is_ipv6', False))
                        
                        # ç»Ÿè®¡ç™½åå•æºæ•°é‡
                        whitelist_count = sum(1 for s in channel['sources'] if s.get('is_whitelist', False))
                        
                        # PotPlayer/VLCå¤šæºæ ¼å¼
                        source_desc = []
                        if ipv6_count > 0:
                            source_desc.append(f"{ipv6_count}IPv6")
                        if whitelist_count > 0:
                            source_desc.append(f"{whitelist_count}ç™½åå•")
                        if source_count > ipv6_count + whitelist_count:
                            source_desc.append(f"{source_count-ipv6_count-whitelist_count}æ™®é€š")
                        
                        if source_desc:
                            display_name = f"{channel['clean_name']} [{'+'.join(source_desc)}]"
                        else:
                            display_name = f"{channel['clean_name']} [{source_count}æº]"
                        
                        # æ”¶é›†æ‰€æœ‰URLï¼ˆIPv6ä¼˜å…ˆï¼Œç™½åå•ä¼˜å…ˆï¼‰
                        urls = []
                        qualities = []
                        ipv6_sources = []
                        whitelist_sources = []
                        other_sources = []
                        
                        for source in channel['sources']:
                            if source.get('is_ipv6', False):
                                ipv6_sources.append(source)
                            elif source.get('is_whitelist', False):
                                whitelist_sources.append(source)
                            else:
                                other_sources.append(source)
                        
                        # ç¡®ä¿IPv6æºåœ¨å‰é¢ï¼Œç„¶åæ˜¯ç™½åå•æº
                        sorted_sources = ipv6_sources + whitelist_sources + other_sources
                        
                        for source in sorted_sources:
                            urls.append(source['url'])
                            if source['quality'] != "æœªçŸ¥":
                                qualities.append(source['quality'])
                        
                        # ç”Ÿæˆå¤šæºURL
                        multi_url = "|".join(urls)
                        
                        # å†™å…¥æ¡ç›®
                        line = "#EXTINF:-1"
                        line += f' tvg-name="{channel["clean_name"]}"'
                        line += f' group-title="{category}"'
                        if main_logo:
                            line += f' tvg-logo="{main_logo}"'
                        if qualities:
                            quality_desc = "/".join(sorted(set(qualities), key=lambda x: ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"].index(x) if x in ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"] else 10))
                            line += f' tvg-quality="{quality_desc}"'
                        if ipv6_count > 0:
                            line += f' tvg-ipv6="true"'
                        if whitelist_count > 0:
                            line += f' tvg-whitelist="true"'
                        line += f',{display_name}\n'
                        line += f"{multi_url}\n"
                        f.write(line)
                
                print(f"  âœ… ç”Ÿæˆ {filename}")
            except Exception as e:
                print(f"  âŒ ç”Ÿæˆ {filename} å¤±è´¥: {e}")
    
    # 17. ç”ŸæˆJSONæ–‡ä»¶
    print("\nğŸ“„ ç”Ÿæˆ channels.json...")
    generate_json_file(
        merged_channels, categories, config,
        sources, success_sources, failed_sources,
        all_channels, filtered_channels,
        blacklisted_count, whitelisted_count,
        blacklist, slow_urls, whitelist_data,
        timestamp
    )
    
    # 18. æ‰“å°æ€»ç»“ä¿¡æ¯
    print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
    print(f"ğŸ“Š ç»Ÿè®¡:")
    print(f"  - ç”µè§†å°æ€»æ•°: {len(merged_channels)}")
    print(f"  - å¤šæºç”µè§†å°: {multi_source_count}")
    print(f"  - å•æºç”µè§†å°: {single_source_count}")
    print(f"  - å«IPv6æºç”µè§†å°: {ipv6_channel_count}")
    print(f"  - å«ç™½åå•æºç”µè§†å°: {whitelist_channel_count}")
    if config['ENABLE_SPEED_TEST']:
        print(f"  - å«é«˜è´¨é‡æºç”µè§†å°: {high_quality_channel_count}")
    print(f"  - åŸå§‹é¢‘é“æ•°: {len(all_channels)}")
    print(f"  - è¿‡æ»¤åé¢‘é“æ•°: {len(filtered_channels)}")
    print(f"  - é»‘åå•è¿‡æ»¤æ•°: {blacklisted_count}")
    if whitelisted_count > 0:
        print(f"  - ç™½åå•ä¿ç•™æ•°: {whitelisted_count}")
    print(f"  - æ•°æ®æº: {len(sources)}")
    if config['ENABLE_BLACKLIST']:
        print(f"  - é»‘åå•æ¡ç›®: {len(blacklist) + len(slow_urls)}")
    if config['ENABLE_WHITELIST']:
        print(f"  - ç™½åå•æ¡ç›®: {len(whitelist_data.get('patterns', set())) + len(whitelist_data.get('urls', set()))}")
    
    print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - live_sources.m3u (IPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ - PotPlayer/VLCæ ¼å¼)")
    print(f"  - merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3u (IPv6ä¼˜å…ˆå¤šæºåˆ†ç¦»ç‰ˆ - TiviMate/Kodiæ ¼å¼)")
    print(f"  - merged/ç²¾ç®€ç‰ˆ.m3u (IPv6ä¼˜å…ˆå•æºç²¾ç®€ç‰ˆ)")
    print(f"  - channels.json (è¯¦ç»†æ•°æ®)")
    print(f"  - categories/*.m3u (åˆ†ç±»åˆ—è¡¨)")
    if config['ENABLE_BLACKLIST']:
        print(f"  - blacklist.txt (ä½è´¨é‡æºé»‘åå•)")
    if config['ENABLE_WHITELIST']:
        print(f"  - {config['WHITELIST_FILE']} (é‡è¦æºç™½åå•)")
    
    print(f"\nğŸ® æ’­æ”¾å™¨ä½¿ç”¨è¯´æ˜:")
    print(f"  1. PotPlayer/VLC: ä½¿ç”¨ live_sources.m3uï¼Œæ’­æ”¾æ—¶æŒ‰Alt+Wåˆ‡æ¢æº")
    print(f"  2. TiviMate/Kodi: ä½¿ç”¨ merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3uï¼Œè‡ªåŠ¨åˆå¹¶ç›¸åŒåç§°é¢‘é“")
    print(f"  3. å…¶ä»–æ’­æ”¾å™¨: ä½¿ç”¨ merged/ç²¾ç®€ç‰ˆ.m3uï¼Œæ¯ä¸ªç”µè§†å°IPv6æºä¼˜å…ˆ")

if __name__ == "__main__":
    main()