#!/usr/bin/env python3
"""
ç”µè§†ç›´æ’­æºæ”¶é›†è„šæœ¬ - å¸¦é»‘åå•çš„IPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ
åŠŸèƒ½ï¼š1. é¢‘é“åç§°ç²¾ç®€ 2. åŒåç”µè§†å°åˆå¹¶ï¼ˆIPv6ä¼˜å…ˆï¼‰3. æ”¯æŒæºåˆ‡æ¢ 4. ç»Ÿä¸€å¤®è§†é¢‘é“å‘½å 5. æ™ºèƒ½é€Ÿåº¦æµ‹è¯•å’Œé»‘åå•è¿‡æ»¤
ç‰¹ç‚¹ï¼šæ”¯æŒé…ç½®é»‘åå•æ˜¯å¦å¯ç”¨ã€ç”µè§†çº¿è·¯æ˜¯å¦æµ‹é€Ÿï¼Œæ”¹è¿›æµ‹é€Ÿç®—æ³•ï¼Œæ›´ç²¾å‡†è¯†åˆ«å¯ç”¨ç›´æ’­æº
åˆ†ç±»ï¼šå¤®è§†ã€å«è§†ã€åœ°æ–¹å°ï¼ˆæŒ‰çœä»½ï¼‰ã€å°‘å„¿å°ã€ç»¼è‰ºå°ã€æ¸¯æ¾³å°ã€ä½“è‚²å°ã€å½±è§†å°ã€æ™¯åŒºé¢‘é“ã€å…¶ä»–å°
æ’­æ”¾å™¨æ”¯æŒï¼šPotPlayerã€VLCã€TiviMateã€Kodiç­‰æ”¯æŒå¤šæºåˆ‡æ¢çš„æ’­æ”¾å™¨
"""

import requests
import re
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path
import json
import os
import sys
import ipaddress
import concurrent.futures
import threading
from urllib.parse import urlparse

print("=" * 70)
print("ç”µè§†ç›´æ’­æºæ”¶é›†è„šæœ¬ v8.0 - é…ç½®åŒ–æ™ºèƒ½æµ‹é€Ÿç‰ˆ")
print("åŠŸèƒ½ï¼šæ”¯æŒé…ç½®é»‘åå•/æµ‹é€Ÿå¼€å…³ï¼ŒIPv6ä¼˜å…ˆï¼Œæ™ºèƒ½æµ‹é€Ÿè¿‡æ»¤")
print("ç‰¹ç‚¹ï¼šå¯é€šè¿‡é…ç½®æ–‡ä»¶æ§åˆ¶é»‘åå•å’Œæµ‹é€ŸåŠŸèƒ½ï¼Œå‡å°‘è¯¯åˆ¤")
print("æ’­æ”¾å™¨ï¼šæ”¯æŒPotPlayerã€VLCã€TiviMateã€Kodiç­‰å¤šæºåˆ‡æ¢åŠŸèƒ½")
print("=" * 70)

# é…ç½®æ–‡ä»¶è·¯å¾„
CONFIG_FILE = "config.txt"

def load_config():
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    config = {
        'ENABLE_BLACKLIST': True,      # æ˜¯å¦å¯ç”¨é»‘åå•
        'ENABLE_SPEED_TEST': True,     # æ˜¯å¦å¯ç”¨æµ‹é€Ÿ
        'CONNECT_TIMEOUT': 3,          # è¿æ¥è¶…æ—¶æ—¶é—´
        'STREAM_TIMEOUT': 10,          # æµåª’ä½“æµ‹è¯•è¶…æ—¶æ—¶é—´
        'MIN_SPEED_SCORE': 0.5,        # æœ€ä½é€Ÿåº¦è¯„åˆ†
        'MAX_WORKERS': 20,             # å¹¶å‘æµ‹è¯•çº¿ç¨‹æ•°
    }
    
    if not os.path.exists(CONFIG_FILE):
        print(f"ğŸ“ é…ç½®æ–‡ä»¶ {CONFIG_FILE} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        print(f"   é»‘åå•åŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_BLACKLIST'] else 'ç¦ç”¨'}")
        print(f"   æµ‹é€ŸåŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_SPEED_TEST'] else 'ç¦ç”¨'}")
        return config
    
    try:
        with open(CONFIG_FILE, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                
                if "=" in line:
                    key, value = line.split("=", 1)
                    key = key.strip()
                    value = value.strip()
                    
                    # å¸ƒå°”å€¼å¤„ç†
                    if key in ['ENABLE_BLACKLIST', 'ENABLE_SPEED_TEST']:
                        if value.lower() in ['true', 'yes', '1', 'on']:
                            config[key] = True
                        elif value.lower() in ['false', 'no', '0', 'off']:
                            config[key] = False
                        else:
                            print(f"âš ï¸  é…ç½®ç¬¬{line_num}è¡Œ: {key} å€¼ '{value}' æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ {config[key]}")
                    
                    # æ•´æ•°å¤„ç†
                    elif key in ['CONNECT_TIMEOUT', 'STREAM_TIMEOUT', 'MAX_WORKERS']:
                        try:
                            config[key] = int(value)
                        except ValueError:
                            print(f"âš ï¸  é…ç½®ç¬¬{line_num}è¡Œ: {key} å€¼ '{value}' ä¸æ˜¯æœ‰æ•ˆæ•´æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ {config[key]}")
                    
                    # æµ®ç‚¹æ•°å¤„ç†
                    elif key == 'MIN_SPEED_SCORE':
                        try:
                            val = float(value)
                            if 0 <= val <= 1:
                                config[key] = val
                            else:
                                print(f"âš ï¸  é…ç½®ç¬¬{line_num}è¡Œ: {key} å€¼ '{value}' è¶…å‡ºèŒƒå›´(0-1)ï¼Œä½¿ç”¨é»˜è®¤å€¼ {config[key]}")
                        except ValueError:
                            print(f"âš ï¸  é…ç½®ç¬¬{line_num}è¡Œ: {key} å€¼ '{value}' ä¸æ˜¯æœ‰æ•ˆæµ®ç‚¹æ•°ï¼Œä½¿ç”¨é»˜è®¤å€¼ {config[key]}")
                    
                    else:
                        print(f"âš ï¸  é…ç½®ç¬¬{line_num}è¡Œ: æœªçŸ¥é…ç½®é¡¹ '{key}'ï¼Œè·³è¿‡")
        
        print(f"âœ… ä» {CONFIG_FILE} åŠ è½½é…ç½®:")
        print(f"   é»‘åå•åŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_BLACKLIST'] else 'ç¦ç”¨'}")
        print(f"   æµ‹é€ŸåŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_SPEED_TEST'] else 'ç¦ç”¨'}")
        print(f"   è¿æ¥è¶…æ—¶: {config['CONNECT_TIMEOUT']}ç§’")
        print(f"   æµæµ‹è¯•è¶…æ—¶: {config['STREAM_TIMEOUT']}ç§’")
        print(f"   æœ€ä½è¯„åˆ†: {config['MIN_SPEED_SCORE']}")
        print(f"   å¹¶å‘çº¿ç¨‹: {config['MAX_WORKERS']}")
        
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
    
    return config

# åŠ è½½é…ç½®
config = load_config()

def load_sources_from_file():
    """ä»sources.txtæ–‡ä»¶åŠ è½½æ‰€æœ‰ç”µè§†æº"""
    sources_file = "sources.txt"
    sources = []
    
    if not os.path.exists(sources_file):
        print(f"âŒ é”™è¯¯: {sources_file} æ–‡ä»¶ä¸å­˜åœ¨")
        print(f"ğŸ“ è¯·åˆ›å»º {sources_file} æ–‡ä»¶ï¼Œæ¯è¡Œæ·»åŠ ä¸€ä¸ªM3Uæ–‡ä»¶URL")
        return sources
    
    try:
        with open(sources_file, "r", encoding="utf-8") as f:
            line_number = 0
            for line in f:
                line_number += 1
                line = line.strip()
                
                # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                if not line:
                    continue
                if line.startswith("#"):
                    continue
                
                # éªŒè¯URLæ ¼å¼
                if line.startswith("http://") or line.startswith("https://"):
                    sources.append(line)
                else:
                    print(f"âš ï¸  ç¬¬{line_number}è¡Œæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡: {line}")
        
        print(f"ğŸ“¡ ä» {sources_file} åŠ è½½äº† {len(sources)} ä¸ªæ•°æ®æº")
        
        if len(sources) == 0:
            print(f"âŒ é”™è¯¯: {sources_file} ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„URL")
            print(f"ğŸ“ è¯·åœ¨ {sources_file} ä¸­æ·»åŠ M3Uæ–‡ä»¶URLï¼Œæ ¼å¼: https://example.com/live.m3u")
        
    except Exception as e:
        print(f"âŒ è¯»å– {sources_file} å¤±è´¥: {e}")
    
    return sources

# ä»sources.txtæ–‡ä»¶åŠ è½½æ‰€æœ‰æº
sources = load_sources_from_file()

if len(sources) == 0:
    print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®æºï¼Œé€€å‡º")
    sys.exit(1)

# é»‘åå•ç®¡ç†
BLACKLIST_FILE = "blacklist.txt"

# æ™ºèƒ½æµ‹é€Ÿé…ç½®
class SpeedTestConfig:
    """æµ‹é€Ÿé…ç½®ç±»"""
    
    # M3U8æµ‹è¯•é…ç½®
    M3U8_TEST_SIZE = 1024 * 10  # æµ‹è¯•æ•°æ®å¤§å° (10KB)
    M3U8_HEAD_TIMEOUT = 2  # HEADè¯·æ±‚è¶…æ—¶
    M3U8_PARTIAL_TIMEOUT = 5  # éƒ¨åˆ†å†…å®¹è¯·æ±‚è¶…æ—¶
    
    # è¯„åˆ†æƒé‡
    CONNECTION_WEIGHT = 0.3  # è¿æ¥é€Ÿåº¦æƒé‡
    STABILITY_WEIGHT = 0.4   # ç¨³å®šæ€§æƒé‡
    RESPONSE_WEIGHT = 0.3    # å“åº”æƒé‡
    
    # IPv6å®½å®¹åº¦
    IPV6_BONUS = 0.2  # IPv6æºåŠ åˆ†
    IPV6_CONNECT_TIMEOUT = 5  # IPv6è¿æ¥è¶…æ—¶æ—¶é—´

# IPv6æ£€æµ‹å‡½æ•°
def is_ipv6_url(url):
    """æ£€æµ‹URLæ˜¯å¦ä¸ºIPv6åœ°å€"""
    try:
        # ä»URLä¸­æå–ä¸»æœºå
        if '://' in url:
            hostname = url.split('://')[1].split('/')[0]
        else:
            hostname = url.split('/')[0]
        
        # ç§»é™¤ç«¯å£å·
        if ':' in hostname:
            # å¤„ç†IPv6åœ°å€çš„ç«¯å£å·æ ¼å¼ [::1]:8080
            if hostname.startswith('['):
                # IPv6åœ°å€å¸¦ç«¯å£
                ip_part = hostname.split(']')[0][1:]
            else:
                ip_part = hostname.split(':')[0]
        else:
            ip_part = hostname
        
        # å°è¯•è§£æä¸ºIPv6åœ°å€
        ipaddress.IPv6Address(ip_part)
        return True
    except:
        # ä¹Ÿæ£€æŸ¥URLä¸­æ˜¯å¦åŒ…å«IPv6å…³é”®å­—
        url_lower = url.lower()
        if 'ipv6' in url_lower or 'ip6' in url_lower or 'v6' in url_lower:
            return True
        # æ£€æŸ¥æ˜¯å¦åŒ…å«IPv6åœ°å€æ ¼å¼ï¼ˆå†’å·æ•°é‡å¤šï¼‰
        if url_lower.count(':') >= 3:
            return True
        return False

def get_smart_timeout(url):
    """è·å–æ™ºèƒ½è¶…æ—¶æ—¶é—´"""
    if is_ipv6_url(url):
        return SpeedTestConfig.IPV6_CONNECT_TIMEOUT
    return config['CONNECT_TIMEOUT']

def test_m3u8_stream(url, timeout=None):
    """æ™ºèƒ½æµ‹è¯•M3U8æµåª’ä½“æº"""
    if timeout is None:
        timeout = config['STREAM_TIMEOUT']
    
    test_results = {
        'connect_time': None,
        'response_time': None,
        'success': False,
        'error': None,
        'content_type': None,
        'content_length': 0
    }
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Range": f"bytes=0-{SpeedTestConfig.M3U8_TEST_SIZE-1}",
            "Connection": "close"
        }
        
        # ç¬¬ä¸€é˜¶æ®µï¼šæµ‹è¯•è¿æ¥é€Ÿåº¦
        start_connect = time.time()
        
        # é¦–å…ˆå°è¯•HEADè¯·æ±‚ï¼ˆè½»é‡çº§ï¼‰
        try:
            head_response = requests.head(
                url, 
                headers=headers, 
                timeout=get_smart_timeout(url),
                allow_redirects=True,
                verify=False
            )
            head_response.close()
        except:
            pass  # HEADè¯·æ±‚å¤±è´¥ä¹Ÿæ²¡å…³ç³»ï¼Œç»§ç»­æµ‹è¯•GET
        
        # ç¬¬äºŒé˜¶æ®µï¼šæµ‹è¯•éƒ¨åˆ†å†…å®¹è·å–
        start_partial = time.time()
        response = requests.get(
            url,
            headers=headers,
            timeout=timeout,
            stream=True,
            allow_redirects=True,
            verify=False
        )
        
        # è®°å½•å“åº”ä¿¡æ¯
        end_partial = time.time()
        
        test_results['connect_time'] = start_partial - start_connect
        test_results['response_time'] = end_partial - start_partial
        test_results['content_type'] = response.headers.get('Content-Type', '')
        test_results['content_length'] = int(response.headers.get('Content-Length', 0))
        
        # éªŒè¯å†…å®¹æ˜¯å¦ä¸ºè§†é¢‘æµ
        content_type = test_results['content_type'].lower()
        is_video_stream = any(marker in content_type for marker in [
            'video', 'application/vnd.apple.mpegurl', 'application/x-mpegurl'
        ])
        
        # æ£€æŸ¥å“åº”çŠ¶æ€ç 
        if response.status_code in [200, 206]:  # 206æ˜¯éƒ¨åˆ†å†…å®¹
            # å°è¯•è¯»å–ä¸€å°éƒ¨åˆ†æ•°æ®éªŒè¯å¯ç”¨æ€§
            bytes_read = 0
            for chunk in response.iter_content(chunk_size=1024):
                bytes_read += len(chunk)
                if bytes_read >= 1024:  # è‡³å°‘è¯»å–1KB
                    test_results['success'] = True
                    break
                if time.time() - start_partial > timeout:
                    break
        else:
            test_results['error'] = f"HTTP {response.status_code}"
        
        response.close()
        
    except requests.exceptions.Timeout:
        test_results['error'] = "è¿æ¥è¶…æ—¶"
    except requests.exceptions.ConnectionError as e:
        test_results['error'] = f"è¿æ¥é”™è¯¯: {str(e)}"
    except requests.exceptions.TooManyRedirects:
        test_results['error'] = "é‡å®šå‘è¿‡å¤š"
    except Exception as e:
        test_results['error'] = f"å…¶ä»–é”™è¯¯: {str(e)}"
    
    return test_results

def calculate_speed_score(test_results, url):
    """è®¡ç®—é€Ÿåº¦è¯„åˆ†ï¼ˆ0-1åˆ†ï¼‰"""
    if not test_results['success']:
        return 0.0
    
    score = 0.0
    
    # 1. è¿æ¥é€Ÿåº¦è¯„åˆ†ï¼ˆ30%ï¼‰
    if test_results['connect_time'] is not None:
        connect_score = 1.0 - min(test_results['connect_time'] / (config['CONNECT_TIMEOUT'] * 2), 1.0)
        score += connect_score * SpeedTestConfig.CONNECTION_WEIGHT
    
    # 2. å“åº”é€Ÿåº¦è¯„åˆ†ï¼ˆ30%ï¼‰
    if test_results['response_time'] is not None:
        # ç†æƒ³å“åº”æ—¶é—´å°äº2ç§’
        response_score = 1.0 - min(test_results['response_time'] / 4.0, 1.0)
        score += response_score * SpeedTestConfig.RESPONSE_WEIGHT
    
    # 3. å†…å®¹éªŒè¯è¯„åˆ†ï¼ˆ40%ï¼‰
    content_score = 0.0
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºè§†é¢‘æµ
    content_type = test_results['content_type'].lower()
    if any(marker in content_type for marker in ['video', 'mpegurl', 'm3u8']):
        content_score += 0.5
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹é•¿åº¦
    if test_results['content_length'] > 0:
        content_score += 0.3
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç›´æ’­æºå¸¸è§æ ¼å¼
    if 'm3u8' in url.lower() or 'ts' in url.lower():
        content_score += 0.2
    
    score += content_score * SpeedTestConfig.STABILITY_WEIGHT
    
    # 4. IPv6åŠ åˆ†
    if is_ipv6_url(url):
        score += SpeedTestConfig.IPV6_BONUS
    
    # ç¡®ä¿åˆ†æ•°åœ¨0-1ä¹‹é—´
    return min(max(score, 0.0), 1.0)

def test_url_speed(url):
    """æ™ºèƒ½æµ‹è¯•URLé€Ÿåº¦ï¼Œè¿”å›è¯„åˆ†å’Œè¯¦ç»†ç»“æœ"""
    start_time = time.time()
    
    # å¦‚æœæ˜¯M3U8æˆ–TSæµï¼Œä½¿ç”¨æ™ºèƒ½æµ‹è¯•
    if url.lower().endswith('.m3u8') or '.m3u8?' in url.lower():
        test_results = test_m3u8_stream(url)
        test_time = time.time() - start_time
        speed_score = calculate_speed_score(test_results, url)
        
        return {
            'score': speed_score,
            'success': test_results['success'],
            'test_time': test_time,
            'connect_time': test_results.get('connect_time'),
            'response_time': test_results.get('response_time'),
            'error': test_results.get('error'),
            'is_ipv6': is_ipv6_url(url)
        }
    else:
        # å¯¹äºå…¶ä»–ç±»å‹URLï¼Œä½¿ç”¨ç®€å•æµ‹è¯•
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "*/*",
                "Connection": "close"
            }
            
            response_start = time.time()
            response = requests.head(
                url, 
                headers=headers, 
                timeout=get_smart_timeout(url),
                allow_redirects=True
            )
            response_time = time.time() - response_start
            
            # ç®€å•è¯„åˆ†
            if response.status_code < 400:
                # åŸºç¡€åˆ† + IPv6åŠ åˆ†
                score = 0.7 - min(response_time / 5.0, 0.7)
                if is_ipv6_url(url):
                    score += SpeedTestConfig.IPV6_BONUS
                
                return {
                    'score': score,
                    'success': True,
                    'test_time': time.time() - start_time,
                    'connect_time': response_time,
                    'response_time': response_time,
                    'error': None,
                    'is_ipv6': is_ipv6_url(url)
                }
            else:
                return {
                    'score': 0.0,
                    'success': False,
                    'test_time': time.time() - start_time,
                    'connect_time': None,
                    'response_time': None,
                    'error': f"HTTP {response.status_code}",
                    'is_ipv6': is_ipv6_url(url)
                }
                
        except Exception as e:
            test_time = time.time() - start_time
            return {
                'score': 0.0,
                'success': False,
                'test_time': test_time,
                'connect_time': None,
                'response_time': None,
                'error': str(e)[:100],
                'is_ipv6': is_ipv6_url(url)
            }

def get_source_priority(source_info):
    """è·å–æºçš„ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆç”¨äºæ’åºï¼‰"""
    priority = 0
    
    # IPv6æºæœ€é«˜ä¼˜å…ˆçº§ï¼ˆ+100åˆ†ï¼‰
    if source_info.get('is_ipv6', False):
        priority += 100
    
    # é€Ÿåº¦è¯„åˆ†ä¼˜å…ˆçº§ï¼ˆå¦‚æœæµ‹é€ŸåŠŸèƒ½å¯ç”¨ï¼‰
    if config['ENABLE_SPEED_TEST'] and 'speed_score' in source_info:
        score = source_info['speed_score']
        if score >= 0.9:
            priority += 50
        elif score >= 0.7:
            priority += 30
        elif score >= 0.5:
            priority += 10
    
    # æ¸…æ™°åº¦ä¼˜å…ˆçº§
    quality_scores = {
        "4K": 40,
        "é«˜æ¸…": 30,
        "æ ‡æ¸…": 20,
        "æµç•…": 10,
        "æœªçŸ¥": 0
    }
    priority += quality_scores.get(source_info['quality'], 0)
    
    # æºè´¨é‡æ ‡è®°ä¼˜å…ˆçº§
    url_lower = source_info['url'].lower()
    if any(marker in url_lower for marker in ['cdn', 'akamai', 'cloudfront']):
        priority += 5  # CDNæºåŠ åˆ†
    if 'https://' in url_lower:
        priority += 3  # HTTPSæºåŠ åˆ†
    if 'm3u8' in url_lower:
        priority += 2  # HLSæºåŠ åˆ†
    
    return priority

# é¢‘é“åç§°æ¸…ç†è§„åˆ™ - æ·±åº¦ç²¾ç®€
CLEAN_RULES = [
    # ç§»é™¤æŠ€æœ¯å‚æ•°æ ‡è®°
    (r'50\s*FPS', ''),  # ç§»é™¤50 FPS
    (r'HEVC', ''),  # ç§»é™¤HEVC
    (r'H\.?264', ''),  # ç§»é™¤H.264
    (r'H\.?265', ''),  # ç§»é™¤H.265
    (r'AAC', ''),  # ç§»é™¤AAC
    (r'AC3', ''),  # ç§»é™¤AC3
    (r'[\[\(][^\]\)]*[\]\)]', ''),  # ç§»é™¤æ‰€æœ‰æ‹¬å·å†…å®¹
    (r'ã€[^ã€‘]*ã€‘', ''),  # ç§»é™¤æ‰€æœ‰ä¸­æ–‡æ‹¬å·å†…å®¹
    
    # ç§»é™¤æ¸…æ™°åº¦æ ‡è®°
    (r'[_\-\s]?4K[_\-\s]?', ' '),  # ç§»é™¤4Kæ ‡è®°
    (r'[_\-\s]?é«˜æ¸…[_\-\s]?', ' '),  # ç§»é™¤é«˜æ¸…æ ‡è®°
    (r'[_\-\s]?HD[_\-\s]?', ' '),  # ç§»é™¤HDæ ‡è®°
    (r'[_\-\s]?è¶…æ¸…[_\-\s]?', ' '),  # ç§»é™¤è¶…æ¸…æ ‡è®°
    (r'[_\-\s]?æ ‡æ¸…[_\-\s]?', ' '),  # ç§»é™¤æ ‡æ¸…æ ‡è®°
    (r'[_\-\s]?æµç•…[_\-\s]?', ' '),  # ç§»é™¤æµç•…æ ‡è®°
    (r'[_\-\s]?1080[Pp]?[_\-\s]?', ' '),  # ç§»é™¤1080Pæ ‡è®°
    (r'[_\-\s]?720[Pp]?[_\-\s]?', ' '),  # ç§»é™¤720Pæ ‡è®°
    
    # ç§»é™¤åè®®æ ‡è®°
    (r'[_\-\s]?IPV6[_\-\s]?', ' '),  # ç§»é™¤IPV6æ ‡è®°
    (r'[_\-\s]?IPV4[_\-\s]?', ' '),  # ç§»é™¤IPV4æ ‡è®°
    (r'[_\-\s]?HLS[_\-\s]?', ' '),  # ç§»é™¤HLSæ ‡è®°
    (r'[_\-\s]?RTMP[_\-\s]?', ' '),  # ç§»é™¤RTMPæ ‡è®°
    (r'[_\-\s]?RTSP[_\-\s]?', ' '),  # ç§»é™¤RTSPæ ‡è®°
    (r'[_\-\s]?FLV[_\-\s]?', ' '),  # ç§»é™¤FLVæ ‡è®°
    
    # ç§»é™¤å†—ä½™è¯
    (r'\s+ç›´æ’­$', ''),  # ç§»é™¤"ç›´æ’­"åç¼€
    (r'\s+é¢‘é“$', ''),  # ç§»é™¤"é¢‘é“"åç¼€
    (r'\s+å°$', ''),  # ç§»é™¤"å°"åç¼€
    (r'\s+ç”µè§†å°$', ''),  # ç§»é™¤"ç”µè§†å°"åç¼€
    (r'\s+å«è§†å°$', 'å«è§†'),  # å«è§†å°æ”¹ä¸ºå«è§†
    
    # ç»Ÿä¸€ç¬¦å·
    (r'\s+', ' '),  # å¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ª
    (r'^\s+|\s+$', ''),  # å»é™¤é¦–å°¾ç©ºæ ¼
    (r'[_\-\|]+', ' '),  # ç»Ÿä¸€åˆ†éš”ç¬¦ä¸ºç©ºæ ¼
    (r'\s*&\s*', ' '),  # &ç¬¦å·æ›¿æ¢ä¸ºç©ºæ ¼
]

# å¤®è§†é¢‘é“æ ‡å‡†åŒ–æ˜ å°„
CCTV_MAPPING = {
    # æ ‡å‡†CCTVæ•°å­—é¢‘é“
    r'^CCTV[_\-\s]?1$': 'CCTV-1 ç»¼åˆ',
    r'^CCTV[_\-\s]?2$': 'CCTV-2 è´¢ç»',
    r'^CCTV[_\-\s]?3$': 'CCTV-3 ç»¼è‰º',
    r'^CCTV[_\-\s]?4$': 'CCTV-4 ä¸­æ–‡å›½é™…',
    r'^CCTV[_\-\s]?5$': 'CCTV-5 ä½“è‚²',
    r'^CCTV[_\-\s]?5\+$': 'CCTV-5+ ä½“è‚²èµ›äº‹',
    r'^CCTV[_\-\s]?6$': 'CCTV-6 ç”µå½±',
    r'^CCTV[_\-\s]?7$': 'CCTV-7 å›½é˜²å†›äº‹',
    r'^CCTV[_\-\s]?8$': 'CCTV-8 ç”µè§†å‰§',
    r'^CCTV[_\-\s]?9$': 'CCTV-9 çºªå½•',
    r'^CCTV[_\-\s]?10$': 'CCTV-10 ç§‘æ•™',
    r'^CCTV[_\-\s]?11$': 'CCTV-11 æˆæ›²',
    r'^CCTV[_\-\s]?12$': 'CCTV-12 ç¤¾ä¼šä¸æ³•',
    r'^CCTV[_\-\s]?13$': 'CCTV-13 æ–°é—»',
    r'^CCTV[_\-\s]?14$': 'CCTV-14 å°‘å„¿',
    r'^CCTV[_\-\s]?15$': 'CCTV-15 éŸ³ä¹',
    r'^CCTV[_\-\s]?16$': 'CCTV-16 å¥¥æ—åŒ¹å…‹',
    r'^CCTV[_\-\s]?17$': 'CCTV-17 å†œä¸šå†œæ‘',
    
    # å¤®è§†ä¸­æ–‡æ•°å­—é¢‘é“
    r'^CCTV[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]$': 'CCTV-{num}',
    r'^å¤®è§†[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]$': 'CCTV-{num}',
    r'^ä¸­å¤®ç”µè§†å°[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]?$': 'CCTV-1 ç»¼åˆ',
    
    # å¤®è§†é«˜æ¸…/4Ké¢‘é“
    r'^CCTV4K$': 'CCTV-4K è¶…é«˜æ¸…',
    r'^CCTV8K$': 'CCTV-8K è¶…é«˜æ¸…',
    r'^CCTV[_\-\s]?é«˜æ¸…$': 'CCTV-é«˜æ¸…',
    
    # å¤®è§†å…¶ä»–é¢‘é“
    r'^CCTV[_\-\s]?æˆæ›²$': 'CCTV-11 æˆæ›²',
    r'^CCTV[_\-\s]?éŸ³ä¹$': 'CCTV-15 éŸ³ä¹',
    r'^CCTV[_\-\s]?å°‘å„¿$': 'CCTV-14 å°‘å„¿',
    r'^CCTV[_\-\s]?æ–°é—»$': 'CCTV-13 æ–°é—»',
    r'^CCTV[_\-\s]?çºªå½•$': 'CCTV-9 çºªå½•',
    r'^CCTV[_\-\s]?ä½“è‚²$': 'CCTV-5 ä½“è‚²',
    r'^CCTV[_\-\s]?ç”µå½±$': 'CCTV-6 ç”µå½±',
    r'^CCTV[_\-\s]?ç”µè§†å‰§$': 'CCTV-8 ç”µè§†å‰§',
    r'^CCTV[_\-\s]?ç»¼è‰º$': 'CCTV-3 ç»¼è‰º',
    r'^CCTV[_\-\s]?è´¢ç»$': 'CCTV-2 è´¢ç»',
}

# ä¸­æ–‡æ•°å­—åˆ°é˜¿æ‹‰ä¼¯æ•°å­—æ˜ å°„
CHINESE_NUMBERS = {
    'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5',
    'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9', 'å': '10',
    'åä¸€': '11', 'åäºŒ': '12', 'åä¸‰': '13', 'åå››': '14', 'åäº”': '15',
    'åå…­': '16', 'åä¸ƒ': '17'
}

# é¢‘é“æ’åºé…ç½®
CHANNEL_ORDER_RULES = {
    # å¤®è§†æŒ‰æ•°å­—é¡ºåº
    "å¤®è§†": {
        "CCTV-1 ç»¼åˆ": 1, "CCTV-2 è´¢ç»": 2, "CCTV-3 ç»¼è‰º": 3, "CCTV-4 ä¸­æ–‡å›½é™…": 4,
        "CCTV-5 ä½“è‚²": 5, "CCTV-5+ ä½“è‚²èµ›äº‹": 6, "CCTV-6 ç”µå½±": 7, "CCTV-7 å›½é˜²å†›äº‹": 8,
        "CCTV-8 ç”µè§†å‰§": 9, "CCTV-9 çºªå½•": 10, "CCTV-10 ç§‘æ•™": 11, "CCTV-11 æˆæ›²": 12,
        "CCTV-12 ç¤¾ä¼šä¸æ³•": 13, "CCTV-13 æ–°é—»": 14, "CCTV-14 å°‘å„¿": 15, "CCTV-15 éŸ³ä¹": 16,
        "CCTV-16 å¥¥æ—åŒ¹å…‹": 17, "CCTV-17 å†œä¸šå†œæ‘": 18, "CCTV-4K è¶…é«˜æ¸…": 19
    },
    
    # å«è§†æŒ‰æ‹¼éŸ³é¡ºåºï¼ˆå¸¸ç”¨å«è§†åœ¨å‰ï¼‰
    "å«è§†": {
        "åŒ—äº¬å«è§†": 1, "ä¸Šæµ·ä¸œæ–¹å«è§†": 2, "å¤©æ´¥å«è§†": 3, "é‡åº†å«è§†": 4,
        "æ²³åŒ—å«è§†": 5, "å±±è¥¿å«è§†": 6, "è¾½å®å«è§†": 7, "å‰æ—å«è§†": 8,
        "é»‘é¾™æ±Ÿå«è§†": 9, "æ±Ÿè‹å«è§†": 10, "æµ™æ±Ÿå«è§†": 11, "å®‰å¾½å«è§†": 12,
        "ç¦å»ºå«è§†": 13, "æ±Ÿè¥¿å«è§†": 14, "å±±ä¸œå«è§†": 15, "æ²³å—å«è§†": 16,
        "æ¹–åŒ—å«è§†": 17, "æ¹–å—å«è§†": 18, "å¹¿ä¸œå«è§†": 19, "å¹¿è¥¿å«è§†": 20,
        "æµ·å—å«è§†": 21, "å››å·å«è§†": 22, "è´µå·å«è§†": 23, "äº‘å—å«è§†": 24,
        "é™•è¥¿å«è§†": 25, "ç”˜è‚ƒå«è§†": 26, "é’æµ·å«è§†": 27, "å®å¤å«è§†": 28,
        "æ–°ç–†å«è§†": 29, "å†…è’™å¤å«è§†": 30, "è¥¿è—å«è§†": 31
    }
}

# çœä»½åˆ—è¡¨ï¼ˆç”¨äºåœ°æ–¹å°åˆ†ç±»ï¼‰
PROVINCES = [
    "åŒ—äº¬å¸‚", "å¤©æ´¥å¸‚", "æ²³åŒ—çœ", "å±±è¥¿çœ", "å†…è’™å¤è‡ªæ²»åŒº",
    "è¾½å®çœ", "å‰æ—çœ", "é»‘é¾™æ±Ÿçœ", "ä¸Šæµ·å¸‚", "æ±Ÿè‹çœ",
    "æµ™æ±Ÿçœ", "å®‰å¾½çœ", "ç¦å»ºçœ", "æ±Ÿè¥¿çœ", "å±±ä¸œçœ",
    "æ²³å—çœ", "æ¹–åŒ—çœ", "æ¹–å—çœ", "å¹¿ä¸œçœ", "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
    "æµ·å—çœ", "é‡åº†å¸‚", "å››å·çœ", "è´µå·çœ", "äº‘å—çœ",
    "è¥¿è—è‡ªæ²»åŒº", "é™•è¥¿çœ", "ç”˜è‚ƒçœ", "é’æµ·çœ", "å®å¤å›æ—è‡ªæ²»åŒº",
    "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº", "å°æ¹¾çœ", "é¦™æ¸¯", "æ¾³é—¨"
]

# çœä»½ç®€ç§°æ˜ å°„
PROVINCE_ABBR = {
    "åŒ—äº¬": "åŒ—äº¬å¸‚", "å¤©æ´¥": "å¤©æ´¥å¸‚", "æ²³åŒ—": "æ²³åŒ—çœ", "å±±è¥¿": "å±±è¥¿çœ",
    "å†…è’™å¤": "å†…è’™å¤è‡ªæ²»åŒº", "è¾½å®": "è¾½å®çœ", "å‰æ—": "å‰æ—çœ", "é»‘é¾™æ±Ÿ": "é»‘é¾™æ±Ÿçœ",
    "ä¸Šæµ·": "ä¸Šæµ·å¸‚", "æ±Ÿè‹": "æ±Ÿè‹çœ", "æµ™æ±Ÿ": "æµ™æ±Ÿçœ", "å®‰å¾½": "å®‰å¾½çœ",
    "ç¦å»º": "ç¦å»ºçœ", "æ±Ÿè¥¿": "æ±Ÿè¥¿çœ", "å±±ä¸œ": "å±±ä¸œçœ", "æ²³å—": "æ²³å—çœ",
    "æ¹–åŒ—": "æ¹–åŒ—çœ", "æ¹–å—": "æ¹–å—çœ", "å¹¿ä¸œ": "å¹¿ä¸œçœ", "å¹¿è¥¿": "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
    "æµ·å—": "æµ·å—çœ", "é‡åº†": "é‡åº†å¸‚", "å››å·": "å››å·çœ", "è´µå·": "è´µå·çœ",
    "äº‘å—": "äº‘å—çœ", "è¥¿è—": "è¥¿è—è‡ªæ²»åŒº", "é™•è¥¿": "é™•è¥¿çœ", "ç”˜è‚ƒ": "ç”˜è‚ƒçœ",
    "é’æµ·": "é’æµ·çœ", "å®å¤": "å®å¤å›æ—è‡ªæ²»åŒº", "æ–°ç–†": "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº",
    "å°æ¹¾": "å°æ¹¾çœ", "é¦™æ¸¯": "é¦™æ¸¯", "æ¾³é—¨": "æ¾³é—¨"
}

# åˆ†ç±»è§„åˆ™ - æŒ‰ä¼˜å…ˆçº§é¡ºåºåŒ¹é…
CATEGORY_RULES = {
    # å¤®è§† - æœ€å…·ä½“ï¼Œæœ€å…ˆåŒ¹é…
    "å¤®è§†": [
        r"^CCTV[-\s]?[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+",  # CCTV1, CCTV-1, CCTVä¸€
        r"^å¤®è§†[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+",  # å¤®è§†ä¸€, å¤®è§†äºŒ
        r"^ä¸­å¤®ç”µè§†å°",  # ä¸­å¤®ç”µè§†å°
        r"^CCTV[-\s]?4K", r"^CCTV[-\s]?8K", r"^CCTV[-\s]?5\+",
        r"^CCTV[-\s]?ç»¼åˆ$", r"^CCTV[-\s]?è´¢ç»$", r"^CCTV[-\s]?ç»¼è‰º$",
        r"^CCTV[-\s]?ä½“è‚²$", r"^CCTV[-\s]?ç”µå½±$", r"^CCTV[-\s]?ç”µè§†å‰§$",
    ],
    
    # å«è§†
    "å«è§†": [
        r"å«è§†$",  # ä»¥"å«è§†"ç»“å°¾
        r"^åŒ—äº¬å«è§†$", r"^æ¹–å—å«è§†$", r"^æµ™æ±Ÿå«è§†$", r"^æ±Ÿè‹å«è§†$",
        r"^ä¸œæ–¹å«è§†$", r"^å¤©æ´¥å«è§†$", r"^å®‰å¾½å«è§†$", r"^å±±ä¸œå«è§†$",
        r"^å¹¿ä¸œå«è§†$", r"^æ·±åœ³å«è§†$", r"^é»‘é¾™æ±Ÿå«è§†$", r"^è¾½å®å«è§†$",
        r"^æ¹–åŒ—å«è§†$", r"^æ²³å—å«è§†$", r"^å››å·å«è§†$", r"^é‡åº†å«è§†$",
        r"^æ±Ÿè¥¿å«è§†$", r"^å¹¿è¥¿å«è§†$", r"^ä¸œå—å«è§†$", r"^è´µå·å«è§†$",
        r"^äº‘å—å«è§†$", r"^é™•è¥¿å«è§†$", r"^å±±è¥¿å«è§†$", r"^æ²³åŒ—å«è§†$",
        r"^æµ·å—å«è§†$", r"^å®å¤å«è§†$", r"^æ–°ç–†å«è§†$", r"^å†…è’™å¤å«è§†$",
    ],
    
    # æ™¯åŒºé¢‘é“ï¼ˆæ–°å¢ï¼‰
    "æ™¯åŒºé¢‘é“": [
        r"æ™¯åŒº$", r"æ—…æ¸¸$", r"é£å…‰$", r"æ™¯ç‚¹$", r"å¯¼è§†$",
        r"^å³¨çœ‰å±±", r"^ä¹å¯¨æ²Ÿ", r"^é»„å±±", r"^æ³°å±±", r"^åå±±",
        r"^å¼ å®¶ç•Œ", r"^è¥¿æ¹–", r"^æ¼“æ±Ÿ", r"^é¼“æµªå±¿", r"^æ•…å®«",
        r"^é•¿åŸ", r"^å…µé©¬ä¿‘", r"^å¸ƒè¾¾æ‹‰å®«", r"^å¤©å®‰é—¨", r"^å¤–æ»©",
        r"^ç»´å¤šåˆ©äºšæ¸¯", r"^æ¾³é—¨å¡”", r"^æ—¥æœˆæ½­", r"^é˜¿é‡Œå±±"
    ],
    
    # å°‘å„¿å°
    "å°‘å„¿å°": [
        r"å°‘å„¿$", r"å¡é€š$", r"åŠ¨æ¼«$", r"åŠ¨ç”»$", r"é‡‘é¹°å¡é€š",
        r"å¡é…·å°‘å„¿", r"å“ˆå“ˆç‚«åŠ¨", r"ä¼˜æ¼«å¡é€š", r"å˜‰ä½³å¡é€š",
        r"ç‚«åŠ¨å¡é€š", r"å®è´"
    ],
    
    # ç»¼è‰ºå°
    "ç»¼è‰ºå°": [
        r"ç»¼è‰º$", r"æ–‡è‰º$", r"å¨±ä¹$", r"éŸ³ä¹$", r"æˆæ›²$",
        r"ç›¸å£°$", r"å°å“$", r"æ–‡åŒ–$", r"è‰ºæœ¯$"
    ],
    
    # æ¸¯æ¾³å°
    "æ¸¯æ¾³å°": [
        r"å‡¤å‡°", r"ç¿¡ç¿ ", r"æ˜ç ", r"TVB", r"ATV", r"æ¾³è§†",
        r"æ¾³é—¨", r"é¦™æ¸¯", r"å°æ¹¾", r"ä¸­å¤©", r"ä¸œæ£®", r"åè§†",
        r"æ°‘è§†", r"ä¸‰ç«‹", r"æ— çº¿"
    ],
    
    # ä½“è‚²å°
    "ä½“è‚²å°": [
        r"ä½“è‚²$", r"è¶³çƒ$", r"ç¯®çƒ$", r"NBA", r"CBA", r"è‹±è¶…",
        r"æ¬§å† $", r"é«˜å°”å¤«$", r"ç½‘çƒ$", r"ä¹’ç¾½$", r"æå‡»$",
        r"èµ›è½¦$", r"F1$", r"å¥¥è¿$", r"èµ›äº‹$"
    ],
    
    # å½±è§†å°
    "å½±è§†å°": [
        r"ç”µå½±$", r"å½±é™¢$", r"å½±è§†é¢‘é“$", r"å¥½è±å$", r"CHC",
        r"å®¶åº­å½±é™¢$", r"åŠ¨ä½œç”µå½±$", r"å–œå‰§ç”µå½±$"
    ]
}

# æ’­æ”¾å™¨å¤šæºæ”¯æŒé…ç½®
PLAYER_SUPPORT = {
    "PotPlayer": {
        "multi_source": True,
        "format": "stream-multi-url",
        "separator": "|",
        "note": "åœ¨æ’­æ”¾æ—¶æŒ‰Alt+Wå¯ä»¥åˆ‡æ¢æºï¼ŒIPv6æºä¼˜å…ˆæ’åˆ—"
    },
    "VLC": {
        "multi_source": True,
        "format": "stream-multi-url",
        "separator": "#",
        "note": "åœ¨æ’­æ”¾åˆ—è¡¨ä¸­ç‚¹å³é”®é€‰æ‹©ä¸åŒæºï¼ŒIPv6æºåœ¨å‰"
    },
    "TiviMate": {
        "multi_source": True,
        "format": "same-name",
        "separator": None,
        "note": "è‡ªåŠ¨åˆå¹¶ç›¸åŒåç§°çš„é¢‘é“ï¼Œæ’­æ”¾æ—¶è‡ªåŠ¨åˆ‡æ¢"
    },
    "Kodi": {
        "multi_source": True,
        "format": "m3u_plus",
        "separator": None,
        "note": "ä½¿ç”¨IPTV Simple Clientæ’ä»¶"
    }
}

# é»‘åå•ç®¡ç†å‡½æ•°
def load_blacklist():
    """åŠ è½½é»‘åå•"""
    if not config['ENABLE_BLACKLIST']:
        print("ğŸ“‹ é»‘åå•åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡åŠ è½½")
        return set()
    
    blacklist = set()
    if os.path.exists(BLACKLIST_FILE):
        try:
            with open(BLACKLIST_FILE, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith("#"):
                        blacklist.add(line)
            print(f"ğŸ“‹ ä» {BLACKLIST_FILE} åŠ è½½äº† {len(blacklist)} ä¸ªé»‘åå•æ¡ç›®")
        except Exception as e:
            print(f"âš ï¸  è¯»å–é»‘åå•å¤±è´¥: {e}")
    else:
        print(f"ğŸ“ {BLACKLIST_FILE} æ–‡ä»¶ä¸å­˜åœ¨")
    return blacklist

def save_to_blacklist(slow_urls, reason="å“åº”æ—¶é—´è¶…è¿‡é˜ˆå€¼"):
    """ä¿å­˜æ…¢é€ŸURLåˆ°é»‘åå•"""
    if not config['ENABLE_BLACKLIST'] or not slow_urls:
        return
    
    # åŠ è½½ç°æœ‰é»‘åå•
    existing_blacklist = load_blacklist()
    
    # æ·»åŠ æ–°çš„æ…¢é€ŸURL
    existing_blacklist.update(slow_urls)
    
    try:
        with open(BLACKLIST_FILE, "w", encoding="utf-8") as f:
            f.write("# ç›´æ’­æºé»‘åå•\n")
            f.write("# è¯¥æ–‡ä»¶åŒ…å«æµ‹è¯•å¤±è´¥çš„ç›´æ’­æº\n")
            f.write("# æ¯è¡Œä¸€ä¸ªURLï¼Œä¸‹æ¬¡æ›´æ–°æ—¶ä¼šè·³è¿‡è¿™äº›æº\n")
            f.write("# ç”Ÿæˆæ—¶é—´: " + get_beijing_time() + "\n")
            f.write(f"# è¿‡æ»¤åŸå› : {reason}\n")
            f.write(f"# é…ç½®æ–‡ä»¶: {CONFIG_FILE}\n")
            f.write(f"# é»‘åå•åŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_BLACKLIST'] else 'ç¦ç”¨'}\n\n")
            
            # æŒ‰åŸŸååˆ†ç»„æ’åº
            url_groups = {}
            for url in existing_blacklist:
                try:
                    parsed = urlparse(url)
                    domain = parsed.netloc
                    if domain not in url_groups:
                        url_groups[domain] = []
                    url_groups[domain].append(url)
                except:
                    if 'unknown' not in url_groups:
                        url_groups['unknown'] = []
                    url_groups['unknown'].append(url)
            
            # æŒ‰åŸŸåæ’åºå†™å…¥
            for domain in sorted(url_groups.keys()):
                if domain == 'unknown':
                    f.write(f"\n# æœªçŸ¥åŸŸå\n")
                else:
                    f.write(f"\n# åŸŸå: {domain}\n")
                
                for url in sorted(url_groups[domain]):
                    f.write(url + "\n")
        
        print(f"ğŸ“ å·²ä¿å­˜ {len(slow_urls)} ä¸ªæ…¢é€Ÿæºåˆ° {BLACKLIST_FILE}")
    except Exception as e:
        print(f"âŒ ä¿å­˜é»‘åå•å¤±è´¥: {e}")

def test_urls_with_progress(urls, blacklist):
    """å¹¶å‘æµ‹è¯•URLé€Ÿåº¦ï¼Œæ˜¾ç¤ºè¿›åº¦"""
    if not config['ENABLE_SPEED_TEST']:
        print("âš¡ æµ‹é€ŸåŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡é€Ÿåº¦æµ‹è¯•")
        return {}, set(), {}
    
    results = {}
    slow_urls = set()
    detailed_results = {}
    
    print(f"âš¡ å¼€å§‹æ™ºèƒ½é€Ÿåº¦æµ‹è¯•")
    print(f"ğŸ“Š é…ç½®: è¿æ¥è¶…æ—¶={config['CONNECT_TIMEOUT']}s, æµæµ‹è¯•è¶…æ—¶={config['STREAM_TIMEOUT']}s")
    print(f"ğŸ“Š éœ€è¦æµ‹è¯• {len(urls)} ä¸ªURL")
    
    # è¿‡æ»¤æ‰å·²ç»åœ¨é»‘åå•ä¸­çš„URLï¼ˆå¦‚æœé»‘åå•å¯ç”¨ï¼‰
    if config['ENABLE_BLACKLIST']:
        urls_to_test = [url for url in urls if url not in blacklist]
    else:
        urls_to_test = urls
    
    if not urls_to_test:
        print("âœ… æ‰€æœ‰URLéƒ½åœ¨é»‘åå•ä¸­ï¼Œè·³è¿‡é€Ÿåº¦æµ‹è¯•")
        return results, slow_urls, detailed_results
    
    print(f"ğŸ” å®é™…éœ€è¦æµ‹è¯• {len(urls_to_test)} ä¸ªURL")
    
    # æŒ‰URLç±»å‹åˆ†ç»„ï¼ˆM3U8ä¼˜å…ˆæµ‹è¯•ï¼‰
    m3u8_urls = []
    other_urls = []
    
    for url in urls_to_test:
        if '.m3u8' in url.lower():
            m3u8_urls.append(url)
        else:
            other_urls.append(url)
    
    print(f"  M3U8æµåª’ä½“æº: {len(m3u8_urls)} ä¸ª")
    print(f"  å…¶ä»–ç±»å‹æº: {len(other_urls)} ä¸ª")
    
    # åˆå¹¶æµ‹è¯•åˆ—è¡¨
    test_order = m3u8_urls + other_urls
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æµ‹è¯•
    with concurrent.futures.ThreadPoolExecutor(max_workers=config['MAX_WORKERS']) as executor:
        # æäº¤æ‰€æœ‰æµ‹è¯•ä»»åŠ¡
        future_to_url = {executor.submit(test_url_speed, url): url for url in test_order}
        
        # è¿›åº¦ç»Ÿè®¡
        completed = 0
        total = len(test_order)
        start_time = time.time()
        
        for future in concurrent.futures.as_completed(future_to_url):
            completed += 1
            url = future_to_url[future]
            
            try:
                result = future.result()
                detailed_results[url] = result
                
                if result['success']:
                    score = result['score']
                    results[url] = score
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæ…¢é€Ÿæº
                    if score < config['MIN_SPEED_SCORE']:
                        slow_urls.add(url)
                        speed_desc = f"è¯„åˆ†ä½({score:.2f})"
                    else:
                        speed_desc = f"è¯„åˆ†{score:.2f}"
                    
                    # æ¯æµ‹è¯•5ä¸ªURLæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                    if completed % 5 == 0 or completed == total:
                        elapsed = time.time() - start_time
                        avg_time = elapsed / completed if completed > 0 else 0
                        remaining = (total - completed) * avg_time if avg_time > 0 else 0
                        
                        print(f"  â³ {completed}/{total} ({completed/total*100:.1f}%) "
                              f"ç”¨æ—¶:{elapsed:.1f}s å‰©ä½™:{remaining:.0f}s "
                              f"æœ€æ–°:{speed_desc} {url[:50]}...")
                else:
                    slow_urls.add(url)
                    error_msg = result.get('error', 'æœªçŸ¥é”™è¯¯')
                    print(f"  âŒ å¤±è´¥: {url[:60]}... - {error_msg}")
                    
            except Exception as e:
                slow_urls.add(url)
                detailed_results[url] = {
                    'success': False,
                    'error': f"æµ‹è¯•å¼‚å¸¸: {str(e)}",
                    'score': 0.0
                }
                print(f"  âš ï¸  å¼‚å¸¸: {url[:60]}... - {str(e)[:50]}")
    
    # ç»Ÿè®¡ç»“æœ
    fast_urls = len(results)
    print(f"\nâœ… é€Ÿåº¦æµ‹è¯•å®Œæˆ")
    print(f"  å¿«é€Ÿæº: {fast_urls} ä¸ª (è¯„åˆ†â‰¥{config['MIN_SPEED_SCORE']})")
    print(f"  æ…¢é€Ÿæº: {len(slow_urls)} ä¸ª (è¯„åˆ†<{config['MIN_SPEED_SCORE']}æˆ–å¤±è´¥)")
    
    # æ˜¾ç¤ºè¯„åˆ†åˆ†å¸ƒ
    if results:
        scores = list(results.values())
        avg_score = sum(scores) / len(scores) if scores else 0
        max_score = max(scores) if scores else 0
        min_score = min(scores) if scores else 0
        
        print(f"  è¯„åˆ†ç»Ÿè®¡: å¹³å‡{avg_score:.2f}, æœ€é«˜{max_score:.2f}, æœ€ä½{min_score:.2f}")
        
        # è¯„åˆ†åˆ†æ®µç»Ÿè®¡
        score_ranges = {
            "ä¼˜ç§€(0.9-1.0)": sum(1 for s in scores if s >= 0.9),
            "è‰¯å¥½(0.7-0.9)": sum(1 for s in scores if 0.7 <= s < 0.9),
            "ä¸€èˆ¬(0.5-0.7)": sum(1 for s in scores if 0.5 <= s < 0.7),
            "è¾ƒå·®(0.0-0.5)": sum(1 for s in scores if s < 0.5)
        }
        
        print(f"  è¯„åˆ†åˆ†å¸ƒ:")
        for desc, count in score_ranges.items():
            if count > 0:
                percentage = count / len(scores) * 100
                print(f"    {desc}: {count}ä¸ª ({percentage:.1f}%)")
    
    return results, slow_urls, detailed_results

def get_beijing_time():
    """è·å–ä¸œå…«åŒºåŒ—äº¬æ—¶é—´"""
    utc_now = datetime.now(timezone.utc)
    beijing_time = utc_now.astimezone(timezone(timedelta(hours=8)))
    return beijing_time.strftime('%Y-%m-%d %H:%M:%S')

def chinese_to_arabic(chinese_num):
    """ä¸­æ–‡æ•°å­—è½¬é˜¿æ‹‰ä¼¯æ•°å­—"""
    if chinese_num in CHINESE_NUMBERS:
        return CHINESE_NUMBERS[chinese_num]
    return chinese_num

def standardize_cctv_name(name):
    """æ ‡å‡†åŒ–CCTVé¢‘é“åç§°ï¼Œç¡®ä¿CCTVå¤§å†™"""
    original_name = name
    
    # å°†cctvå°å†™è½¬ä¸ºå¤§å†™
    if 'cctv' in name.lower():
        name = re.sub(r'cctv', 'CCTV', name, flags=re.IGNORECASE)
    
    # é¦–å…ˆå°è¯•åŒ¹é…CCTV_MAPPINGä¸­çš„è§„åˆ™
    for pattern, replacement in CCTV_MAPPING.items():
        if re.match(pattern, name, re.IGNORECASE):
            if '{num}' in replacement:
                # æå–æ•°å­—éƒ¨åˆ†
                match = re.search(r'[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+', name)
                if match:
                    num = chinese_to_arabic(match.group())
                    return replacement.replace('{num}', num)
            return replacement
    
    # å¤„ç†CCTV-æ•°å­—æ ¼å¼
    cctv_match = re.match(r'^CCTV[_\-\s]?([\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)(?:\s+(.+))?$', name, re.IGNORECASE)
    if cctv_match:
        num = chinese_to_arabic(cctv_match.group(1))
        suffix = cctv_match.group(2) or ""
        
        # æ ¹æ®æ•°å­—ç¡®å®šé¢‘é“åç§°
        cctv_names = {
            '1': 'ç»¼åˆ', '2': 'è´¢ç»', '3': 'ç»¼è‰º', '4': 'ä¸­æ–‡å›½é™…',
            '5': 'ä½“è‚²', '5+': 'ä½“è‚²èµ›äº‹', '6': 'ç”µå½±', '7': 'å›½é˜²å†›äº‹',
            '8': 'ç”µè§†å‰§', '9': 'çºªå½•', '10': 'ç§‘æ•™', '11': 'æˆæ›²',
            '12': 'ç¤¾ä¼šä¸æ³•', '13': 'æ–°é—»', '14': 'å°‘å„¿', '15': 'éŸ³ä¹',
            '16': 'å¥¥æ—åŒ¹å…‹', '17': 'å†œä¸šå†œæ‘'
        }
        
        if num in cctv_names:
            channel_name = cctv_names[num]
            return f"CCTV-{num} {channel_name}"
        else:
            if suffix:
                return f"CCTV-{num} {suffix}"
            else:
                return f"CCTV-{num}"
    
    # å¤„ç†å¤®è§†å¼€å¤´
    if name.startswith('å¤®è§†'):
        match = re.match(r'^å¤®è§†([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)(?:\s+(.+))?$', name)
        if match:
            num = chinese_to_arabic(match.group(1))
            suffix = match.group(2) or ""
            return f"CCTV-{num} {suffix}"
    
    return original_name

def clean_channel_name(name):
    """æ·±åº¦æ¸…ç†é¢‘é“åç§°ï¼Œç§»é™¤å†—ä½™ä¿¡æ¯ï¼Œç»Ÿä¸€CCTVå¤§å†™"""
    original_name = name
    
    # æ·±åº¦æ¸…ç†ï¼šåº”ç”¨æ‰€æœ‰æ¸…ç†è§„åˆ™
    for pattern, replacement in CLEAN_RULES:  # ä¿®å¤ï¼šç›´æ¥éå†åˆ—è¡¨
        name = re.sub(pattern, replacement, name, flags=re.IGNORECASE)
    
    # é¢å¤–æ¸…ç†ï¼šç§»é™¤é‡å¤è¯
    name = re.sub(r'\b(\w+)(?:\s+\1)+\b', r'\1', name)
    
    # æ ‡å‡†åŒ–CCTVåç§°
    if re.match(r'^(CCTV|å¤®è§†|ä¸­å¤®ç”µè§†å°)', name, re.IGNORECASE):
        name = standardize_cctv_name(name)
    
    # ç»Ÿä¸€å«è§†å‘½å
    if name.endswith('å«è§†') and len(name) > 2:
        # ç§»é™¤å«è§†å‰çš„å¤šä½™ç©ºæ ¼
        name = re.sub(r'\s+å«è§†$', 'å«è§†', name)
    
    # å¼ºåˆ¶å°†cctvè½¬ä¸ºCCTVï¼ˆå¤§å°å†™ç»Ÿä¸€ï¼‰
    if 'cctv' in name.lower():
        name = re.sub(r'cctv', 'CCTV', name, flags=re.IGNORECASE)
    
    # æœ€ç»ˆæ¸…ç†
    name = re.sub(r'\s+', ' ', name)  # åˆå¹¶å¤šä¸ªç©ºæ ¼
    name = name.strip()
    
    # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹åç§°
    if not name or len(name) < 2:
        name = original_name
    
    return name

def get_channel_sort_key(channel_name, category):
    """è·å–é¢‘é“æ’åºé”®å€¼"""
    if category in CHANNEL_ORDER_RULES:
        if channel_name in CHANNEL_ORDER_RULES[category]:
            return (0, CHANNEL_ORDER_RULES[category][channel_name])
        else:
            # æŸ¥æ‰¾åŒ¹é…çš„æ¨¡å¼
            for pattern, order in CHANNEL_ORDER_RULES[category].items():
                if pattern in channel_name:
                    return (1, order, channel_name)
    
    # æŒ‰å­—æ¯é¡ºåºæ’åº
    return (2, channel_name)

def categorize_channel(channel_name):
    """ä¸ºé¢‘é“åˆ†ç±»ï¼Œæ”¯æŒçœä»½åˆ†ç±»"""
    # æŒ‰ä¼˜å…ˆçº§é¡ºåºåŒ¹é…åˆ†ç±»è§„åˆ™
    for category, patterns in CATEGORY_RULES.items():
        for pattern in patterns:
            try:
                if re.search(pattern, channel_name, re.IGNORECASE):
                    return category
            except re.error:
                # å¦‚æœæ­£åˆ™è¡¨è¾¾å¼æœ‰è¯¯ï¼Œå°è¯•ç›´æ¥å­—ç¬¦ä¸²åŒ¹é…
                if pattern.lower() in channel_name.lower():
                    return category
    
    # å°è¯•åŒ¹é…çœä»½åˆ†ç±»
    for province_full in PROVINCES:
        if province_full in channel_name:
            return province_full
    
    # å°è¯•åŒ¹é…çœä»½ç®€ç§°
    for abbr, full in PROVINCE_ABBR.items():
        if abbr in channel_name and len(abbr) >= 2:
            return full
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•è§„åˆ™ï¼Œè¿”å›"å…¶ä»–å°"
    return "å…¶ä»–å°"

def fetch_m3u(url, retry=2):
    """è·å–M3Uæ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•"""
    for attempt in range(retry + 1):
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "text/plain,application/x-mpegURL,*/*",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Connection": "keep-alive",
                "Cache-Control": "no-cache"
            }
            response = requests.get(url, headers=headers, timeout=15)
            response.encoding = 'utf-8'
            
            if response.status_code == 200:
                return response.text
            else:
                print(f"âŒ è·å–å¤±è´¥ {url}: HTTP {response.status_code} (å°è¯• {attempt + 1}/{retry + 1})")
                if attempt < retry:
                    time.sleep(2)
                
        except requests.exceptions.Timeout:
            print(f"âŒ è¯·æ±‚è¶…æ—¶ {url} (å°è¯• {attempt + 1}/{retry + 1})")
            if attempt < retry:
                time.sleep(2)
        except requests.exceptions.ConnectionError:
            print(f"âŒ è¿æ¥é”™è¯¯ {url} (å°è¯• {attempt + 1}/{retry + 1})")
            if attempt < retry:
                time.sleep(2)
        except Exception as e:
            print(f"âŒ è¯·æ±‚é”™è¯¯ {url}: {e} (å°è¯• {attempt + 1}/{retry + 1})")
            if attempt < retry:
                time.sleep(2)
    
    return None

def parse_channels(content, source_url):
    """è§£æM3Uå†…å®¹ï¼Œè¿”å›é¢‘é“åˆ—è¡¨"""
    channels = []
    lines = content.split('\n')
    i = 0
    
    while i < len(lines):
        line = lines[i].strip()
        if line.startswith('#EXTINF:'):
            # æå–é¢‘é“åç§°
            name = "æœªçŸ¥é¢‘é“"
            match = re.search(r',([^,\n]+)$', line)
            if match:
                name = match.group(1).strip()
            
            # æå–åˆ†ç»„
            group = None
            match = re.search(r'group-title="([^"]+)"', line)
            if match:
                group = match.group(1).strip()
            
            # æå–logo
            logo = None
            match = re.search(r'tvg-logo="([^"]+)"', line)
            if match:
                logo = match.group(1).strip()
            
            # æå–æ¸…æ™°åº¦ä¿¡æ¯
            quality = "æœªçŸ¥"
            if re.search(r'4K|è¶…æ¸…|UHD|2160', name, re.IGNORECASE):
                quality = "4K"
            elif re.search(r'é«˜æ¸…|HD|1080|FHD', name, re.IGNORECASE):
                quality = "é«˜æ¸…"
            elif re.search(r'æ ‡æ¸…|SD|720', name, re.IGNORECASE):
                quality = "æ ‡æ¸…"
            elif re.search(r'æµç•…|360|480', name, re.IGNORECASE):
                quality = "æµç•…"
            
            # è·å–URL
            if i + 1 < len(lines):
                url = lines[i + 1].strip()
                if url and not url.startswith('#'):
                    # æ·±åº¦æ¸…ç†é¢‘é“åç§°
                    clean_name = clean_channel_name(name)
                    
                    channels.append({
                        'original_name': name,
                        'clean_name': clean_name,
                        'url': url,
                        'group': group,
                        'logo': logo,
                        'quality': quality,
                        'source': source_url,
                        'extinf_line': line
                    })
                    i += 1
        i += 1
    
    return channels

def merge_channels(all_channels, speed_test_results=None):
    """åˆå¹¶åŒåç”µè§†å°ï¼Œæ”¯æŒå¤šæºï¼ŒIPv6ä¼˜å…ˆæ’åºï¼Œè¿‡æ»¤é»‘åå•"""
    merged = {}
    
    for channel in all_channels:
        key = channel['clean_name']
        
        if key not in merged:
            # åˆ›å»ºæ–°çš„åˆå¹¶é¢‘é“
            merged[key] = {
                'clean_name': key,
                'original_names': [channel['original_name']],
                'sources': [{
                    'url': channel['url'],
                    'quality': channel['quality'],
                    'source': channel['source'],
                    'logo': channel['logo'],
                    'priority': 0,  # ç¨åè®¡ç®—
                    'is_ipv6': is_ipv6_url(channel['url']),
                    'speed_score': speed_test_results.get(channel['url'], {}).get('score', 0.0) if speed_test_results else 0.0,
                    'test_details': speed_test_results.get(channel['url'], {}) if speed_test_results else {}
                }],
                'logos': [],
                'categories': set(),
                'first_seen': channel
            }
            
            # æ”¶é›†logo
            if channel['logo']:
                merged[key]['logos'].append(channel['logo'])
            
            # ç¡®å®šåˆ†ç±»
            category = categorize_channel(key)
            merged[key]['categories'].add(category)
        else:
            # æ·»åŠ åˆ°ç°æœ‰é¢‘é“
            merged[key]['original_names'].append(channel['original_name'])
            
            # æ£€æŸ¥URLæ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤
            urls = [s['url'] for s in merged[key]['sources']]
            if channel['url'] not in urls:
                merged[key]['sources'].append({
                    'url': channel['url'],
                    'quality': channel['quality'],
                    'source': channel['source'],
                    'logo': channel['logo'],
                    'priority': 0,
                    'is_ipv6': is_ipv6_url(channel['url']),
                    'speed_score': speed_test_results.get(channel['url'], {}).get('score', 0.0) if speed_test_results else 0.0,
                    'test_details': speed_test_results.get(channel['url'], {}) if speed_test_results else {}
                })
            
            # æ”¶é›†logo
            if channel['logo'] and channel['logo'] not in merged[key]['logos']:
                merged[key]['logos'].append(channel['logo'])
            
            # æ›´æ–°åˆ†ç±»
            category = categorize_channel(key)
            merged[key]['categories'].add(category)
    
    # ä¸ºæ¯ä¸ªé¢‘é“çš„æºè®¡ç®—ä¼˜å…ˆçº§å¹¶æ’åº
    for key in merged:
        for source in merged[key]['sources']:
            source['priority'] = get_source_priority(source)
        
        # æŒ‰ä¼˜å…ˆçº§é™åºæ’åº
        merged[key]['sources'].sort(key=lambda x: x['priority'], reverse=True)
        
        # ä¸ºæ¯ä¸ªåˆå¹¶åçš„é¢‘é“é€‰æ‹©ä¸€ä¸ªä¸»åˆ†ç±»
        categories = list(merged[key]['categories'])
        if categories:
            non_other = [c for c in categories if c != "å…¶ä»–å°"]
            if non_other:
                merged[key]['category'] = non_other[0]
            else:
                merged[key]['category'] = "å…¶ä»–å°"
        else:
            merged[key]['category'] = "å…¶ä»–å°"
    
    return merged

def generate_multi_source_m3u(merged_channels, categories, final_category_order, timestamp, output_file, mode="multi"):
    """
    ç”Ÿæˆæ”¯æŒå¤šæºçš„M3Uæ–‡ä»¶
    mode: 
      "multi" - å¤šæºåˆå¹¶æˆä¸€ä¸ªæ¡ç›®ï¼ˆPotPlayeræ ¼å¼ï¼‰
      "separate" - æ¯ä¸ªæºåˆ†å¼€æ¡ç›®ä½†ç›¸åŒåç§°
      "single" - åªä¿ç•™æœ€ä½³æº
    """
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
            if mode == "multi":
                f.write(f"# ç”µè§†ç›´æ’­æº - IPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ\n")
                f.write(f"# æ¯ä¸ªç”µè§†å°åªæ˜¾ç¤ºä¸€ä¸ªæ¡ç›®ï¼ŒIPv6æºä¼˜å…ˆæ’åˆ—\n")
                f.write(f"# æ’­æ”¾å™¨åˆ‡æ¢æºæ–¹æ³•ï¼šPotPlayeræŒ‰Alt+Wï¼ŒVLCå³é”®é€‰æ‹©æº\n")
                f.write(f"# æ’åºè§„åˆ™ï¼šIPv6æº > 4K > é«˜æ¸… > æ ‡æ¸… > æµç•…\n")
            elif mode == "separate":
                f.write(f"# ç”µè§†ç›´æ’­æº - IPv6ä¼˜å…ˆå¤šæºåˆ†ç¦»ç‰ˆ\n")
                f.write(f"# åŒåç”µè§†å°æ˜¾ç¤ºä¸ºå¤šä¸ªæ¡ç›®ï¼ŒIPv6æºä¼˜å…ˆï¼Œæ’­æ”¾å™¨è‡ªåŠ¨åˆå¹¶\n")
            else:
                f.write(f"# ç”µè§†ç›´æ’­æº - IPv6ä¼˜å…ˆç²¾ç®€ç‰ˆ\n")
                f.write(f"# æ¯ä¸ªç”µè§†å°åªä¿ç•™æœ€ä½³æºï¼ˆIPv6ä¼˜å…ˆï¼‰\n")
            
            f.write(f"# æ›´æ–°æ—¶é—´(åŒ—äº¬æ—¶é—´): {timestamp}\n")
            f.write(f"# ç”µè§†å°æ€»æ•°: {len(merged_channels)}\n")
            f.write(f"# æ•°æ®æº: {len(sources)} ä¸ª (æˆåŠŸ: {success_sources}, å¤±è´¥: {len(failed_sources)})\n")
            f.write(f"# ç‰¹ç‚¹: ç§»é™¤æŠ€æœ¯å‚æ•°ï¼Œç»Ÿä¸€å¤®è§†é¢‘é“å‘½åï¼ŒæŒ‰çœä»½åˆ†ç±»åœ°æ–¹å°ï¼ŒIPv6ä¼˜å…ˆ\n")
            f.write(f"# é…ç½®æ–‡ä»¶: {CONFIG_FILE}\n")
            f.write(f"# é»‘åå•åŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_BLACKLIST'] else 'ç¦ç”¨'}\n")
            f.write(f"# æµ‹é€ŸåŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_SPEED_TEST'] else 'ç¦ç”¨'}\n")
            
            if config['ENABLE_SPEED_TEST']:
                f.write(f"# å·²è¿‡æ»¤ä½è´¨é‡æºï¼ˆè¯„åˆ† < {config['MIN_SPEED_SCORE']}ï¼‰\n")
            
            f.write(f"# æºæ–‡ä»¶: sources.txt\n")
            if config['ENABLE_BLACKLIST']:
                f.write(f"# é»‘åå•: {BLACKLIST_FILE}\n")
            f.write("\n")
            
            # æŒ‰åˆ†ç±»é¡ºåºå†™å…¥
            for category in final_category_order:
                cat_channels = categories[category]
                if cat_channels:
                    # å¯¹é¢‘é“è¿›è¡Œæ’åº
                    sorted_channels = sorted(
                        cat_channels,
                        key=lambda x: get_channel_sort_key(x['clean_name'], category)
                    )
                    
                    f.write(f"\n# åˆ†ç±»: {category} ({len(cat_channels)}ä¸ªç”µè§†å°)\n")
                    
                    for channel in sorted_channels:
                        # é€‰æ‹©ä¸»logoï¼ˆç¬¬ä¸€ä¸ªéç©ºçš„logoï¼‰
                        main_logo = channel['logos'][0] if channel['logos'] else ""
                        source_count = len(channel['sources'])
                        
                        # ç»Ÿè®¡IPv6æºæ•°é‡
                        ipv6_count = sum(1 for s in channel['sources'] if s.get('is_ipv6', False))
                        
                        # ç»Ÿè®¡é«˜è´¨é‡æºæ•°é‡ï¼ˆè¯„åˆ†â‰¥0.7ï¼‰
                        high_quality_sources = [s for s in channel['sources'] if s.get('speed_score', 0) >= 0.7]
                        high_quality_count = len(high_quality_sources)
                        
                        if mode == "multi":
                            # PotPlayer/VLCå¤šæºæ ¼å¼ï¼šä¸€ä¸ªæ¡ç›®åŒ…å«å¤šä¸ªURLï¼Œç”¨"|"åˆ†éš”
                            source_desc = []
                            if ipv6_count > 0:
                                source_desc.append(f"{ipv6_count}IPv6")
                            if high_quality_count > 0 and config['ENABLE_SPEED_TEST']:
                                source_desc.append(f"{high_quality_count}é«˜é€Ÿ")
                            if source_count > ipv6_count:
                                source_desc.append(f"{source_count}æº")
                            
                            if source_desc:
                                display_name = f"{channel['clean_name']} [{'+'.join(source_desc)}]"
                            else:
                                display_name = f"{channel['clean_name']} [{source_count}æº]"
                            
                            # æ”¶é›†æ‰€æœ‰URLï¼ˆå·²æŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
                            urls = []
                            qualities = []
                            ipv6_sources = []
                            ipv4_sources = []
                            
                            for source in channel['sources']:
                                if source.get('is_ipv6', False):
                                    ipv6_sources.append(source)
                                else:
                                    ipv4_sources.append(source)
                            
                            # ç¡®ä¿IPv6æºåœ¨å‰é¢
                            sorted_sources = ipv6_sources + ipv4_sources
                            
                            for source in sorted_sources:
                                urls.append(source['url'])
                                if source['quality'] != "æœªçŸ¥":
                                    qualities.append(source['quality'])
                            
                            # ç”Ÿæˆå¤šæºURL
                            multi_url = "|".join(urls)
                            
                            # å†™å…¥æ¡ç›®
                            line = "#EXTINF:-1"
                            line += f' tvg-name="{channel["clean_name"]}"'
                            line += f' group-title="{category}"'
                            if main_logo:
                                line += f' tvg-logo="{main_logo}"'
                            if qualities:
                                quality_desc = "/".join(sorted(set(qualities), key=lambda x: ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"].index(x) if x in ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"] else 10))
                                line += f' tvg-quality="{quality_desc}"'
                            if ipv6_count > 0:
                                line += f' tvg-ipv6="true"'
                            line += f',{display_name}\n'
                            line += f"{multi_url}\n"
                            f.write(line)
                            
                        elif mode == "separate":
                            # TiviMate/Kodiæ ¼å¼ï¼šç›¸åŒåç§°çš„å¤šä¸ªæ¡ç›®ï¼ŒIPv6æºä¼˜å…ˆ
                            display_name = channel['clean_name']
                            
                            # åˆ†ç¦»IPv6å’ŒIPv4æº
                            ipv6_sources = []
                            ipv4_sources = []
                            for source in channel['sources']:
                                if source.get('is_ipv6', False):
                                    ipv6_sources.append(source)
                                else:
                                    ipv4_sources.append(source)
                            
                            # ç¡®ä¿IPv6æºåœ¨å‰é¢
                            sorted_sources = ipv6_sources + ipv4_sources
                            
                            for i, source in enumerate(sorted_sources, 1):
                                source_type = "IPv6" if source.get('is_ipv6', False) else "IPv4"
                                speed_info = ""
                                if source.get('speed_score') and config['ENABLE_SPEED_TEST']:
                                    speed_info = f" ({source['speed_score']:.2f})"
                                
                                line = "#EXTINF:-1"
                                line += f' tvg-name="{channel["clean_name"]}"'
                                line += f' group-title="{category}"'
                                if main_logo:
                                    line += f' tvg-logo="{main_logo}"'
                                if source['quality'] != "æœªçŸ¥":
                                    line += f' tvg-quality="{source["quality"]}"'
                                if source.get('is_ipv6', False):
                                    line += f' tvg-ipv6="true"'
                                if source_count > 1:
                                    line += f',{display_name} [{source_type}æº{i}{speed_info}]\n'
                                else:
                                    line += f',{display_name}{speed_info}\n'
                                line += f"{source['url']}\n"
                                f.write(line)
                                
                        else:  # mode == "single"
                            # ç²¾ç®€ç‰ˆï¼šåªä¿ç•™æœ€ä½³æºï¼ˆIPv6ä¼˜å…ˆï¼‰
                            display_name = channel['clean_name']
                            
                            # é€‰æ‹©æœ€ä½³æºï¼ˆä¼˜å…ˆé€‰æ‹©IPv6å¿«é€Ÿæºï¼‰
                            best_source = None
                            
                            # å¦‚æœæµ‹é€ŸåŠŸèƒ½å¯ç”¨ï¼Œä¼˜å…ˆé€‰æ‹©é«˜é€Ÿæº
                            if config['ENABLE_SPEED_TEST']:
                                # é¦–å…ˆæ‰¾IPv6é«˜é€Ÿæºï¼ˆè¯„åˆ†â‰¥0.7ï¼‰
                                for source in channel['sources']:
                                    if source.get('is_ipv6', False) and source.get('speed_score', 0) >= 0.7:
                                        best_source = source
                                        break
                                
                                # ç„¶åæ‰¾IPv4é«˜é€Ÿæº
                                if not best_source:
                                    for source in channel['sources']:
                                        if not source.get('is_ipv6', False) and source.get('speed_score', 0) >= 0.7:
                                            best_source = source
                                            break
                            
                            # å¦‚æœæ²¡æ‰¾åˆ°é«˜é€Ÿæºæˆ–æµ‹é€Ÿç¦ç”¨ï¼ŒæŒ‰é»˜è®¤è§„åˆ™é€‰æ‹©
                            if not best_source:
                                # é¦–å…ˆæ‰¾IPv6é«˜æ¸…æº
                                for source in channel['sources']:
                                    if source.get('is_ipv6', False) and source['quality'] == "é«˜æ¸…":
                                        best_source = source
                                        break
                                
                                # ç„¶åæ‰¾IPv4é«˜æ¸…æº
                                if not best_source:
                                    for source in channel['sources']:
                                        if not source.get('is_ipv6', False) and source['quality'] == "é«˜æ¸…":
                                            best_source = source
                                            break
                                
                                # æœ€åé€‰ç¬¬ä¸€ä¸ªæº
                                if not best_source:
                                    best_source = channel['sources'][0]
                            
                            line = "#EXTINF:-1"
                            line += f' tvg-name="{channel["clean_name"]}"'
                            line += f' group-title="{category}"'
                            if main_logo:
                                line += f' tvg-logo="{main_logo}"'
                            if best_source['quality'] != "æœªçŸ¥":
                                line += f' tvg-quality="{best_source["quality"]}"'
                            if best_source.get('is_ipv6', False):
                                line += f' tvg-ipv6="true"'
                                display_name = f"{display_name} [IPv6]"
                            if best_source.get('speed_score') and config['ENABLE_SPEED_TEST']:
                                line += f' tvg-score="{best_source["speed_score"]:.2f}"'
                                display_name = f"{display_name} ({best_source['speed_score']:.2f})"
                            line += f',{display_name}\n'
                            line += f"{best_source['url']}\n"
                            f.write(line)
        
        print(f"  âœ… {output_file} ç”ŸæˆæˆåŠŸ")
        return True
    except Exception as e:
        print(f"  âŒ ç”Ÿæˆ{output_file}å¤±è´¥: {e}")
        return False

# ä¸»æ”¶é›†è¿‡ç¨‹
print("ğŸš€ å¼€å§‹é‡‡é›†ç”µè§†ç›´æ’­æº...")

# 1. åŠ è½½é»‘åå•
print("ğŸ“‹ åŠ è½½é»‘åå•...")
blacklist = load_blacklist()

print(f"ğŸ“‹ æ•°æ®æºåˆ—è¡¨ (ä»sources.txtåŠ è½½):")
for i, source in enumerate(sources, 1):
    print(f"  {i:2d}. {source}")

all_channels = []
success_sources = 0
failed_sources = []

# 2. æ”¶é›†æ‰€æœ‰é¢‘é“çš„åŸå§‹æ•°æ®
print("\nğŸ“¡ å¼€å§‹æ”¶é›†é¢‘é“æ•°æ®...")
for idx, source_url in enumerate(sources, 1):
    print(f"\n[{idx}/{len(sources)}] å¤„ç†: {source_url}")
    
    content = fetch_m3u(source_url)
    if not content:
        failed_sources.append(source_url)
        print("   âŒ æ— æ³•è·å–å†…å®¹ï¼Œè·³è¿‡")
        continue
    
    channels = parse_channels(content, source_url)
    
    # ç»Ÿè®¡é¢‘é“åç§°å˜åŒ–
    changed_count = 0
    for channel in channels:
        if channel['original_name'] != channel['clean_name']:
            changed_count += 1
    
    print(f"   âœ… è§£æåˆ° {len(channels)} ä¸ªé¢‘é“ ({changed_count}ä¸ªå·²ç²¾ç®€)")
    
    if changed_count > 0 and len(channels) <= 10:
        for channel in channels[:5]:
            if channel['original_name'] != channel['clean_name']:
                print(f"      '{channel['original_name']}' -> '{channel['clean_name']}'")
    
    all_channels.extend(channels)
    success_sources += 1
    
    # é¿å…è¯·æ±‚è¿‡å¿«
    if idx < len(sources):
        time.sleep(1)

print(f"\n{'='*50}")
print(f"âœ… é‡‡é›†å®Œæˆç»Ÿè®¡:")
print(f"   æˆåŠŸæºæ•°: {success_sources}/{len(sources)}")
print(f"   å¤±è´¥æºæ•°: {len(failed_sources)}")
print(f"   æ€»è®¡é‡‡é›†: {len(all_channels)} ä¸ªåŸå§‹é¢‘é“")

if len(failed_sources) > 0:
    print(f"\nâš ï¸  å¤±è´¥çš„æº:")
    for failed in failed_sources:
        print(f"   - {failed}")

if len(all_channels) == 0:
    print("\nâŒ æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•é¢‘é“ï¼Œé€€å‡º")
    sys.exit(1)

# 3. æå–æ‰€æœ‰å”¯ä¸€çš„URLè¿›è¡Œé€Ÿåº¦æµ‹è¯•
print("\nğŸ“Š æå–æ‰€æœ‰å”¯ä¸€URL...")
all_urls = set()
for channel in all_channels:
    all_urls.add(channel['url'])

print(f"   å‘ç° {len(all_urls)} ä¸ªå”¯ä¸€URL")

# 4. è¿›è¡Œæ™ºèƒ½é€Ÿåº¦æµ‹è¯•
print("\nâš¡ å¼€å§‹æ™ºèƒ½é€Ÿåº¦æµ‹è¯•...")
speed_test_results, slow_urls, detailed_results = test_urls_with_progress(all_urls, blacklist)

# 5. ä¿å­˜å¤±è´¥å’Œä½è´¨é‡URLåˆ°é»‘åå•
if slow_urls and config['ENABLE_BLACKLIST'] and config['ENABLE_SPEED_TEST']:
    # åˆ†æå¤±è´¥åŸå› 
    error_types = {}
    for url in slow_urls:
        result = detailed_results.get(url, {})
        error = result.get('error', 'è¯„åˆ†è¿‡ä½')
        error_types[error] = error_types.get(error, 0) + 1
    
    print(f"\nğŸ“Š å¤±è´¥åŸå› åˆ†æ:")
    for error, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
        print(f"  {error}: {count}ä¸ª")
    
    reason = "è¯„åˆ†è¿‡ä½æˆ–è¿æ¥å¤±è´¥"
    if error_types:
        main_error = max(error_types.items(), key=lambda x: x[1])[0]
        reason = f"ä¸»è¦å¤±è´¥åŸå› : {main_error}"
    
    print(f"\nğŸ“ å‘ç° {len(slow_urls)} ä¸ªä½è´¨é‡æºï¼Œä¿å­˜åˆ°é»‘åå•...")
    save_to_blacklist(slow_urls, reason)
elif slow_urls:
    print(f"\nâš ï¸  å‘ç° {len(slow_urls)} ä¸ªä½è´¨é‡æºï¼Œä½†é»‘åå•æˆ–æµ‹é€ŸåŠŸèƒ½å·²ç¦ç”¨ï¼Œä¸ä¿å­˜")

# 6. è¿‡æ»¤æ‰é»‘åå•ä¸­çš„é¢‘é“ï¼ˆå¦‚æœé»‘åå•å¯ç”¨ï¼‰
print("\nğŸš« è¿‡æ»¤é»‘åå•ä¸­çš„é¢‘é“...")
filtered_channels = []
blacklisted_count = 0

for channel in all_channels:
    if config['ENABLE_BLACKLIST'] and (channel['url'] in blacklist or channel['url'] in slow_urls):
        blacklisted_count += 1
    else:
        filtered_channels.append(channel)

print(f"   åŸå§‹é¢‘é“æ•°: {len(all_channels)}")
print(f"   è¿‡æ»¤åé¢‘é“æ•°: {len(filtered_channels)}")
print(f"   é»‘åå•è¿‡æ»¤æ•°: {blacklisted_count}")

if len(filtered_channels) == 0:
    print("\nâŒ æ‰€æœ‰é¢‘é“éƒ½è¢«é»‘åå•è¿‡æ»¤ï¼Œé€€å‡º")
    sys.exit(1)

# 7. åˆå¹¶åŒåç”µè§†å°
print("\nğŸ”„ æ­£åœ¨åˆå¹¶åŒåç”µè§†å°...")
merged_channels = merge_channels(filtered_channels, detailed_results)
print(f"   åˆå¹¶å: {len(merged_channels)} ä¸ªå”¯ä¸€ç”µè§†å°")

# 8. æ˜¾ç¤ºå¤šæºç»Ÿè®¡å’ŒIPv6ç»Ÿè®¡
multi_source_count = sum(1 for c in merged_channels.values() if len(c['sources']) > 1)
single_source_count = len(merged_channels) - multi_source_count
ipv6_channel_count = sum(1 for c in merged_channels.values() if any(s.get('is_ipv6', False) for s in c['sources']))
high_quality_channel_count = sum(1 for c in merged_channels.values() if any(s.get('speed_score', 0) >= 0.7 for s in c['sources']))

print(f"   å¤šæºç”µè§†å°: {multi_source_count} ä¸ª")
print(f"   å•æºç”µè§†å°: {single_source_count} ä¸ª")
print(f"   å«IPv6æºç”µè§†å°: {ipv6_channel_count} ä¸ª")
if config['ENABLE_SPEED_TEST']:
    print(f"   å«é«˜è´¨é‡æºç”µè§†å°: {high_quality_channel_count} ä¸ª")

# æ˜¾ç¤ºä¸€äº›å¤šæºç¤ºä¾‹
print("\nğŸ“ IPv6å¤šæºç”µè§†å°ç¤ºä¾‹:")
ipv6_multi_examples = [(k, v) for k, v in merged_channels.items() 
                      if any(s.get('is_ipv6', False) for s in v['sources'])][:5]
for clean_name, data in ipv6_multi_examples:
    source_count = len(data['sources'])
    ipv6_count = sum(1 for s in data['sources'] if s.get('is_ipv6', False))
    high_quality_count = sum(1 for s in data['sources'] if s.get('speed_score', 0) >= 0.7)
    qualities = [s['quality'] for s in data['sources']]
    quality_desc = "/".join(set(qualities))
    quality_info = f" é«˜è´¨é‡æº:{high_quality_count}" if config['ENABLE_SPEED_TEST'] else ""
    print(f"   {clean_name}: {ipv6_count}IPv6+{source_count-ipv6_count}IPv4 [{quality_desc}]{quality_info}")

# 9. ç»Ÿè®¡åˆ†ç±»æ•°é‡
category_stats = {}
for channel in merged_channels.values():
    category = channel['category']
    if category in category_stats:
        category_stats[category] += 1
    else:
        category_stats[category] = 1

print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
for category, count in sorted(category_stats.items()):
    print(f"   {category}: {count} ä¸ªç”µè§†å°")

# 10. ç”Ÿæˆæ–‡ä»¶ - ä½¿ç”¨åŒ—äº¬æ—¶é—´
timestamp = get_beijing_time()
print(f"\nğŸ“… å½“å‰åŒ—äº¬æ—¶é—´: {timestamp}")

# 11. æŒ‰åˆ†ç±»ç»„ç»‡é¢‘é“
categories = {}
for channel in merged_channels.values():
    category = channel['category']
    if category not in categories:
        categories[category] = []
    categories[category].append(channel)

# ç¡®å®šåˆ†ç±»é¡ºåºï¼ˆå›ºå®šåˆ†ç±»åœ¨å‰ï¼Œçœä»½åˆ†ç±»åœ¨åï¼ŒæŒ‰æ‹¼éŸ³æ’åºï¼‰
fixed_categories = ["å¤®è§†", "å«è§†", "æ™¯åŒºé¢‘é“", "å°‘å„¿å°", "ç»¼è‰ºå°", 
                   "æ¸¯æ¾³å°", "ä½“è‚²å°", "å½±è§†å°", "å…¶ä»–å°"]

# åˆ†ç¦»çœä»½åˆ†ç±»
province_categories = []
other_categories = []
for category in categories.keys():
    if category in fixed_categories:
        continue
    elif category in PROVINCES or any(province in category for province in PROVINCES):
        province_categories.append(category)
    else:
        other_categories.append(category)

# æŒ‰æ‹¼éŸ³æ’åºçœä»½åˆ†ç±»
province_categories.sort()

# æœ€ç»ˆåˆ†ç±»é¡ºåº
final_category_order = fixed_categories + province_categories + other_categories

# ç¡®ä¿æ¯ä¸ªåˆ†ç±»éƒ½å­˜åœ¨ï¼ˆå³ä½¿ä¸ºç©ºï¼‰
for category in final_category_order:
    if category not in categories:
        categories[category] = []

# åˆ›å»ºè¾“å‡ºç›®å½•
Path("categories").mkdir(exist_ok=True)
Path("merged").mkdir(exist_ok=True)

print("\nğŸ¯ æ’­æ”¾å™¨å¤šæºæ”¯æŒä¿¡æ¯:")
for player, info in PLAYER_SUPPORT.items():
    if info['multi_source']:
        print(f"   âœ… {player}: {info['note']}")

# 12. ç”Ÿæˆå¤šæºåˆå¹¶ç‰ˆM3Uï¼ˆPotPlayer/VLCæ ¼å¼ï¼‰
print("\nğŸ“„ ç”Ÿæˆ live_sources.m3uï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ - PotPlayer/VLCæ ¼å¼ï¼‰...")
generate_multi_source_m3u(
    merged_channels, categories, final_category_order, 
    timestamp, "live_sources.m3u", mode="multi"
)

# 13. ç”Ÿæˆå¤šæºåˆ†ç¦»ç‰ˆM3Uï¼ˆTiviMate/Kodiæ ¼å¼ï¼‰
print("\nğŸ“„ ç”Ÿæˆ merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3uï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆ†ç¦»ç‰ˆ - TiviMate/Kodiæ ¼å¼ï¼‰...")
generate_multi_source_m3u(
    merged_channels, categories, final_category_order,
    timestamp, "merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3u", mode="separate"
)

# 14. ç”Ÿæˆç²¾ç®€ç‰ˆM3Uï¼ˆæ¯ä¸ªç”µè§†å°åªä¿ç•™æœ€ä½³æºï¼‰
print("\nğŸ“„ ç”Ÿæˆ merged/ç²¾ç®€ç‰ˆ.m3uï¼ˆIPv6ä¼˜å…ˆå•æºç²¾ç®€ç‰ˆï¼‰...")
generate_multi_source_m3u(
    merged_channels, categories, final_category_order,
    timestamp, "merged/ç²¾ç®€ç‰ˆ.m3u", mode="single"
)

# 15. ç”Ÿæˆåˆ†ç±»M3Uæ–‡ä»¶ï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶æ ¼å¼ï¼‰
print("\nğŸ“„ ç”Ÿæˆåˆ†ç±»æ–‡ä»¶ï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶æ ¼å¼ï¼‰...")
for category in final_category_order:
    cat_channels = categories[category]
    if cat_channels:
        try:
            # å¯¹é¢‘é“è¿›è¡Œæ’åº
            sorted_channels = sorted(
                cat_channels,
                key=lambda x: get_channel_sort_key(x['clean_name'], category)
            )
            
            # åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å
            safe_category_name = category.replace('/', '_').replace('\\', '_')
            filename = f"categories/{safe_category_name}.m3u"
            
            with open(filename, "w", encoding="utf-8") as f:
                f.write("#EXTM3U\n")
                f.write(f"# {category}é¢‘é“åˆ—è¡¨ï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆï¼‰\n")
                f.write(f"# æ›´æ–°æ—¶é—´(åŒ—äº¬æ—¶é—´): {timestamp}\n")
                f.write(f"# ç”µè§†å°æ•°é‡: {len(cat_channels)}\n")
                f.write(f"# è¯´æ˜: æ¯ä¸ªç”µè§†å°åŒ…å«å¤šä¸ªæºï¼ŒIPv6æºä¼˜å…ˆï¼ŒPotPlayeræŒ‰Alt+Wåˆ‡æ¢\n")
                if config['ENABLE_SPEED_TEST']:
                    f.write(f"# å·²è¿‡æ»¤ä½è´¨é‡æºï¼ˆè¯„åˆ† < {config['MIN_SPEED_SCORE']}ï¼‰\n")
                f.write(f"# é…ç½®æ–‡ä»¶: {CONFIG_FILE}\n")
                f.write(f"# é»‘åå•åŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_BLACKLIST'] else 'ç¦ç”¨'}\n")
                f.write(f"# æµ‹é€ŸåŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_SPEED_TEST'] else 'ç¦ç”¨'}\n\n")
                
                for channel in sorted_channels:
                    # é€‰æ‹©ä¸»logoï¼ˆç¬¬ä¸€ä¸ªéç©ºçš„logoï¼‰
                    main_logo = channel['logos'][0] if channel['logos'] else ""
                    source_count = len(channel['sources'])
                    
                    # ç»Ÿè®¡IPv6æºæ•°é‡
                    ipv6_count = sum(1 for s in channel['sources'] if s.get('is_ipv6', False))
                    
                    # PotPlayer/VLCå¤šæºæ ¼å¼
                    source_desc = []
                    if ipv6_count > 0:
                        source_desc.append(f"{ipv6_count}IPv6")
                    if source_count > ipv6_count:
                        source_desc.append(f"{source_count-ipv6_count}IPv4")
                    
                    if source_desc:
                        display_name = f"{channel['clean_name']} [{'+'.join(source_desc)}]"
                    else:
                        display_name = f"{channel['clean_name']} [{source_count}æº]"
                    
                    # æ”¶é›†æ‰€æœ‰URLï¼ˆIPv6ä¼˜å…ˆï¼‰
                    urls = []
                    qualities = []
                    ipv6_sources = []
                    ipv4_sources = []
                    
                    for source in channel['sources']:
                        if source.get('is_ipv6', False):
                            ipv6_sources.append(source)
                        else:
                            ipv4_sources.append(source)
                    
                    # ç¡®ä¿IPv6æºåœ¨å‰é¢
                    sorted_sources = ipv6_sources + ipv4_sources
                    
                    for source in sorted_sources:
                        urls.append(source['url'])
                        if source['quality'] != "æœªçŸ¥":
                            qualities.append(source['quality'])
                    
                    # ç”Ÿæˆå¤šæºURL
                    multi_url = "|".join(urls)
                    
                    # å†™å…¥æ¡ç›®
                    line = "#EXTINF:-1"
                    line += f' tvg-name="{channel["clean_name"]}"'
                    line += f' group-title="{category}"'
                    if main_logo:
                        line += f' tvg-logo="{main_logo}"'
                    if qualities:
                        quality_desc = "/".join(sorted(set(qualities), key=lambda x: ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"].index(x) if x in ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"] else 10))
                        line += f' tvg-quality="{quality_desc}"'
                    if ipv6_count > 0:
                        line += f' tvg-ipv6="true"'
                    line += f',{display_name}\n'
                    line += f"{multi_url}\n"
                    f.write(line)
            
            print(f"  âœ… ç”Ÿæˆ {filename}")
        except Exception as e:
            print(f"  âŒ ç”Ÿæˆ {filename} å¤±è´¥: {e}")

# 16. ç”Ÿæˆåˆå¹¶çš„JSONæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰æºä¿¡æ¯ï¼‰
print("\nğŸ“„ ç”Ÿæˆ channels.json...")
try:
    # åˆ›å»ºé¢‘é“åˆ—è¡¨
    channel_list = []
    for clean_name, channel_data in sorted(merged_channels.items()):
        # å‡†å¤‡æºä¿¡æ¯
        sources_info = []
        for i, source in enumerate(channel_data['sources'], 1):
            sources_info.append({
                'index': i,
                'url': source['url'],
                'quality': source['quality'],
                'source': source['source'],
                'logo': source['logo'] if source['logo'] else "",
                'is_ipv6': source.get('is_ipv6', False),
                'priority': source.get('priority', 0),
                'speed_score': source.get('speed_score', 0.0),
                'test_details': source.get('test_details', {})
            })
        
        # ç»Ÿè®¡IPv6æºæ•°é‡
        ipv6_count = sum(1 for s in sources_info if s.get('is_ipv6', False))
        
        # ç»Ÿè®¡é«˜è´¨é‡æºæ•°é‡
        high_quality_count = sum(1 for s in sources_info if s.get('speed_score', 0) >= 0.7)
        
        # é¢‘é“ä¿¡æ¯
        channel_info = {
            'clean_name': clean_name,
            'original_names': list(set(channel_data['original_names'])),  # å»é‡
            'category': channel_data['category'],
            'source_count': len(channel_data['sources']),
            'ipv6_source_count': ipv6_count,
            'high_quality_source_count': high_quality_count,
            'logos': channel_data['logos'],
            'sources': sources_info
        }
        channel_list.append(channel_info)
    
    # é»‘åå•ç»Ÿè®¡
    blacklist_stats = {
        'total_blacklisted': len(blacklist) + len(slow_urls),
        'previously_blacklisted': len(blacklist),
        'newly_blacklisted': len(slow_urls)
    }
    
    # åˆ›å»ºJSONæ•°æ®
    json_data = {
        'last_updated': timestamp,
        'config': {
            'enable_blacklist': config['ENABLE_BLACKLIST'],
            'enable_speed_test': config['ENABLE_SPEED_TEST'],
            'connect_timeout': config['CONNECT_TIMEOUT'],
            'stream_timeout': config['STREAM_TIMEOUT'],
            'min_speed_score': config['MIN_SPEED_SCORE'],
            'max_workers': config['MAX_WORKERS']
        },
        'total_channels': len(merged_channels),
        'original_channel_count': len(all_channels),
        'filtered_channel_count': len(filtered_channels),
        'blacklisted_channel_count': blacklisted_count,
        'sources_count': len(sources),
        'success_sources': success_sources,
        'failed_sources': failed_sources,
        'multi_source_channels': multi_source_count,
        'single_source_channels': single_source_count,
        'ipv6_channels': ipv6_channel_count,
        'high_quality_channels': high_quality_channel_count,
        'blacklist_stats': blacklist_stats,
        'category_stats': category_stats,
        'sorting_rules': {
            'ipv6_priority': 100,
            '4k_priority': 40,
            'hd_priority': 30,
            'sd_priority': 20,
            'fluent_priority': 10
        },
        'channels': channel_list,
        'player_support': PLAYER_SUPPORT,
        'source_file': 'sources.txt',
        'blacklist_file': BLACKLIST_FILE,
        'config_file': CONFIG_FILE
    }
    
    # å†™å…¥æ–‡ä»¶
    with open("channels.json", "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"  âœ… channels.json ç”ŸæˆæˆåŠŸï¼ŒåŒ…å« {len(merged_channels)} ä¸ªç”µè§†å°çš„è¯¦ç»†ä¿¡æ¯")
except Exception as e:
    print(f"  âŒ ç”Ÿæˆchannels.jsonå¤±è´¥: {e}")

print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
print(f"ğŸ“Š ç»Ÿè®¡:")
print(f"  - ç”µè§†å°æ€»æ•°: {len(merged_channels)}")
print(f"  - å¤šæºç”µè§†å°: {multi_source_count}")
print(f"  - å•æºç”µè§†å°: {single_source_count}")
print(f"  - å«IPv6æºç”µè§†å°: {ipv6_channel_count}")
if config['ENABLE_SPEED_TEST']:
    print(f"  - å«é«˜è´¨é‡æºç”µè§†å°: {high_quality_channel_count}")
print(f"  - åŸå§‹é¢‘é“æ•°: {len(all_channels)}")
print(f"  - è¿‡æ»¤åé¢‘é“æ•°: {len(filtered_channels)}")
print(f"  - é»‘åå•è¿‡æ»¤æ•°: {blacklisted_count}")
print(f"  - æ•°æ®æº: {len(sources)}")
if config['ENABLE_BLACKLIST']:
    print(f"  - é»‘åå•æ¡ç›®: {len(blacklist) + len(slow_urls)}")
print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  - live_sources.m3u (IPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ - PotPlayer/VLCæ ¼å¼)")
print(f"  - merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3u (IPv6ä¼˜å…ˆå¤šæºåˆ†ç¦»ç‰ˆ - TiviMate/Kodiæ ¼å¼)")
print(f"  - merged/ç²¾ç®€ç‰ˆ.m3u (IPv6ä¼˜å…ˆå•æºç²¾ç®€ç‰ˆ)")
print(f"  - channels.json (è¯¦ç»†æ•°æ®)")
print(f"  - categories/*.m3u (åˆ†ç±»åˆ—è¡¨)")
if config['ENABLE_BLACKLIST']:
    print(f"  - {BLACKLIST_FILE} (ä½è´¨é‡æºé»‘åå•)")
print(f"\nğŸ® æ’­æ”¾å™¨ä½¿ç”¨è¯´æ˜:")
print(f"  1. PotPlayer/VLC: ä½¿ç”¨ live_sources.m3uï¼Œæ’­æ”¾æ—¶æŒ‰Alt+Wåˆ‡æ¢æº")
print(f"  2. TiviMate/Kodi: ä½¿ç”¨ merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3uï¼Œè‡ªåŠ¨åˆå¹¶ç›¸åŒåç§°é¢‘é“")
print(f"  3. å…¶ä»–æ’­æ”¾å™¨: ä½¿ç”¨ merged/ç²¾ç®€ç‰ˆ.m3uï¼Œæ¯ä¸ªç”µè§†å°IPv6æºä¼˜å…ˆ")
print(f"\nâš™ï¸  å½“å‰é…ç½®:")
print(f"  - é»‘åå•åŠŸèƒ½: {'âœ…å¯ç”¨' if config['ENABLE_BLACKLIST'] else 'âŒç¦ç”¨'}")
print(f"  - æµ‹é€ŸåŠŸèƒ½: {'âœ…å¯ç”¨' if config['ENABLE_SPEED_TEST'] else 'âŒç¦ç”¨'}")
if config['ENABLE_SPEED_TEST']:
    print(f"  - æœ€ä½è¯„åˆ†è¦æ±‚: {config['MIN_SPEED_SCORE']}")
    print(f"  - è¶…æ—¶è®¾ç½®: {config['CONNECT_TIMEOUT']}sè¿æ¥, {config['STREAM_TIMEOUT']}sæµæµ‹è¯•")
print(f"\nğŸ“ é…ç½®æ–‡ä»¶è¯´æ˜:")
print(f"  ä¿®æ”¹ {CONFIG_FILE} æ–‡ä»¶å¯ä»¥è°ƒæ•´é…ç½®ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ä¼šä½¿ç”¨é»˜è®¤å€¼")
print(f"  ç¤ºä¾‹é…ç½®:")
print(f"    ENABLE_BLACKLIST=true")
print(f"    ENABLE_SPEED_TEST=true")
print(f"    CONNECT_TIMEOUT=3")
print(f"    STREAM_TIMEOUT=10")
print(f"    MIN_SPEED_SCORE=0.5")
print(f"    MAX_WORKERS=20")