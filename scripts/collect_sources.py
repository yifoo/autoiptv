#!/usr/bin/env python3
"""
ç”µè§†ç›´æ’­æºæ”¶é›†è„šæœ¬ - å¤šæºåˆå¹¶ç‰ˆ
åŠŸèƒ½ï¼š1. é¢‘é“åç§°ç²¾ç®€ 2. åŒåç”µè§†å°åˆå¹¶ï¼ˆå¤šæºé›†æˆï¼‰3. æ”¯æŒæºåˆ‡æ¢ 4. ç»Ÿä¸€å¤®è§†é¢‘é“å‘½å
ç‰¹ç‚¹ï¼šæ‰€æœ‰ç”µè§†æºç»Ÿä¸€ä»sources.txtæ–‡ä»¶è·å–ï¼Œæ¯ä¸ªç”µè§†å°æ˜¾ç¤ºä¸ºä¸€ä¸ªæ¡ç›®ä½†åŒ…å«å¤šä¸ªæº
åˆ†ç±»ï¼šå¤®è§†ã€å«è§†ã€åœ°æ–¹å°ï¼ˆæŒ‰çœä»½ï¼‰ã€å°‘å„¿å°ã€ç»¼è‰ºå°ã€æ¸¯æ¾³å°ã€ä½“è‚²å°ã€å½±è§†å°ã€æ™¯åŒºé¢‘é“ã€å…¶ä»–å°
æ’­æ”¾å™¨æ”¯æŒï¼šPotPlayerã€VLCã€TiviMateã€Kodiç­‰æ”¯æŒå¤šæºåˆ‡æ¢çš„æ’­æ”¾å™¨
"""

import requests
import re
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path
import json
import os
import sys

print("=" * 70)
print("ç”µè§†ç›´æ’­æºæ”¶é›†è„šæœ¬ v5.0 - å¤šæºåˆå¹¶ç‰ˆ")
print("åŠŸèƒ½ï¼šé¢‘é“åç§°æ·±åº¦ç²¾ç®€ã€ç»Ÿä¸€å¤®è§†é¢‘é“å‘½åã€æŒ‰çœä»½åˆ†ç±»åœ°æ–¹å°ã€å¤šæºé›†æˆ")
print("ç‰¹ç‚¹ï¼šæ¯ä¸ªç”µè§†å°æ˜¾ç¤ºä¸ºä¸€ä¸ªæ¡ç›®ï¼Œå†…éƒ¨åŒ…å«å¤šä¸ªå¯åˆ‡æ¢æº")
print("æ’­æ”¾å™¨ï¼šæ”¯æŒPotPlayerã€VLCã€TiviMateã€Kodiç­‰å¤šæºåˆ‡æ¢åŠŸèƒ½")
print("=" * 70)

def load_sources_from_file():
    """ä»sources.txtæ–‡ä»¶åŠ è½½æ‰€æœ‰ç”µè§†æº"""
    sources_file = "sources.txt"
    sources = []
    
    if not os.path.exists(sources_file):
        print(f"âŒ é”™è¯¯: {sources_file} æ–‡ä»¶ä¸å­˜åœ¨")
        print(f"ğŸ“ è¯·åˆ›å»º {sources_file} æ–‡ä»¶ï¼Œæ¯è¡Œæ·»åŠ ä¸€ä¸ªM3Uæ–‡ä»¶URL")
        return sources
    
    try:
        with open(sources_file, "r", encoding="utf-8") as f:
            line_number = 0
            for line in f:
                line_number += 1
                line = line.strip()
                
                # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                if not line:
                    continue
                if line.startswith("#"):
                    continue
                
                # éªŒè¯URLæ ¼å¼
                if line.startswith("http://") or line.startswith("https://"):
                    sources.append(line)
                else:
                    print(f"âš ï¸  ç¬¬{line_number}è¡Œæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡: {line}")
        
        print(f"ğŸ“¡ ä» {sources_file} åŠ è½½äº† {len(sources)} ä¸ªæ•°æ®æº")
        
        if len(sources) == 0:
            print(f"âŒ é”™è¯¯: {sources_file} ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„URL")
            print(f"ğŸ“ è¯·åœ¨ {sources_file} ä¸­æ·»åŠ M3Uæ–‡ä»¶URLï¼Œæ ¼å¼: https://example.com/live.m3u")
        
    except Exception as e:
        print(f"âŒ è¯»å– {sources_file} å¤±è´¥: {e}")
    
    return sources

# ä»sources.txtæ–‡ä»¶åŠ è½½æ‰€æœ‰æº
sources = load_sources_from_file()

if len(sources) == 0:
    print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®æºï¼Œé€€å‡º")
    sys.exit(1)

# é¢‘é“åç§°æ¸…ç†è§„åˆ™ - æ·±åº¦ç²¾ç®€
CLEAN_RULES = [
    # ç§»é™¤æŠ€æœ¯å‚æ•°æ ‡è®°
    (r'50\s*FPS', ''),  # ç§»é™¤50 FPS
    (r'HEVC', ''),  # ç§»é™¤HEVC
    (r'H\.?264', ''),  # ç§»é™¤H.264
    (r'H\.?265', ''),  # ç§»é™¤H.265
    (r'AAC', ''),  # ç§»é™¤AAC
    (r'AC3', ''),  # ç§»é™¤AC3
    (r'[\[\(][^\]\)]*[\]\)]', ''),  # ç§»é™¤æ‰€æœ‰æ‹¬å·å†…å®¹
    (r'ã€[^ã€‘]*ã€‘', ''),  # ç§»é™¤æ‰€æœ‰ä¸­æ–‡æ‹¬å·å†…å®¹
    
    # ç§»é™¤æ¸…æ™°åº¦æ ‡è®°
    (r'[_\-\s]?4K[_\-\s]?', ' '),  # ç§»é™¤4Kæ ‡è®°
    (r'[_\-\s]?é«˜æ¸…[_\-\s]?', ' '),  # ç§»é™¤é«˜æ¸…æ ‡è®°
    (r'[_\-\s]?HD[_\-\s]?', ' '),  # ç§»é™¤HDæ ‡è®°
    (r'[_\-\s]?è¶…æ¸…[_\-\s]?', ' '),  # ç§»é™¤è¶…æ¸…æ ‡è®°
    (r'[_\-\s]?æ ‡æ¸…[_\-\s]?', ' '),  # ç§»é™¤æ ‡æ¸…æ ‡è®°
    (r'[_\-\s]?æµç•…[_\-\s]?', ' '),  # ç§»é™¤æµç•…æ ‡è®°
    (r'[_\-\s]?1080[Pp]?[_\-\s]?', ' '),  # ç§»é™¤1080Pæ ‡è®°
    (r'[_\-\s]?720[Pp]?[_\-\s]?', ' '),  # ç§»é™¤720Pæ ‡è®°
    
    # ç§»é™¤åè®®æ ‡è®°
    (r'[_\-\s]?IPV6[_\-\s]?', ' '),  # ç§»é™¤IPV6æ ‡è®°
    (r'[_\-\s]?IPV4[_\-\s]?', ' '),  # ç§»é™¤IPV4æ ‡è®°
    (r'[_\-\s]?HLS[_\-\s]?', ' '),  # ç§»é™¤HLSæ ‡è®°
    (r'[_\-\s]?RTMP[_\-\s]?', ' '),  # ç§»é™¤RTMPæ ‡è®°
    (r'[_\-\s]?RTSP[_\-\s]?', ' '),  # ç§»é™¤RTSPæ ‡è®°
    (r'[_\-\s]?FLV[_\-\s]?', ' '),  # ç§»é™¤FLVæ ‡è®°
    
    # ç§»é™¤å†—ä½™è¯
    (r'\s+ç›´æ’­$', ''),  # ç§»é™¤"ç›´æ’­"åç¼€
    (r'\s+é¢‘é“$', ''),  # ç§»é™¤"é¢‘é“"åç¼€
    (r'\s+å°$', ''),  # ç§»é™¤"å°"åç¼€
    (r'\s+ç”µè§†å°$', ''),  # ç§»é™¤"ç”µè§†å°"åç¼€
    (r'\s+å«è§†å°$', 'å«è§†'),  # å«è§†å°æ”¹ä¸ºå«è§†
    
    # ç»Ÿä¸€ç¬¦å·
    (r'\s+', ' '),  # å¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ª
    (r'^\s+|\s+$', ''),  # å»é™¤é¦–å°¾ç©ºæ ¼
    (r'[_\-\|]+', ' '),  # ç»Ÿä¸€åˆ†éš”ç¬¦ä¸ºç©ºæ ¼
    (r'\s*&\s*', ' '),  # &ç¬¦å·æ›¿æ¢ä¸ºç©ºæ ¼
]

# å¤®è§†é¢‘é“æ ‡å‡†åŒ–æ˜ å°„
CCTV_MAPPING = {
    # æ ‡å‡†CCTVæ•°å­—é¢‘é“
    r'^CCTV[_\-\s]?1$': 'CCTV-1 ç»¼åˆ',
    r'^CCTV[_\-\s]?2$': 'CCTV-2 è´¢ç»',
    r'^CCTV[_\-\s]?3$': 'CCTV-3 ç»¼è‰º',
    r'^CCTV[_\-\s]?4$': 'CCTV-4 ä¸­æ–‡å›½é™…',
    r'^CCTV[_\-\s]?5$': 'CCTV-5 ä½“è‚²',
    r'^CCTV[_\-\s]?5\+$': 'CCTV-5+ ä½“è‚²èµ›äº‹',
    r'^CCTV[_\-\s]?6$': 'CCTV-6 ç”µå½±',
    r'^CCTV[_\-\s]?7$': 'CCTV-7 å›½é˜²å†›äº‹',
    r'^CCTV[_\-\s]?8$': 'CCTV-8 ç”µè§†å‰§',
    r'^CCTV[_\-\s]?9$': 'CCTV-9 çºªå½•',
    r'^CCTV[_\-\s]?10$': 'CCTV-10 ç§‘æ•™',
    r'^CCTV[_\-\s]?11$': 'CCTV-11 æˆæ›²',
    r'^CCTV[_\-\s]?12$': 'CCTV-12 ç¤¾ä¼šä¸æ³•',
    r'^CCTV[_\-\s]?13$': 'CCTV-13 æ–°é—»',
    r'^CCTV[_\-\s]?14$': 'CCTV-14 å°‘å„¿',
    r'^CCTV[_\-\s]?15$': 'CCTV-15 éŸ³ä¹',
    r'^CCTV[_\-\s]?16$': 'CCTV-16 å¥¥æ—åŒ¹å…‹',
    r'^CCTV[_\-\s]?17$': 'CCTV-17 å†œä¸šå†œæ‘',
    
    # å¤®è§†ä¸­æ–‡æ•°å­—é¢‘é“
    r'^CCTV[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]$': 'CCTV-{num}',
    r'^å¤®è§†[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]$': 'CCTV-{num}',
    r'^ä¸­å¤®ç”µè§†å°[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]?$': 'CCTV-1 ç»¼åˆ',
    
    # å¤®è§†é«˜æ¸…/4Ké¢‘é“
    r'^CCTV4K$': 'CCTV-4K è¶…é«˜æ¸…',
    r'^CCTV8K$': 'CCTV-8K è¶…é«˜æ¸…',
    r'^CCTV[_\-\s]?é«˜æ¸…$': 'CCTV-é«˜æ¸…',
    
    # å¤®è§†å…¶ä»–é¢‘é“
    r'^CCTV[_\-\s]?æˆæ›²$': 'CCTV-11 æˆæ›²',
    r'^CCTV[_\-\s]?éŸ³ä¹$': 'CCTV-15 éŸ³ä¹',
    r'^CCTV[_\-\s]?å°‘å„¿$': 'CCTV-14 å°‘å„¿',
    r'^CCTV[_\-\s]?æ–°é—»$': 'CCTV-13 æ–°é—»',
    r'^CCTV[_\-\s]?çºªå½•$': 'CCTV-9 çºªå½•',
    r'^CCTV[_\-\s]?ä½“è‚²$': 'CCTV-5 ä½“è‚²',
    r'^CCTV[_\-\s]?ç”µå½±$': 'CCTV-6 ç”µå½±',
    r'^CCTV[_\-\s]?ç”µè§†å‰§$': 'CCTV-8 ç”µè§†å‰§',
    r'^CCTV[_\-\s]?ç»¼è‰º$': 'CCTV-3 ç»¼è‰º',
    r'^CCTV[_\-\s]?è´¢ç»$': 'CCTV-2 è´¢ç»',
}

# ä¸­æ–‡æ•°å­—åˆ°é˜¿æ‹‰ä¼¯æ•°å­—æ˜ å°„
CHINESE_NUMBERS = {
    'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5',
    'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9', 'å': '10',
    'åä¸€': '11', 'åäºŒ': '12', 'åä¸‰': '13', 'åå››': '14', 'åäº”': '15',
    'åå…­': '16', 'åä¸ƒ': '17'
}

# é¢‘é“æ’åºé…ç½®
CHANNEL_ORDER_RULES = {
    # å¤®è§†æŒ‰æ•°å­—é¡ºåº
    "å¤®è§†": {
        "CCTV-1 ç»¼åˆ": 1, "CCTV-2 è´¢ç»": 2, "CCTV-3 ç»¼è‰º": 3, "CCTV-4 ä¸­æ–‡å›½é™…": 4,
        "CCTV-5 ä½“è‚²": 5, "CCTV-5+ ä½“è‚²èµ›äº‹": 6, "CCTV-6 ç”µå½±": 7, "CCTV-7 å›½é˜²å†›äº‹": 8,
        "CCTV-8 ç”µè§†å‰§": 9, "CCTV-9 çºªå½•": 10, "CCTV-10 ç§‘æ•™": 11, "CCTV-11 æˆæ›²": 12,
        "CCTV-12 ç¤¾ä¼šä¸æ³•": 13, "CCTV-13 æ–°é—»": 14, "CCTV-14 å°‘å„¿": 15, "CCTV-15 éŸ³ä¹": 16,
        "CCTV-16 å¥¥æ—åŒ¹å…‹": 17, "CCTV-17 å†œä¸šå†œæ‘": 18, "CCTV-4K è¶…é«˜æ¸…": 19
    },
    
    # å«è§†æŒ‰æ‹¼éŸ³é¡ºåºï¼ˆå¸¸ç”¨å«è§†åœ¨å‰ï¼‰
    "å«è§†": {
        "åŒ—äº¬å«è§†": 1, "ä¸Šæµ·ä¸œæ–¹å«è§†": 2, "å¤©æ´¥å«è§†": 3, "é‡åº†å«è§†": 4,
        "æ²³åŒ—å«è§†": 5, "å±±è¥¿å«è§†": 6, "è¾½å®å«è§†": 7, "å‰æ—å«è§†": 8,
        "é»‘é¾™æ±Ÿå«è§†": 9, "æ±Ÿè‹å«è§†": 10, "æµ™æ±Ÿå«è§†": 11, "å®‰å¾½å«è§†": 12,
        "ç¦å»ºå«è§†": 13, "æ±Ÿè¥¿å«è§†": 14, "å±±ä¸œå«è§†": 15, "æ²³å—å«è§†": 16,
        "æ¹–åŒ—å«è§†": 17, "æ¹–å—å«è§†": 18, "å¹¿ä¸œå«è§†": 19, "å¹¿è¥¿å«è§†": 20,
        "æµ·å—å«è§†": 21, "å››å·å«è§†": 22, "è´µå·å«è§†": 23, "äº‘å—å«è§†": 24,
        "é™•è¥¿å«è§†": 25, "ç”˜è‚ƒå«è§†": 26, "é’æµ·å«è§†": 27, "å®å¤å«è§†": 28,
        "æ–°ç–†å«è§†": 29, "å†…è’™å¤å«è§†": 30, "è¥¿è—å«è§†": 31
    }
}

# çœä»½åˆ—è¡¨ï¼ˆç”¨äºåœ°æ–¹å°åˆ†ç±»ï¼‰
PROVINCES = [
    "åŒ—äº¬å¸‚", "å¤©æ´¥å¸‚", "æ²³åŒ—çœ", "å±±è¥¿çœ", "å†…è’™å¤è‡ªæ²»åŒº",
    "è¾½å®çœ", "å‰æ—çœ", "é»‘é¾™æ±Ÿçœ", "ä¸Šæµ·å¸‚", "æ±Ÿè‹çœ",
    "æµ™æ±Ÿçœ", "å®‰å¾½çœ", "ç¦å»ºçœ", "æ±Ÿè¥¿çœ", "å±±ä¸œçœ",
    "æ²³å—çœ", "æ¹–åŒ—çœ", "æ¹–å—çœ", "å¹¿ä¸œçœ", "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
    "æµ·å—çœ", "é‡åº†å¸‚", "å››å·çœ", "è´µå·çœ", "äº‘å—çœ",
    "è¥¿è—è‡ªæ²»åŒº", "é™•è¥¿çœ", "ç”˜è‚ƒçœ", "é’æµ·çœ", "å®å¤å›æ—è‡ªæ²»åŒº",
    "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº", "å°æ¹¾çœ", "é¦™æ¸¯", "æ¾³é—¨"
]

# çœä»½ç®€ç§°æ˜ å°„
PROVINCE_ABBR = {
    "åŒ—äº¬": "åŒ—äº¬å¸‚", "å¤©æ´¥": "å¤©æ´¥å¸‚", "æ²³åŒ—": "æ²³åŒ—çœ", "å±±è¥¿": "å±±è¥¿çœ",
    "å†…è’™å¤": "å†…è’™å¤è‡ªæ²»åŒº", "è¾½å®": "è¾½å®çœ", "å‰æ—": "å‰æ—çœ", "é»‘é¾™æ±Ÿ": "é»‘é¾™æ±Ÿçœ",
    "ä¸Šæµ·": "ä¸Šæµ·å¸‚", "æ±Ÿè‹": "æ±Ÿè‹çœ", "æµ™æ±Ÿ": "æµ™æ±Ÿçœ", "å®‰å¾½": "å®‰å¾½çœ",
    "ç¦å»º": "ç¦å»ºçœ", "æ±Ÿè¥¿": "æ±Ÿè¥¿çœ", "å±±ä¸œ": "å±±ä¸œçœ", "æ²³å—": "æ²³å—çœ",
    "æ¹–åŒ—": "æ¹–åŒ—çœ", "æ¹–å—": "æ¹–å—çœ", "å¹¿ä¸œ": "å¹¿ä¸œçœ", "å¹¿è¥¿": "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
    "æµ·å—": "æµ·å—çœ", "é‡åº†": "é‡åº†å¸‚", "å››å·": "å››å·çœ", "è´µå·": "è´µå·çœ",
    "äº‘å—": "äº‘å—çœ", "è¥¿è—": "è¥¿è—è‡ªæ²»åŒº", "é™•è¥¿": "é™•è¥¿çœ", "ç”˜è‚ƒ": "ç”˜è‚ƒçœ",
    "é’æµ·": "é’æµ·çœ", "å®å¤": "å®å¤å›æ—è‡ªæ²»åŒº", "æ–°ç–†": "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº",
    "å°æ¹¾": "å°æ¹¾çœ", "é¦™æ¸¯": "é¦™æ¸¯", "æ¾³é—¨": "æ¾³é—¨"
}

# åˆ†ç±»è§„åˆ™ - æŒ‰ä¼˜å…ˆçº§é¡ºåºåŒ¹é…
CATEGORY_RULES = {
    # å¤®è§† - æœ€å…·ä½“ï¼Œæœ€å…ˆåŒ¹é…
    "å¤®è§†": [
        r"^CCTV[-\s]?[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+",  # CCTV1, CCTV-1, CCTVä¸€
        r"^å¤®è§†[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+",  # å¤®è§†ä¸€, å¤®è§†äºŒ
        r"^ä¸­å¤®ç”µè§†å°",  # ä¸­å¤®ç”µè§†å°
        r"^CCTV[-\s]?4K", r"^CCTV[-\s]?8K", r"^CCTV[-\s]?5\+",
        r"^CCTV[-\s]?ç»¼åˆ$", r"^CCTV[-\s]?è´¢ç»$", r"^CCTV[-\s]?ç»¼è‰º$",
        r"^CCTV[-\s]?ä½“è‚²$", r"^CCTV[-\s]?ç”µå½±$", r"^CCTV[-\s]?ç”µè§†å‰§$",
    ],
    
    # å«è§†
    "å«è§†": [
        r"å«è§†$",  # ä»¥"å«è§†"ç»“å°¾
        r"^åŒ—äº¬å«è§†$", r"^æ¹–å—å«è§†$", r"^æµ™æ±Ÿå«è§†$", r"^æ±Ÿè‹å«è§†$",
        r"^ä¸œæ–¹å«è§†$", r"^å¤©æ´¥å«è§†$", r"^å®‰å¾½å«è§†$", r"^å±±ä¸œå«è§†$",
        r"^å¹¿ä¸œå«è§†$", r"^æ·±åœ³å«è§†$", r"^é»‘é¾™æ±Ÿå«è§†$", r"^è¾½å®å«è§†$",
        r"^æ¹–åŒ—å«è§†$", r"^æ²³å—å«è§†$", r"^å››å·å«è§†$", r"^é‡åº†å«è§†$",
        r"^æ±Ÿè¥¿å«è§†$", r"^å¹¿è¥¿å«è§†$", r"^ä¸œå—å«è§†$", r"^è´µå·å«è§†$",
        r"^äº‘å—å«è§†$", r"^é™•è¥¿å«è§†$", r"^å±±è¥¿å«è§†$", r"^æ²³åŒ—å«è§†$",
        r"^æµ·å—å«è§†$", r"^å®å¤å«è§†$", r"^æ–°ç–†å«è§†$", r"^å†…è’™å¤å«è§†$",
    ],
    
    # æ™¯åŒºé¢‘é“ï¼ˆæ–°å¢ï¼‰
    "æ™¯åŒºé¢‘é“": [
        r"æ™¯åŒº$", r"æ—…æ¸¸$", r"é£å…‰$", r"æ™¯ç‚¹$", r"å¯¼è§†$",
        r"^å³¨çœ‰å±±", r"^ä¹å¯¨æ²Ÿ", r"^é»„å±±", r"^æ³°å±±", r"^åå±±",
        r"^å¼ å®¶ç•Œ", r"^è¥¿æ¹–", r"^æ¼“æ±Ÿ", r"^é¼“æµªå±¿", r"^æ•…å®«",
        r"^é•¿åŸ", r"^å…µé©¬ä¿‘", r"^å¸ƒè¾¾æ‹‰å®«", r"^å¤©å®‰é—¨", r"^å¤–æ»©",
        r"^ç»´å¤šåˆ©äºšæ¸¯", r"^æ¾³é—¨å¡”", r"^æ—¥æœˆæ½­", r"^é˜¿é‡Œå±±"
    ],
    
    # å°‘å„¿å°
    "å°‘å„¿å°": [
        r"å°‘å„¿$", r"å¡é€š$", r"åŠ¨æ¼«$", r"åŠ¨ç”»$", r"é‡‘é¹°å¡é€š",
        r"å¡é…·å°‘å„¿", r"å“ˆå“ˆç‚«åŠ¨", r"ä¼˜æ¼«å¡é€š", r"å˜‰ä½³å¡é€š",
        r"ç‚«åŠ¨å¡é€š", r"å®è´"
    ],
    
    # ç»¼è‰ºå°
    "ç»¼è‰ºå°": [
        r"ç»¼è‰º$", r"æ–‡è‰º$", r"å¨±ä¹$", r"éŸ³ä¹$", r"æˆæ›²$",
        r"ç›¸å£°$", r"å°å“$", r"æ–‡åŒ–$", r"è‰ºæœ¯$"
    ],
    
    # æ¸¯æ¾³å°
    "æ¸¯æ¾³å°": [
        r"å‡¤å‡°", r"ç¿¡ç¿ ", r"æ˜ç ", r"TVB", r"ATV", r"æ¾³è§†",
        r"æ¾³é—¨", r"é¦™æ¸¯", r"å°æ¹¾", r"ä¸­å¤©", r"ä¸œæ£®", r"åè§†",
        r"æ°‘è§†", r"ä¸‰ç«‹", r"æ— çº¿"
    ],
    
    # ä½“è‚²å°
    "ä½“è‚²å°": [
        r"ä½“è‚²$", r"è¶³çƒ$", r"ç¯®çƒ$", r"NBA", r"CBA", r"è‹±è¶…",
        r"æ¬§å† $", r"é«˜å°”å¤«$", r"ç½‘çƒ$", r"ä¹’ç¾½$", r"æå‡»$",
        r"èµ›è½¦$", r"F1$", r"å¥¥è¿$", r"èµ›äº‹$"
    ],
    
    # å½±è§†å°
    "å½±è§†å°": [
        r"ç”µå½±$", r"å½±é™¢$", r"å½±è§†é¢‘é“$", r"å¥½è±å$", r"CHC",
        r"å®¶åº­å½±é™¢$", r"åŠ¨ä½œç”µå½±$", r"å–œå‰§ç”µå½±$"
    ]
}

# æ’­æ”¾å™¨å¤šæºæ”¯æŒé…ç½®
PLAYER_SUPPORT = {
    "PotPlayer": {
        "multi_source": True,
        "format": "stream-multi-url",
        "separator": "|",
        "note": "åœ¨æ’­æ”¾æ—¶æŒ‰Alt+Wå¯ä»¥åˆ‡æ¢æº"
    },
    "VLC": {
        "multi_source": True,
        "format": "stream-multi-url",
        "separator": "#",
        "note": "åœ¨æ’­æ”¾åˆ—è¡¨ä¸­ç‚¹å³é”®é€‰æ‹©ä¸åŒæº"
    },
    "TiviMate": {
        "multi_source": True,
        "format": "same-name",
        "separator": None,
        "note": "è‡ªåŠ¨åˆå¹¶ç›¸åŒåç§°çš„é¢‘é“ï¼Œæ’­æ”¾æ—¶è‡ªåŠ¨åˆ‡æ¢"
    },
    "Kodi": {
        "multi_source": True,
        "format": "m3u_plus",
        "separator": None,
        "note": "ä½¿ç”¨IPTV Simple Clientæ’ä»¶"
    }
}

def get_beijing_time():
    """è·å–ä¸œå…«åŒºåŒ—äº¬æ—¶é—´"""
    utc_now = datetime.now(timezone.utc)
    beijing_time = utc_now.astimezone(timezone(timedelta(hours=8)))
    return beijing_time.strftime('%Y-%m-%d %H:%M:%S')

def chinese_to_arabic(chinese_num):
    """ä¸­æ–‡æ•°å­—è½¬é˜¿æ‹‰ä¼¯æ•°å­—"""
    if chinese_num in CHINESE_NUMBERS:
        return CHINESE_NUMBERS[chinese_num]
    return chinese_num

def standardize_cctv_name(name):
    """æ ‡å‡†åŒ–CCTVé¢‘é“åç§°ï¼Œç¡®ä¿CCTVå¤§å†™"""
    original_name = name
    
    # å°†cctvå°å†™è½¬ä¸ºå¤§å†™
    if 'cctv' in name.lower():
        name = re.sub(r'cctv', 'CCTV', name, flags=re.IGNORECASE)
    
    # é¦–å…ˆå°è¯•åŒ¹é…CCTV_MAPPINGä¸­çš„è§„åˆ™
    for pattern, replacement in CCTV_MAPPING.items():
        if re.match(pattern, name, re.IGNORECASE):
            if '{num}' in replacement:
                # æå–æ•°å­—éƒ¨åˆ†
                match = re.search(r'[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+', name)
                if match:
                    num = chinese_to_arabic(match.group())
                    return replacement.replace('{num}', num)
            return replacement
    
    # å¤„ç†CCTV-æ•°å­—æ ¼å¼
    cctv_match = re.match(r'^CCTV[_\-\s]?([\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)(?:\s+(.+))?$', name, re.IGNORECASE)
    if cctv_match:
        num = chinese_to_arabic(cctv_match.group(1))
        suffix = cctv_match.group(2) or ""
        
        # æ ¹æ®æ•°å­—ç¡®å®šé¢‘é“åç§°
        cctv_names = {
            '1': 'ç»¼åˆ', '2': 'è´¢ç»', '3': 'ç»¼è‰º', '4': 'ä¸­æ–‡å›½é™…',
            '5': 'ä½“è‚²', '5+': 'ä½“è‚²èµ›äº‹', '6': 'ç”µå½±', '7': 'å›½é˜²å†›äº‹',
            '8': 'ç”µè§†å‰§', '9': 'çºªå½•', '10': 'ç§‘æ•™', '11': 'æˆæ›²',
            '12': 'ç¤¾ä¼šä¸æ³•', '13': 'æ–°é—»', '14': 'å°‘å„¿', '15': 'éŸ³ä¹',
            '16': 'å¥¥æ—åŒ¹å…‹', '17': 'å†œä¸šå†œæ‘'
        }
        
        if num in cctv_names:
            channel_name = cctv_names[num]
            return f"CCTV-{num} {channel_name}"
        else:
            if suffix:
                return f"CCTV-{num} {suffix}"
            else:
                return f"CCTV-{num}"
    
    # å¤„ç†å¤®è§†å¼€å¤´
    if name.startswith('å¤®è§†'):
        match = re.match(r'^å¤®è§†([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)(?:\s+(.+))?$', name)
        if match:
            num = chinese_to_arabic(match.group(1))
            suffix = match.group(2) or ""
            return f"CCTV-{num} {suffix}"
    
    return original_name

def clean_channel_name(name):
    """æ·±åº¦æ¸…ç†é¢‘é“åç§°ï¼Œç§»é™¤å†—ä½™ä¿¡æ¯ï¼Œç»Ÿä¸€CCTVå¤§å†™"""
    original_name = name
    
    # æ·±åº¦æ¸…ç†ï¼šåº”ç”¨æ‰€æœ‰æ¸…ç†è§„åˆ™
    for pattern, replacement in CLEAN_RULES:
        name = re.sub(pattern, replacement, name, flags=re.IGNORECASE)
    
    # é¢å¤–æ¸…ç†ï¼šç§»é™¤é‡å¤è¯
    name = re.sub(r'\b(\w+)(?:\s+\1)+\b', r'\1', name)
    
    # æ ‡å‡†åŒ–CCTVåç§°
    if re.match(r'^(CCTV|å¤®è§†|ä¸­å¤®ç”µè§†å°)', name, re.IGNORECASE):
        name = standardize_cctv_name(name)
    
    # ç»Ÿä¸€å«è§†å‘½å
    if name.endswith('å«è§†') and len(name) > 2:
        # ç§»é™¤å«è§†å‰çš„å¤šä½™ç©ºæ ¼
        name = re.sub(r'\s+å«è§†$', 'å«è§†', name)
    
    # å¼ºåˆ¶å°†cctvè½¬ä¸ºCCTVï¼ˆå¤§å°å†™ç»Ÿä¸€ï¼‰
    if 'cctv' in name.lower():
        name = re.sub(r'cctv', 'CCTV', name, flags=re.IGNORECASE)
    
    # æœ€ç»ˆæ¸…ç†
    name = re.sub(r'\s+', ' ', name)  # åˆå¹¶å¤šä¸ªç©ºæ ¼
    name = name.strip()
    
    # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹åç§°
    if not name or len(name) < 2:
        name = original_name
    
    return name

def get_channel_sort_key(channel_name, category):
    """è·å–é¢‘é“æ’åºé”®å€¼"""
    if category in CHANNEL_ORDER_RULES:
        if channel_name in CHANNEL_ORDER_RULES[category]:
            return (0, CHANNEL_ORDER_RULES[category][channel_name])
        else:
            # æŸ¥æ‰¾åŒ¹é…çš„æ¨¡å¼
            for pattern, order in CHANNEL_ORDER_RULES[category].items():
                if pattern in channel_name:
                    return (1, order, channel_name)
    
    # æŒ‰å­—æ¯é¡ºåºæ’åº
    return (2, channel_name)

def categorize_channel(channel_name):
    """ä¸ºé¢‘é“åˆ†ç±»ï¼Œæ”¯æŒçœä»½åˆ†ç±»"""
    # æŒ‰ä¼˜å…ˆçº§é¡ºåºåŒ¹é…åˆ†ç±»è§„åˆ™
    for category, patterns in CATEGORY_RULES.items():
        for pattern in patterns:
            try:
                if re.search(pattern, channel_name, re.IGNORECASE):
                    return category
            except re.error:
                # å¦‚æœæ­£åˆ™è¡¨è¾¾å¼æœ‰è¯¯ï¼Œå°è¯•ç›´æ¥å­—ç¬¦ä¸²åŒ¹é…
                if pattern.lower() in channel_name.lower():
                    return category
    
    # å°è¯•åŒ¹é…çœä»½åˆ†ç±»
    for province_full in PROVINCES:
        if province_full in channel_name:
            return province_full
    
    # å°è¯•åŒ¹é…çœä»½ç®€ç§°
    for abbr, full in PROVINCE_ABBR.items():
        if abbr in channel_name and len(abbr) >= 2:
            return full
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•è§„åˆ™ï¼Œè¿”å›"å…¶ä»–å°"
    return "å…¶ä»–å°"

def fetch_m3u(url, retry=2):
    """è·å–M3Uæ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•"""
    for attempt in range(retry + 1):
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "text/plain,application/x-mpegURL,*/*",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Connection": "keep-alive",
                "Cache-Control": "no-cache"
            }
            response = requests.get(url, headers=headers, timeout=15)
            response.encoding = 'utf-8'
            
            if response.status_code == 200:
                return response.text
            else:
                print(f"âŒ è·å–å¤±è´¥ {url}: HTTP {response.status_code} (å°è¯• {attempt + 1}/{retry + 1})")
                if attempt < retry:
                    time.sleep(2)
                
        except requests.exceptions.Timeout:
            print(f"âŒ è¯·æ±‚è¶…æ—¶ {url} (å°è¯• {attempt + 1}/{retry + 1})")
            if attempt < retry:
                time.sleep(2)
        except requests.exceptions.ConnectionError:
            print(f"âŒ è¿æ¥é”™è¯¯ {url} (å°è¯• {attempt + 1}/{retry + 1})")
            if attempt < retry:
                time.sleep(2)
        except Exception as e:
            print(f"âŒ è¯·æ±‚é”™è¯¯ {url}: {e} (å°è¯• {attempt + 1}/{retry + 1})")
            if attempt < retry:
                time.sleep(2)
    
    return None

def parse_channels(content, source_url):
    """è§£æM3Uå†…å®¹ï¼Œè¿”å›é¢‘é“åˆ—è¡¨"""
    channels = []
    lines = content.split('\n')
    i = 0
    
    while i < len(lines):
        line = lines[i].strip()
        if line.startswith('#EXTINF:'):
            # æå–é¢‘é“åç§°
            name = "æœªçŸ¥é¢‘é“"
            match = re.search(r',([^,\n]+)$', line)
            if match:
                name = match.group(1).strip()
            
            # æå–åˆ†ç»„
            group = None
            match = re.search(r'group-title="([^"]+)"', line)
            if match:
                group = match.group(1).strip()
            
            # æå–logo
            logo = None
            match = re.search(r'tvg-logo="([^"]+)"', line)
            if match:
                logo = match.group(1).strip()
            
            # æå–æ¸…æ™°åº¦ä¿¡æ¯
            quality = "æœªçŸ¥"
            if re.search(r'4K|è¶…æ¸…|UHD|2160', name, re.IGNORECASE):
                quality = "4K"
            elif re.search(r'é«˜æ¸…|HD|1080|FHD', name, re.IGNORECASE):
                quality = "é«˜æ¸…"
            elif re.search(r'æ ‡æ¸…|SD|720', name, re.IGNORECASE):
                quality = "æ ‡æ¸…"
            elif re.search(r'æµç•…|360|480', name, re.IGNORECASE):
                quality = "æµç•…"
            
            # è·å–URL
            if i + 1 < len(lines):
                url = lines[i + 1].strip()
                if url and not url.startswith('#'):
                    # æ·±åº¦æ¸…ç†é¢‘é“åç§°
                    clean_name = clean_channel_name(name)
                    
                    channels.append({
                        'original_name': name,
                        'clean_name': clean_name,
                        'url': url,
                        'group': group,
                        'logo': logo,
                        'quality': quality,
                        'source': source_url,
                        'extinf_line': line
                    })
                    i += 1
        i += 1
    
    return channels

def merge_channels(all_channels):
    """åˆå¹¶åŒåç”µè§†å°ï¼Œæ”¯æŒå¤šæº"""
    merged = {}
    
    for channel in all_channels:
        key = channel['clean_name']
        
        if key not in merged:
            # åˆ›å»ºæ–°çš„åˆå¹¶é¢‘é“
            merged[key] = {
                'clean_name': key,
                'original_names': [channel['original_name']],
                'sources': [{
                    'url': channel['url'],
                    'quality': channel['quality'],
                    'source': channel['source'],
                    'logo': channel['logo']
                }],
                'logos': [],
                'categories': set(),
                'first_seen': channel
            }
            
            # æ”¶é›†logo
            if channel['logo']:
                merged[key]['logos'].append(channel['logo'])
            
            # ç¡®å®šåˆ†ç±»
            category = categorize_channel(key)
            merged[key]['categories'].add(category)
        else:
            # æ·»åŠ åˆ°ç°æœ‰é¢‘é“
            merged[key]['original_names'].append(channel['original_name'])
            
            # æ£€æŸ¥URLæ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤
            urls = [s['url'] for s in merged[key]['sources']]
            if channel['url'] not in urls:
                merged[key]['sources'].append({
                    'url': channel['url'],
                    'quality': channel['quality'],
                    'source': channel['source'],
                    'logo': channel['logo']
                })
            
            # æ”¶é›†logo
            if channel['logo'] and channel['logo'] not in merged[key]['logos']:
                merged[key]['logos'].append(channel['logo'])
            
            # æ›´æ–°åˆ†ç±»
            category = categorize_channel(key)
            merged[key]['categories'].add(category)
    
    # ä¸ºæ¯ä¸ªåˆå¹¶åçš„é¢‘é“é€‰æ‹©ä¸€ä¸ªä¸»åˆ†ç±»
    for key in merged:
        categories = list(merged[key]['categories'])
        if categories:
            # ä¼˜å…ˆé€‰æ‹©é"å…¶ä»–å°"çš„åˆ†ç±»
            non_other = [c for c in categories if c != "å…¶ä»–å°"]
            if non_other:
                merged[key]['category'] = non_other[0]
            else:
                merged[key]['category'] = "å…¶ä»–å°"
        else:
            merged[key]['category'] = "å…¶ä»–å°"
    
    return merged

def generate_multi_source_m3u(merged_channels, categories, final_category_order, timestamp, output_file, mode="multi"):
    """
    ç”Ÿæˆæ”¯æŒå¤šæºçš„M3Uæ–‡ä»¶
    mode: 
      "multi" - å¤šæºåˆå¹¶æˆä¸€ä¸ªæ¡ç›®ï¼ˆPotPlayeræ ¼å¼ï¼‰
      "separate" - æ¯ä¸ªæºåˆ†å¼€æ¡ç›®ä½†ç›¸åŒåç§°
      "single" - åªä¿ç•™æœ€ä½³æº
    """
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
            if mode == "multi":
                f.write(f"# ç”µè§†ç›´æ’­æº - å¤šæºåˆå¹¶ç‰ˆï¼ˆPotPlayer/VLC/TiviMateæ”¯æŒï¼‰\n")
                f.write(f"# æ¯ä¸ªç”µè§†å°åªæ˜¾ç¤ºä¸€ä¸ªæ¡ç›®ï¼Œå†…éƒ¨åŒ…å«å¤šä¸ªæº\n")
                f.write(f"# æ’­æ”¾å™¨åˆ‡æ¢æºæ–¹æ³•ï¼šPotPlayeræŒ‰Alt+Wï¼ŒVLCå³é”®é€‰æ‹©æº\n")
            elif mode == "separate":
                f.write(f"# ç”µè§†ç›´æ’­æº - å¤šæºåˆ†ç¦»ç‰ˆï¼ˆTiviMate/Kodiæ”¯æŒï¼‰\n")
                f.write(f"# åŒåç”µè§†å°æ˜¾ç¤ºä¸ºå¤šä¸ªæ¡ç›®ï¼Œæ’­æ”¾å™¨è‡ªåŠ¨åˆå¹¶\n")
            else:
                f.write(f"# ç”µè§†ç›´æ’­æº - ç²¾ç®€ç‰ˆ\n")
                f.write(f"# æ¯ä¸ªç”µè§†å°åªä¿ç•™æœ€ä½³æº\n")
            
            f.write(f"# æ›´æ–°æ—¶é—´(åŒ—äº¬æ—¶é—´): {timestamp}\n")
            f.write(f"# ç”µè§†å°æ€»æ•°: {len(merged_channels)}\n")
            f.write(f"# åŸå§‹é¢‘é“æ•°: {len(all_channels)}\n")
            f.write(f"# æ•°æ®æº: {len(sources)} ä¸ª (æˆåŠŸ: {success_sources}, å¤±è´¥: {len(failed_sources)})\n")
            f.write(f"# ç‰¹ç‚¹: ç§»é™¤æŠ€æœ¯å‚æ•°ï¼Œç»Ÿä¸€å¤®è§†é¢‘é“å‘½åï¼ŒæŒ‰çœä»½åˆ†ç±»åœ°æ–¹å°\n")
            f.write(f"# æºæ–‡ä»¶: sources.txt\n\n")
            
            # æŒ‰åˆ†ç±»é¡ºåºå†™å…¥
            for category in final_category_order:
                cat_channels = categories[category]
                if cat_channels:
                    # å¯¹é¢‘é“è¿›è¡Œæ’åº
                    sorted_channels = sorted(
                        cat_channels,
                        key=lambda x: get_channel_sort_key(x['clean_name'], category)
                    )
                    
                    f.write(f"\n# åˆ†ç±»: {category} ({len(cat_channels)}ä¸ªç”µè§†å°)\n")
                    
                    for channel in sorted_channels:
                        # é€‰æ‹©ä¸»logoï¼ˆç¬¬ä¸€ä¸ªéç©ºçš„logoï¼‰
                        main_logo = channel['logos'][0] if channel['logos'] else ""
                        source_count = len(channel['sources'])
                        
                        if mode == "multi":
                            # PotPlayer/VLCå¤šæºæ ¼å¼ï¼šä¸€ä¸ªæ¡ç›®åŒ…å«å¤šä¸ªURLï¼Œç”¨"|"åˆ†éš”
                            display_name = f"{channel['clean_name']} [{source_count}æº]"
                            
                            # æ”¶é›†æ‰€æœ‰URL
                            urls = []
                            qualities = []
                            for source in channel['sources']:
                                urls.append(source['url'])
                                if source['quality'] != "æœªçŸ¥":
                                    qualities.append(source['quality'])
                            
                            # ç”Ÿæˆå¤šæºURL
                            multi_url = "|".join(urls)
                            
                            # å†™å…¥æ¡ç›®
                            line = "#EXTINF:-1"
                            line += f' tvg-name="{channel["clean_name"]}"'
                            line += f' group-title="{category}"'
                            if main_logo:
                                line += f' tvg-logo="{main_logo}"'
                            if qualities:
                                quality_desc = "/".join(set(qualities))
                                line += f' tvg-quality="{quality_desc}"'
                            line += f',{display_name}\n'
                            line += f"{multi_url}\n"
                            f.write(line)
                            
                        elif mode == "separate":
                            # TiviMate/Kodiæ ¼å¼ï¼šç›¸åŒåç§°çš„å¤šä¸ªæ¡ç›®ï¼Œæ’­æ”¾å™¨ä¼šè‡ªåŠ¨åˆå¹¶
                            display_name = channel['clean_name']
                            
                            for i, source in enumerate(channel['sources']):
                                line = "#EXTINF:-1"
                                line += f' tvg-name="{channel["clean_name"]}"'
                                line += f' group-title="{category}"'
                                if main_logo:
                                    line += f' tvg-logo="{main_logo}"'
                                if source['quality'] != "æœªçŸ¥":
                                    line += f' tvg-quality="{source["quality"]}"'
                                if source_count > 1:
                                    line += f',{display_name} [æº{i+1}]\n'
                                else:
                                    line += f',{display_name}\n'
                                line += f"{source['url']}\n"
                                f.write(line)
                                
                        else:  # mode == "single"
                            # ç²¾ç®€ç‰ˆï¼šåªä¿ç•™æœ€ä½³æº
                            display_name = channel['clean_name']
                            
                            # é€‰æ‹©æœ€ä½³æºï¼ˆä¼˜å…ˆé€‰æ‹©é«˜æ¸…æºï¼‰
                            best_source = None
                            for source in channel['sources']:
                                if source['quality'] == "4K":
                                    best_source = source
                                    break
                                elif source['quality'] == "é«˜æ¸…":
                                    best_source = source
                            
                            if not best_source:
                                best_source = channel['sources'][0]
                            
                            line = "#EXTINF:-1"
                            line += f' tvg-name="{channel["clean_name"]}"'
                            line += f' group-title="{category}"'
                            if main_logo:
                                line += f' tvg-logo="{main_logo}"'
                            if best_source['quality'] != "æœªçŸ¥":
                                line += f' tvg-quality="{best_source["quality"]}"'
                            line += f',{display_name}\n'
                            line += f"{best_source['url']}\n"
                            f.write(line)
        
        print(f"  âœ… {output_file} ç”ŸæˆæˆåŠŸ")
        return True
    except Exception as e:
        print(f"  âŒ ç”Ÿæˆ{output_file}å¤±è´¥: {e}")
        return False

# ä¸»æ”¶é›†è¿‡ç¨‹
print("ğŸš€ å¼€å§‹é‡‡é›†ç”µè§†ç›´æ’­æº...")
print(f"ğŸ“‹ æ•°æ®æºåˆ—è¡¨ (ä»sources.txtåŠ è½½):")
for i, source in enumerate(sources, 1):
    print(f"  {i:2d}. {source}")

all_channels = []
success_sources = 0
failed_sources = []

for idx, source_url in enumerate(sources, 1):
    print(f"\n[{idx}/{len(sources)}] å¤„ç†: {source_url}")
    
    content = fetch_m3u(source_url)
    if not content:
        failed_sources.append(source_url)
        print("   âŒ æ— æ³•è·å–å†…å®¹ï¼Œè·³è¿‡")
        continue
    
    channels = parse_channels(content, source_url)
    
    # ç»Ÿè®¡é¢‘é“åç§°å˜åŒ–
    changed_count = 0
    for channel in channels:
        if channel['original_name'] != channel['clean_name']:
            changed_count += 1
    
    print(f"   âœ… è§£æåˆ° {len(channels)} ä¸ªé¢‘é“ ({changed_count}ä¸ªå·²ç²¾ç®€)")
    
    if changed_count > 0 and len(channels) <= 10:
        for channel in channels[:5]:
            if channel['original_name'] != channel['clean_name']:
                print(f"      '{channel['original_name']}' -> '{channel['clean_name']}'")
    
    all_channels.extend(channels)
    success_sources += 1
    
    # é¿å…è¯·æ±‚è¿‡å¿«
    if idx < len(sources):
        time.sleep(1)

print(f"\n{'='*50}")
print(f"âœ… é‡‡é›†å®Œæˆç»Ÿè®¡:")
print(f"   æˆåŠŸæºæ•°: {success_sources}/{len(sources)}")
print(f"   å¤±è´¥æºæ•°: {len(failed_sources)}")
print(f"   æ€»è®¡é‡‡é›†: {len(all_channels)} ä¸ªåŸå§‹é¢‘é“")

if len(failed_sources) > 0:
    print(f"\nâš ï¸  å¤±è´¥çš„æº:")
    for failed in failed_sources:
        print(f"   - {failed}")

if len(all_channels) == 0:
    print("\nâŒ æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•é¢‘é“ï¼Œé€€å‡º")
    sys.exit(1)

# åˆå¹¶åŒåç”µè§†å°
print("\nğŸ”„ æ­£åœ¨åˆå¹¶åŒåç”µè§†å°...")
merged_channels = merge_channels(all_channels)
print(f"   åˆå¹¶å: {len(merged_channels)} ä¸ªå”¯ä¸€ç”µè§†å°")

# æ˜¾ç¤ºå¤šæºç»Ÿè®¡
multi_source_count = sum(1 for c in merged_channels.values() if len(c['sources']) > 1)
single_source_count = len(merged_channels) - multi_source_count
print(f"   å¤šæºç”µè§†å°: {multi_source_count} ä¸ª")
print(f"   å•æºç”µè§†å°: {single_source_count} ä¸ª")

# æ˜¾ç¤ºä¸€äº›å¤šæºç¤ºä¾‹
print("\nğŸ“ å¤šæºç”µè§†å°ç¤ºä¾‹:")
multi_source_examples = [(k, v) for k, v in merged_channels.items() if len(v['sources']) > 1][:5]
for clean_name, data in multi_source_examples:
    source_count = len(data['sources'])
    qualities = [s['quality'] for s in data['sources']]
    quality_desc = "/".join(set(qualities))
    print(f"   {clean_name}: {source_count}ä¸ªæº [{quality_desc}]")

# ç»Ÿè®¡åˆ†ç±»æ•°é‡
category_stats = {}
for channel in merged_channels.values():
    category = channel['category']
    if category in category_stats:
        category_stats[category] += 1
    else:
        category_stats[category] = 1

print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
for category, count in sorted(category_stats.items()):
    print(f"   {category}: {count} ä¸ªç”µè§†å°")

# ç”Ÿæˆæ–‡ä»¶ - ä½¿ç”¨åŒ—äº¬æ—¶é—´
timestamp = get_beijing_time()
print(f"\nğŸ“… å½“å‰åŒ—äº¬æ—¶é—´: {timestamp}")

# æŒ‰åˆ†ç±»ç»„ç»‡é¢‘é“
categories = {}
for channel in merged_channels.values():
    category = channel['category']
    if category not in categories:
        categories[category] = []
    categories[category].append(channel)

# ç¡®å®šåˆ†ç±»é¡ºåºï¼ˆå›ºå®šåˆ†ç±»åœ¨å‰ï¼Œçœä»½åˆ†ç±»åœ¨åï¼ŒæŒ‰æ‹¼éŸ³æ’åºï¼‰
fixed_categories = ["å¤®è§†", "å«è§†", "æ™¯åŒºé¢‘é“", "å°‘å„¿å°", "ç»¼è‰ºå°", 
                   "æ¸¯æ¾³å°", "ä½“è‚²å°", "å½±è§†å°", "å…¶ä»–å°"]

# åˆ†ç¦»çœä»½åˆ†ç±»
province_categories = []
other_categories = []
for category in categories.keys():
    if category in fixed_categories:
        continue
    elif category in PROVINCES or any(province in category for province in PROVINCES):
        province_categories.append(category)
    else:
        other_categories.append(category)

# æŒ‰æ‹¼éŸ³æ’åºçœä»½åˆ†ç±»
province_categories.sort()

# æœ€ç»ˆåˆ†ç±»é¡ºåº
final_category_order = fixed_categories + province_categories + other_categories

# ç¡®ä¿æ¯ä¸ªåˆ†ç±»éƒ½å­˜åœ¨ï¼ˆå³ä½¿ä¸ºç©ºï¼‰
for category in final_category_order:
    if category not in categories:
        categories[category] = []

# åˆ›å»ºè¾“å‡ºç›®å½•
Path("categories").mkdir(exist_ok=True)
Path("merged").mkdir(exist_ok=True)

print("\nğŸ¯ æ’­æ”¾å™¨å¤šæºæ”¯æŒä¿¡æ¯:")
for player, info in PLAYER_SUPPORT.items():
    if info['multi_source']:
        print(f"   âœ… {player}: {info['note']}")

# 1. ç”Ÿæˆå¤šæºåˆå¹¶ç‰ˆM3Uï¼ˆPotPlayer/VLCæ ¼å¼ï¼‰
print("\nğŸ“„ ç”Ÿæˆ live_sources.m3uï¼ˆå¤šæºåˆå¹¶ç‰ˆ - PotPlayer/VLCæ ¼å¼ï¼‰...")
generate_multi_source_m3u(
    merged_channels, categories, final_category_order, 
    timestamp, "live_sources.m3u", mode="multi"
)

# 2. ç”Ÿæˆå¤šæºåˆ†ç¦»ç‰ˆM3Uï¼ˆTiviMate/Kodiæ ¼å¼ï¼‰
print("\nğŸ“„ ç”Ÿæˆ merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3uï¼ˆTiviMate/Kodiæ ¼å¼ï¼‰...")
generate_multi_source_m3u(
    merged_channels, categories, final_category_order,
    timestamp, "merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3u", mode="separate"
)

# 3. ç”Ÿæˆç²¾ç®€ç‰ˆM3Uï¼ˆæ¯ä¸ªç”µè§†å°åªä¿ç•™æœ€ä½³æºï¼‰
print("\nğŸ“„ ç”Ÿæˆ merged/ç²¾ç®€ç‰ˆ.m3uï¼ˆå•æºç²¾ç®€ç‰ˆï¼‰...")
generate_multi_source_m3u(
    merged_channels, categories, final_category_order,
    timestamp, "merged/ç²¾ç®€ç‰ˆ.m3u", mode="single"
)

# 4. ç”Ÿæˆåˆ†ç±»M3Uæ–‡ä»¶ï¼ˆå¤šæºåˆå¹¶æ ¼å¼ï¼‰
print("\nğŸ“„ ç”Ÿæˆåˆ†ç±»æ–‡ä»¶ï¼ˆå¤šæºåˆå¹¶æ ¼å¼ï¼‰...")
for category in final_category_order:
    cat_channels = categories[category]
    if cat_channels:
        try:
            # å¯¹é¢‘é“è¿›è¡Œæ’åº
            sorted_channels = sorted(
                cat_channels,
                key=lambda x: get_channel_sort_key(x['clean_name'], category)
            )
            
            # åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å
            safe_category_name = category.replace('/', '_').replace('\\', '_')
            filename = f"categories/{safe_category_name}.m3u"
            
            with open(filename, "w", encoding="utf-8") as f:
                f.write("#EXTM3U\n")
                f.write(f"# {category}é¢‘é“åˆ—è¡¨ï¼ˆå¤šæºåˆå¹¶ç‰ˆï¼‰\n")
                f.write(f"# æ›´æ–°æ—¶é—´(åŒ—äº¬æ—¶é—´): {timestamp}\n")
                f.write(f"# ç”µè§†å°æ•°é‡: {len(cat_channels)}\n")
                f.write(f"# è¯´æ˜: æ¯ä¸ªç”µè§†å°åŒ…å«å¤šä¸ªæºï¼ŒPotPlayeræŒ‰Alt+Wåˆ‡æ¢\n\n")
                
                for channel in sorted_channels:
                    # é€‰æ‹©ä¸»logoï¼ˆç¬¬ä¸€ä¸ªéç©ºçš„logoï¼‰
                    main_logo = channel['logos'][0] if channel['logos'] else ""
                    source_count = len(channel['sources'])
                    
                    # PotPlayer/VLCå¤šæºæ ¼å¼
                    display_name = f"{channel['clean_name']} [{source_count}æº]"
                    
                    # æ”¶é›†æ‰€æœ‰URL
                    urls = []
                    qualities = []
                    for source in channel['sources']:
                        urls.append(source['url'])
                        if source['quality'] != "æœªçŸ¥":
                            qualities.append(source['quality'])
                    
                    # ç”Ÿæˆå¤šæºURL
                    multi_url = "|".join(urls)
                    
                    # å†™å…¥æ¡ç›®
                    line = "#EXTINF:-1"
                    line += f' tvg-name="{channel["clean_name"]}"'
                    line += f' group-title="{category}"'
                    if main_logo:
                        line += f' tvg-logo="{main_logo}"'
                    if qualities:
                        quality_desc = "/".join(set(qualities))
                        line += f' tvg-quality="{quality_desc}"'
                    line += f',{display_name}\n'
                    line += f"{multi_url}\n"
                    f.write(line)
            
            print(f"  âœ… ç”Ÿæˆ {filename}")
        except Exception as e:
            print(f"  âŒ ç”Ÿæˆ {filename} å¤±è´¥: {e}")

# 5. ç”Ÿæˆåˆå¹¶çš„JSONæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰æºä¿¡æ¯ï¼‰
print("\nğŸ“„ ç”Ÿæˆ channels.json...")
try:
    # åˆ›å»ºé¢‘é“åˆ—è¡¨
    channel_list = []
    for clean_name, channel_data in sorted(merged_channels.items()):
        # å‡†å¤‡æºä¿¡æ¯
        sources_info = []
        for i, source in enumerate(channel_data['sources'], 1):
            sources_info.append({
                'index': i,
                'url': source['url'],
                'quality': source['quality'],
                'source': source['source'],
                'logo': source['logo'] if source['logo'] else ""
            })
        
        # é¢‘é“ä¿¡æ¯
        channel_info = {
            'clean_name': clean_name,
            'original_names': list(set(channel_data['original_names'])),  # å»é‡
            'category': channel_data['category'],
            'source_count': len(channel_data['sources']),
            'logos': channel_data['logos'],
            'sources': sources_info
        }
        channel_list.append(channel_info)
    
    # åˆ›å»ºJSONæ•°æ®
    json_data = {
        'last_updated': timestamp,
        'total_channels': len(merged_channels),
        'original_channel_count': len(all_channels),
        'sources_count': len(sources),
        'success_sources': success_sources,
        'failed_sources': failed_sources,
        'multi_source_channels': multi_source_count,
        'single_source_channels': single_source_count,
        'category_stats': category_stats,
        'channels': channel_list,
        'player_support': PLAYER_SUPPORT,
        'source_file': 'sources.txt'
    }
    
    # å†™å…¥æ–‡ä»¶
    with open("channels.json", "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"  âœ… channels.json ç”ŸæˆæˆåŠŸï¼ŒåŒ…å« {len(merged_channels)} ä¸ªç”µè§†å°çš„è¯¦ç»†ä¿¡æ¯")
except Exception as e:
    print(f"  âŒ ç”Ÿæˆchannels.jsonå¤±è´¥: {e}")

print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
print(f"ğŸ“Š ç»Ÿè®¡:")
print(f"  - ç”µè§†å°æ€»æ•°: {len(merged_channels)}")
print(f"  - å¤šæºç”µè§†å°: {multi_source_count}")
print(f"  - å•æºç”µè§†å°: {single_source_count}")
print(f"  - åŸå§‹é¢‘é“æ•°: {len(all_channels)}")
print(f"  - æ•°æ®æº: {len(sources)}")
print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  - live_sources.m3u (å¤šæºåˆå¹¶ç‰ˆ - PotPlayer/VLCæ ¼å¼)")
print(f"  - merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3u (TiviMate/Kodiæ ¼å¼)")
print(f"  - merged/ç²¾ç®€ç‰ˆ.m3u (å•æºç²¾ç®€ç‰ˆ)")
print(f"  - channels.json (è¯¦ç»†æ•°æ®)")
print(f"  - categories/*.m3u (åˆ†ç±»åˆ—è¡¨)")
print(f"\nğŸ® æ’­æ”¾å™¨ä½¿ç”¨è¯´æ˜:")
print(f"  1. PotPlayer/VLC: ä½¿ç”¨ live_sources.m3uï¼Œæ’­æ”¾æ—¶æŒ‰Alt+Wåˆ‡æ¢æº")
print(f"  2. TiviMate/Kodi: ä½¿ç”¨ merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3uï¼Œè‡ªåŠ¨åˆå¹¶ç›¸åŒåç§°é¢‘é“")
print(f"  3. å…¶ä»–æ’­æ”¾å™¨: ä½¿ç”¨ merged/ç²¾ç®€ç‰ˆ.m3uï¼Œæ¯ä¸ªç”µè§†å°åªæœ‰ä¸€ä¸ªæº")