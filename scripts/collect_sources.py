#!/usr/bin/env python3
"""
ç”µè§†ç›´æ’­æºæ”¶é›†è„šæœ¬ - å¸¦é»‘åå•çš„IPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ
åŠŸèƒ½ï¼š1. é¢‘é“åç§°ç²¾ç®€ 2. åŒåç”µè§†å°åˆå¹¶ï¼ˆIPv6ä¼˜å…ˆï¼‰3. æ”¯æŒæºåˆ‡æ¢ 4. ç»Ÿä¸€å¤®è§†é¢‘é“å‘½å 5. é€Ÿåº¦æµ‹è¯•å’Œé»‘åå•è¿‡æ»¤
ç‰¹ç‚¹ï¼šæ‰€æœ‰ç”µè§†æºç»Ÿä¸€ä»sources.txtæ–‡ä»¶è·å–ï¼ŒIPv6åœ°å€ä¼˜å…ˆæ’åºï¼Œæ…¢é€Ÿæºè‡ªåŠ¨åŠ å…¥é»‘åå•
åˆ†ç±»ï¼šå¤®è§†ã€å«è§†ã€åœ°æ–¹å°ï¼ˆæŒ‰çœä»½ï¼‰ã€å°‘å„¿å°ã€ç»¼è‰ºå°ã€æ¸¯æ¾³å°ã€ä½“è‚²å°ã€å½±è§†å°ã€æ™¯åŒºé¢‘é“ã€å…¶ä»–å°
æ’­æ”¾å™¨æ”¯æŒï¼šPotPlayerã€VLCã€TiviMateã€Kodiç­‰æ”¯æŒå¤šæºåˆ‡æ¢çš„æ’­æ”¾å™¨
"""

import requests
import re
import time
from datetime import datetime, timezone, timedelta
from pathlib import Path
import json
import os
import sys
import ipaddress
import concurrent.futures
import threading

print("=" * 70)
print("ç”µè§†ç›´æ’­æºæ”¶é›†è„šæœ¬ v7.0 - å¸¦é»‘åå•çš„IPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ")
print("åŠŸèƒ½ï¼šé¢‘é“åç§°æ·±åº¦ç²¾ç®€ã€ç»Ÿä¸€å¤®è§†é¢‘é“å‘½åã€æŒ‰çœä»½åˆ†ç±»åœ°æ–¹å°ã€IPv6ä¼˜å…ˆæ’åºã€æ…¢é€Ÿæºé»‘åå•è¿‡æ»¤")
print("ç‰¹ç‚¹ï¼šæ¯ä¸ªç”µè§†å°æ˜¾ç¤ºä¸ºä¸€ä¸ªæ¡ç›®ï¼ŒIPv6æºä¼˜å…ˆæ’åˆ—ï¼Œæ…¢é€Ÿæºè‡ªåŠ¨è¿‡æ»¤")
print("æ’­æ”¾å™¨ï¼šæ”¯æŒPotPlayerã€VLCã€TiviMateã€Kodiç­‰å¤šæºåˆ‡æ¢åŠŸèƒ½")
print("=" * 70)

def load_sources_from_file():
    """ä»sources.txtæ–‡ä»¶åŠ è½½æ‰€æœ‰ç”µè§†æº"""
    sources_file = "sources.txt"
    sources = []
    
    if not os.path.exists(sources_file):
        print(f"âŒ é”™è¯¯: {sources_file} æ–‡ä»¶ä¸å­˜åœ¨")
        print(f"ğŸ“ è¯·åˆ›å»º {sources_file} æ–‡ä»¶ï¼Œæ¯è¡Œæ·»åŠ ä¸€ä¸ªM3Uæ–‡ä»¶URL")
        return sources
    
    try:
        with open(sources_file, "r", encoding="utf-8") as f:
            line_number = 0
            for line in f:
                line_number += 1
                line = line.strip()
                
                # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                if not line:
                    continue
                if line.startswith("#"):
                    continue
                
                # éªŒè¯URLæ ¼å¼
                if line.startswith("http://") or line.startswith("https://"):
                    sources.append(line)
                else:
                    print(f"âš ï¸  ç¬¬{line_number}è¡Œæ ¼å¼é”™è¯¯ï¼Œè·³è¿‡: {line}")
        
        print(f"ğŸ“¡ ä» {sources_file} åŠ è½½äº† {len(sources)} ä¸ªæ•°æ®æº")
        
        if len(sources) == 0:
            print(f"âŒ é”™è¯¯: {sources_file} ä¸­æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„URL")
            print(f"ğŸ“ è¯·åœ¨ {sources_file} ä¸­æ·»åŠ M3Uæ–‡ä»¶URLï¼Œæ ¼å¼: https://example.com/live.m3u")
        
    except Exception as e:
        print(f"âŒ è¯»å– {sources_file} å¤±è´¥: {e}")
    
    return sources

# ä»sources.txtæ–‡ä»¶åŠ è½½æ‰€æœ‰æº
sources = load_sources_from_file()

if len(sources) == 0:
    print("âŒ æ²¡æœ‰å¯ç”¨çš„æ•°æ®æºï¼Œé€€å‡º")
    sys.exit(1)

# é»‘åå•ç®¡ç†
BLACKLIST_FILE = "blacklist.txt"
SPEED_TEST_TIMEOUT = 10  # 10ç§’è¶…æ—¶
MAX_WORKERS = 20  # å¹¶å‘æµ‹è¯•çº¿ç¨‹æ•°

# IPv6æ£€æµ‹å‡½æ•°
def is_ipv6_url(url):
    """æ£€æµ‹URLæ˜¯å¦ä¸ºIPv6åœ°å€"""
    try:
        # ä»URLä¸­æå–ä¸»æœºå
        if '://' in url:
            hostname = url.split('://')[1].split('/')[0]
        else:
            hostname = url.split('/')[0]
        
        # ç§»é™¤ç«¯å£å·
        if ':' in hostname:
            # å¤„ç†IPv6åœ°å€çš„ç«¯å£å·æ ¼å¼ [::1]:8080
            if hostname.startswith('['):
                # IPv6åœ°å€å¸¦ç«¯å£
                ip_part = hostname.split(']')[0][1:]
            else:
                ip_part = hostname.split(':')[0]
        else:
            ip_part = hostname
        
        # å°è¯•è§£æä¸ºIPv6åœ°å€
        ipaddress.IPv6Address(ip_part)
        return True
    except:
        # ä¹Ÿæ£€æŸ¥URLä¸­æ˜¯å¦åŒ…å«IPv6å…³é”®å­—
        url_lower = url.lower()
        if 'ipv6' in url_lower or 'ip6' in url_lower or 'v6' in url_lower:
            return True
        # æ£€æŸ¥æ˜¯å¦åŒ…å«IPv6åœ°å€æ ¼å¼ï¼ˆå†’å·æ•°é‡å¤šï¼‰
        if url_lower.count(':') >= 3:
            return True
        return False

def get_source_priority(source_info):
    """è·å–æºçš„ä¼˜å…ˆçº§åˆ†æ•°ï¼ˆç”¨äºæ’åºï¼‰"""
    priority = 0
    
    # IPv6æºæœ€é«˜ä¼˜å…ˆçº§ï¼ˆ+100åˆ†ï¼‰
    if is_ipv6_url(source_info['url']):
        priority += 100
        # æ ‡è®°ä¸ºIPv6æº
        source_info['is_ipv6'] = True
    else:
        source_info['is_ipv6'] = False
    
    # æ¸…æ™°åº¦ä¼˜å…ˆçº§
    quality_scores = {
        "4K": 40,
        "é«˜æ¸…": 30,
        "æ ‡æ¸…": 20,
        "æµç•…": 10,
        "æœªçŸ¥": 0
    }
    priority += quality_scores.get(source_info['quality'], 0)
    
    # æºè´¨é‡æ ‡è®°ä¼˜å…ˆçº§
    url_lower = source_info['url'].lower()
    if any(marker in url_lower for marker in ['cdn', 'akamai', 'cloudfront']):
        priority += 5  # CDNæºåŠ åˆ†
    if 'https://' in url_lower:
        priority += 3  # HTTPSæºåŠ åˆ†
    if 'm3u8' in url_lower:
        priority += 2  # HLSæºåŠ åˆ†
    
    # é€Ÿåº¦æµ‹è¯•ç»“æœä¼˜å…ˆçº§ï¼ˆå¦‚æœå·²ç»æµ‹è¯•è¿‡ï¼‰
    if 'speed' in source_info:
        if source_info['speed'] < 2.0:
            priority += 20  # è¶…å¿«æº
        elif source_info['speed'] < 4.0:
            priority += 10  # å¿«é€Ÿæº
    
    return priority

# é¢‘é“åç§°æ¸…ç†è§„åˆ™ - æ·±åº¦ç²¾ç®€
CLEAN_RULES = [
    # ç§»é™¤æŠ€æœ¯å‚æ•°æ ‡è®°
    (r'50\s*FPS', ''),  # ç§»é™¤50 FPS
    (r'HEVC', ''),  # ç§»é™¤HEVC
    (r'H\.?264', ''),  # ç§»é™¤H.264
    (r'H\.?265', ''),  # ç§»é™¤H.265
    (r'AAC', ''),  # ç§»é™¤AAC
    (r'AC3', ''),  # ç§»é™¤AC3
    (r'[\[\(][^\]\)]*[\]\)]', ''),  # ç§»é™¤æ‰€æœ‰æ‹¬å·å†…å®¹
    (r'ã€[^ã€‘]*ã€‘', ''),  # ç§»é™¤æ‰€æœ‰ä¸­æ–‡æ‹¬å·å†…å®¹
    
    # ç§»é™¤æ¸…æ™°åº¦æ ‡è®°
    (r'[_\-\s]?4K[_\-\s]?', ' '),  # ç§»é™¤4Kæ ‡è®°
    (r'[_\-\s]?é«˜æ¸…[_\-\s]?', ' '),  # ç§»é™¤é«˜æ¸…æ ‡è®°
    (r'[_\-\s]?HD[_\-\s]?', ' '),  # ç§»é™¤HDæ ‡è®°
    (r'[_\-\s]?è¶…æ¸…[_\-\s]?', ' '),  # ç§»é™¤è¶…æ¸…æ ‡è®°
    (r'[_\-\s]?æ ‡æ¸…[_\-\s]?', ' '),  # ç§»é™¤æ ‡æ¸…æ ‡è®°
    (r'[_\-\s]?æµç•…[_\-\s]?', ' '),  # ç§»é™¤æµç•…æ ‡è®°
    (r'[_\-\s]?1080[Pp]?[_\-\s]?', ' '),  # ç§»é™¤1080Pæ ‡è®°
    (r'[_\-\s]?720[Pp]?[_\-\s]?', ' '),  # ç§»é™¤720Pæ ‡è®°
    
    # ç§»é™¤åè®®æ ‡è®°
    (r'[_\-\s]?IPV6[_\-\s]?', ' '),  # ç§»é™¤IPV6æ ‡è®°
    (r'[_\-\s]?IPV4[_\-\s]?', ' '),  # ç§»é™¤IPV4æ ‡è®°
    (r'[_\-\s]?HLS[_\-\s]?', ' '),  # ç§»é™¤HLSæ ‡è®°
    (r'[_\-\s]?RTMP[_\-\s]?', ' '),  # ç§»é™¤RTMPæ ‡è®°
    (r'[_\-\s]?RTSP[_\-\s]?', ' '),  # ç§»é™¤RTSPæ ‡è®°
    (r'[_\-\s]?FLV[_\-\s]?', ' '),  # ç§»é™¤FLVæ ‡è®°
    
    # ç§»é™¤å†—ä½™è¯
    (r'\s+ç›´æ’­$', ''),  # ç§»é™¤"ç›´æ’­"åç¼€
    (r'\s+é¢‘é“$', ''),  # ç§»é™¤"é¢‘é“"åç¼€
    (r'\s+å°$', ''),  # ç§»é™¤"å°"åç¼€
    (r'\s+ç”µè§†å°$', ''),  # ç§»é™¤"ç”µè§†å°"åç¼€
    (r'\s+å«è§†å°$', 'å«è§†'),  # å«è§†å°æ”¹ä¸ºå«è§†
    
    # ç»Ÿä¸€ç¬¦å·
    (r'\s+', ' '),  # å¤šä¸ªç©ºæ ¼åˆå¹¶ä¸ºä¸€ä¸ª
    (r'^\s+|\s+$', ''),  # å»é™¤é¦–å°¾ç©ºæ ¼
    (r'[_\-\|]+', ' '),  # ç»Ÿä¸€åˆ†éš”ç¬¦ä¸ºç©ºæ ¼
    (r'\s*&\s*', ' '),  # &ç¬¦å·æ›¿æ¢ä¸ºç©ºæ ¼
]

# å¤®è§†é¢‘é“æ ‡å‡†åŒ–æ˜ å°„
CCTV_MAPPING = {
    # æ ‡å‡†CCTVæ•°å­—é¢‘é“
    r'^CCTV[_\-\s]?1$': 'CCTV-1 ç»¼åˆ',
    r'^CCTV[_\-\s]?2$': 'CCTV-2 è´¢ç»',
    r'^CCTV[_\-\s]?3$': 'CCTV-3 ç»¼è‰º',
    r'^CCTV[_\-\s]?4$': 'CCTV-4 ä¸­æ–‡å›½é™…',
    r'^CCTV[_\-\s]?5$': 'CCTV-5 ä½“è‚²',
    r'^CCTV[_\-\s]?5\+$': 'CCTV-5+ ä½“è‚²èµ›äº‹',
    r'^CCTV[_\-\s]?6$': 'CCTV-6 ç”µå½±',
    r'^CCTV[_\-\s]?7$': 'CCTV-7 å›½é˜²å†›äº‹',
    r'^CCTV[_\-\s]?8$': 'CCTV-8 ç”µè§†å‰§',
    r'^CCTV[_\-\s]?9$': 'CCTV-9 çºªå½•',
    r'^CCTV[_\-\s]?10$': 'CCTV-10 ç§‘æ•™',
    r'^CCTV[_\-\s]?11$': 'CCTV-11 æˆæ›²',
    r'^CCTV[_\-\s]?12$': 'CCTV-12 ç¤¾ä¼šä¸æ³•',
    r'^CCTV[_\-\s]?13$': 'CCTV-13 æ–°é—»',
    r'^CCTV[_\-\s]?14$': 'CCTV-14 å°‘å„¿',
    r'^CCTV[_\-\s]?15$': 'CCTV-15 éŸ³ä¹',
    r'^CCTV[_\-\s]?16$': 'CCTV-16 å¥¥æ—åŒ¹å…‹',
    r'^CCTV[_\-\s]?17$': 'CCTV-17 å†œä¸šå†œæ‘',
    
    # å¤®è§†ä¸­æ–‡æ•°å­—é¢‘é“
    r'^CCTV[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]$': 'CCTV-{num}',
    r'^å¤®è§†[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]$': 'CCTV-{num}',
    r'^ä¸­å¤®ç”µè§†å°[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]?$': 'CCTV-1 ç»¼åˆ',
    
    # å¤®è§†é«˜æ¸…/4Ké¢‘é“
    r'^CCTV4K$': 'CCTV-4K è¶…é«˜æ¸…',
    r'^CCTV8K$': 'CCTV-8K è¶…é«˜æ¸…',
    r'^CCTV[_\-\s]?é«˜æ¸…$': 'CCTV-é«˜æ¸…',
    
    # å¤®è§†å…¶ä»–é¢‘é“
    r'^CCTV[_\-\s]?æˆæ›²$': 'CCTV-11 æˆæ›²',
    r'^CCTV[_\-\s]?éŸ³ä¹$': 'CCTV-15 éŸ³ä¹',
    r'^CCTV[_\-\s]?å°‘å„¿$': 'CCTV-14 å°‘å„¿',
    r'^CCTV[_\-\s]?æ–°é—»$': 'CCTV-13 æ–°é—»',
    r'^CCTV[_\-\s]?çºªå½•$': 'CCTV-9 çºªå½•',
    r'^CCTV[_\-\s]?ä½“è‚²$': 'CCTV-5 ä½“è‚²',
    r'^CCTV[_\-\s]?ç”µå½±$': 'CCTV-6 ç”µå½±',
    r'^CCTV[_\-\s]?ç”µè§†å‰§$': 'CCTV-8 ç”µè§†å‰§',
    r'^CCTV[_\-\s]?ç»¼è‰º$': 'CCTV-3 ç»¼è‰º',
    r'^CCTV[_\-\s]?è´¢ç»$': 'CCTV-2 è´¢ç»',
}

# ä¸­æ–‡æ•°å­—åˆ°é˜¿æ‹‰ä¼¯æ•°å­—æ˜ å°„
CHINESE_NUMBERS = {
    'ä¸€': '1', 'äºŒ': '2', 'ä¸‰': '3', 'å››': '4', 'äº”': '5',
    'å…­': '6', 'ä¸ƒ': '7', 'å…«': '8', 'ä¹': '9', 'å': '10',
    'åä¸€': '11', 'åäºŒ': '12', 'åä¸‰': '13', 'åå››': '14', 'åäº”': '15',
    'åå…­': '16', 'åä¸ƒ': '17'
}

# é¢‘é“æ’åºé…ç½®
CHANNEL_ORDER_RULES = {
    # å¤®è§†æŒ‰æ•°å­—é¡ºåº
    "å¤®è§†": {
        "CCTV-1 ç»¼åˆ": 1, "CCTV-2 è´¢ç»": 2, "CCTV-3 ç»¼è‰º": 3, "CCTV-4 ä¸­æ–‡å›½é™…": 4,
        "CCTV-5 ä½“è‚²": 5, "CCTV-5+ ä½“è‚²èµ›äº‹": 6, "CCTV-6 ç”µå½±": 7, "CCTV-7 å›½é˜²å†›äº‹": 8,
        "CCTV-8 ç”µè§†å‰§": 9, "CCTV-9 çºªå½•": 10, "CCTV-10 ç§‘æ•™": 11, "CCTV-11 æˆæ›²": 12,
        "CCTV-12 ç¤¾ä¼šä¸æ³•": 13, "CCTV-13 æ–°é—»": 14, "CCTV-14 å°‘å„¿": 15, "CCTV-15 éŸ³ä¹": 16,
        "CCTV-16 å¥¥æ—åŒ¹å…‹": 17, "CCTV-17 å†œä¸šå†œæ‘": 18, "CCTV-4K è¶…é«˜æ¸…": 19
    },
    
    # å«è§†æŒ‰æ‹¼éŸ³é¡ºåºï¼ˆå¸¸ç”¨å«è§†åœ¨å‰ï¼‰
    "å«è§†": {
        "åŒ—äº¬å«è§†": 1, "ä¸Šæµ·ä¸œæ–¹å«è§†": 2, "å¤©æ´¥å«è§†": 3, "é‡åº†å«è§†": 4,
        "æ²³åŒ—å«è§†": 5, "å±±è¥¿å«è§†": 6, "è¾½å®å«è§†": 7, "å‰æ—å«è§†": 8,
        "é»‘é¾™æ±Ÿå«è§†": 9, "æ±Ÿè‹å«è§†": 10, "æµ™æ±Ÿå«è§†": 11, "å®‰å¾½å«è§†": 12,
        "ç¦å»ºå«è§†": 13, "æ±Ÿè¥¿å«è§†": 14, "å±±ä¸œå«è§†": 15, "æ²³å—å«è§†": 16,
        "æ¹–åŒ—å«è§†": 17, "æ¹–å—å«è§†": 18, "å¹¿ä¸œå«è§†": 19, "å¹¿è¥¿å«è§†": 20,
        "æµ·å—å«è§†": 21, "å››å·å«è§†": 22, "è´µå·å«è§†": 23, "äº‘å—å«è§†": 24,
        "é™•è¥¿å«è§†": 25, "ç”˜è‚ƒå«è§†": 26, "é’æµ·å«è§†": 27, "å®å¤å«è§†": 28,
        "æ–°ç–†å«è§†": 29, "å†…è’™å¤å«è§†": 30, "è¥¿è—å«è§†": 31
    }
}

# çœä»½åˆ—è¡¨ï¼ˆç”¨äºåœ°æ–¹å°åˆ†ç±»ï¼‰
PROVINCES = [
    "åŒ—äº¬å¸‚", "å¤©æ´¥å¸‚", "æ²³åŒ—çœ", "å±±è¥¿çœ", "å†…è’™å¤è‡ªæ²»åŒº",
    "è¾½å®çœ", "å‰æ—çœ", "é»‘é¾™æ±Ÿçœ", "ä¸Šæµ·å¸‚", "æ±Ÿè‹çœ",
    "æµ™æ±Ÿçœ", "å®‰å¾½çœ", "ç¦å»ºçœ", "æ±Ÿè¥¿çœ", "å±±ä¸œçœ",
    "æ²³å—çœ", "æ¹–åŒ—çœ", "æ¹–å—çœ", "å¹¿ä¸œçœ", "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
    "æµ·å—çœ", "é‡åº†å¸‚", "å››å·çœ", "è´µå·çœ", "äº‘å—çœ",
    "è¥¿è—è‡ªæ²»åŒº", "é™•è¥¿çœ", "ç”˜è‚ƒçœ", "é’æµ·çœ", "å®å¤å›æ—è‡ªæ²»åŒº",
    "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº", "å°æ¹¾çœ", "é¦™æ¸¯", "æ¾³é—¨"
]

# çœä»½ç®€ç§°æ˜ å°„
PROVINCE_ABBR = {
    "åŒ—äº¬": "åŒ—äº¬å¸‚", "å¤©æ´¥": "å¤©æ´¥å¸‚", "æ²³åŒ—": "æ²³åŒ—çœ", "å±±è¥¿": "å±±è¥¿çœ",
    "å†…è’™å¤": "å†…è’™å¤è‡ªæ²»åŒº", "è¾½å®": "è¾½å®çœ", "å‰æ—": "å‰æ—çœ", "é»‘é¾™æ±Ÿ": "é»‘é¾™æ±Ÿçœ",
    "ä¸Šæµ·": "ä¸Šæµ·å¸‚", "æ±Ÿè‹": "æ±Ÿè‹çœ", "æµ™æ±Ÿ": "æµ™æ±Ÿçœ", "å®‰å¾½": "å®‰å¾½çœ",
    "ç¦å»º": "ç¦å»ºçœ", "æ±Ÿè¥¿": "æ±Ÿè¥¿çœ", "å±±ä¸œ": "å±±ä¸œçœ", "æ²³å—": "æ²³å—çœ",
    "æ¹–åŒ—": "æ¹–åŒ—çœ", "æ¹–å—": "æ¹–å—çœ", "å¹¿ä¸œ": "å¹¿ä¸œçœ", "å¹¿è¥¿": "å¹¿è¥¿å£®æ—è‡ªæ²»åŒº",
    "æµ·å—": "æµ·å—çœ", "é‡åº†": "é‡åº†å¸‚", "å››å·": "å››å·çœ", "è´µå·": "è´µå·çœ",
    "äº‘å—": "äº‘å—çœ", "è¥¿è—": "è¥¿è—è‡ªæ²»åŒº", "é™•è¥¿": "é™•è¥¿çœ", "ç”˜è‚ƒ": "ç”˜è‚ƒçœ",
    "é’æµ·": "é’æµ·çœ", "å®å¤": "å®å¤å›æ—è‡ªæ²»åŒº", "æ–°ç–†": "æ–°ç–†ç»´å¾å°”è‡ªæ²»åŒº",
    "å°æ¹¾": "å°æ¹¾çœ", "é¦™æ¸¯": "é¦™æ¸¯", "æ¾³é—¨": "æ¾³é—¨"
}

# åˆ†ç±»è§„åˆ™ - æŒ‰ä¼˜å…ˆçº§é¡ºåºåŒ¹é…
CATEGORY_RULES = {
    # å¤®è§† - æœ€å…·ä½“ï¼Œæœ€å…ˆåŒ¹é…
    "å¤®è§†": [
        r"^CCTV[-\s]?[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+",  # CCTV1, CCTV-1, CCTVä¸€
        r"^å¤®è§†[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+",  # å¤®è§†ä¸€, å¤®è§†äºŒ
        r"^ä¸­å¤®ç”µè§†å°",  # ä¸­å¤®ç”µè§†å°
        r"^CCTV[-\s]?4K", r"^CCTV[-\s]?8K", r"^CCTV[-\s]?5\+",
        r"^CCTV[-\s]?ç»¼åˆ$", r"^CCTV[-\s]?è´¢ç»$", r"^CCTV[-\s]?ç»¼è‰º$",
        r"^CCTV[-\s]?ä½“è‚²$", r"^CCTV[-\s]?ç”µå½±$", r"^CCTV[-\s]?ç”µè§†å‰§$",
    ],
    
    # å«è§†
    "å«è§†": [
        r"å«è§†$",  # ä»¥"å«è§†"ç»“å°¾
        r"^åŒ—äº¬å«è§†$", r"^æ¹–å—å«è§†$", r"^æµ™æ±Ÿå«è§†$", r"^æ±Ÿè‹å«è§†$",
        r"^ä¸œæ–¹å«è§†$", r"^å¤©æ´¥å«è§†$", r"^å®‰å¾½å«è§†$", r"^å±±ä¸œå«è§†$",
        r"^å¹¿ä¸œå«è§†$", r"^æ·±åœ³å«è§†$", r"^é»‘é¾™æ±Ÿå«è§†$", r"^è¾½å®å«è§†$",
        r"^æ¹–åŒ—å«è§†$", r"^æ²³å—å«è§†$", r"^å››å·å«è§†$", r"^é‡åº†å«è§†$",
        r"^æ±Ÿè¥¿å«è§†$", r"^å¹¿è¥¿å«è§†$", r"^ä¸œå—å«è§†$", r"^è´µå·å«è§†$",
        r"^äº‘å—å«è§†$", r"^é™•è¥¿å«è§†$", r"^å±±è¥¿å«è§†$", r"^æ²³åŒ—å«è§†$",
        r"^æµ·å—å«è§†$", r"^å®å¤å«è§†$", r"^æ–°ç–†å«è§†$", r"^å†…è’™å¤å«è§†$",
    ],
    
    # æ™¯åŒºé¢‘é“ï¼ˆæ–°å¢ï¼‰
    "æ™¯åŒºé¢‘é“": [
        r"æ™¯åŒº$", r"æ—…æ¸¸$", r"é£å…‰$", r"æ™¯ç‚¹$", r"å¯¼è§†$",
        r"^å³¨çœ‰å±±", r"^ä¹å¯¨æ²Ÿ", r"^é»„å±±", r"^æ³°å±±", r"^åå±±",
        r"^å¼ å®¶ç•Œ", r"^è¥¿æ¹–", r"^æ¼“æ±Ÿ", r"^é¼“æµªå±¿", r"^æ•…å®«",
        r"^é•¿åŸ", r"^å…µé©¬ä¿‘", r"^å¸ƒè¾¾æ‹‰å®«", r"^å¤©å®‰é—¨", r"^å¤–æ»©",
        r"^ç»´å¤šåˆ©äºšæ¸¯", r"^æ¾³é—¨å¡”", r"^æ—¥æœˆæ½­", r"^é˜¿é‡Œå±±"
    ],
    
    # å°‘å„¿å°
    "å°‘å„¿å°": [
        r"å°‘å„¿$", r"å¡é€š$", r"åŠ¨æ¼«$", r"åŠ¨ç”»$", r"é‡‘é¹°å¡é€š",
        r"å¡é…·å°‘å„¿", r"å“ˆå“ˆç‚«åŠ¨", r"ä¼˜æ¼«å¡é€š", r"å˜‰ä½³å¡é€š",
        r"ç‚«åŠ¨å¡é€š", r"å®è´"
    ],
    
    # ç»¼è‰ºå°
    "ç»¼è‰ºå°": [
        r"ç»¼è‰º$", r"æ–‡è‰º$", r"å¨±ä¹$", r"éŸ³ä¹$", r"æˆæ›²$",
        r"ç›¸å£°$", r"å°å“$", r"æ–‡åŒ–$", r"è‰ºæœ¯$"
    ],
    
    # æ¸¯æ¾³å°
    "æ¸¯æ¾³å°": [
        r"å‡¤å‡°", r"ç¿¡ç¿ ", r"æ˜ç ", r"TVB", r"ATV", r"æ¾³è§†",
        r"æ¾³é—¨", r"é¦™æ¸¯", r"å°æ¹¾", r"ä¸­å¤©", r"ä¸œæ£®", r"åè§†",
        r"æ°‘è§†", r"ä¸‰ç«‹", r"æ— çº¿"
    ],
    
    # ä½“è‚²å°
    "ä½“è‚²å°": [
        r"ä½“è‚²$", r"è¶³çƒ$", r"ç¯®çƒ$", r"NBA", r"CBA", r"è‹±è¶…",
        r"æ¬§å† $", r"é«˜å°”å¤«$", r"ç½‘çƒ$", r"ä¹’ç¾½$", r"æå‡»$",
        r"èµ›è½¦$", r"F1$", r"å¥¥è¿$", r"èµ›äº‹$"
    ],
    
    # å½±è§†å°
    "å½±è§†å°": [
        r"ç”µå½±$", r"å½±é™¢$", r"å½±è§†é¢‘é“$", r"å¥½è±å$", r"CHC",
        r"å®¶åº­å½±é™¢$", r"åŠ¨ä½œç”µå½±$", r"å–œå‰§ç”µå½±$"
    ]
}

# æ’­æ”¾å™¨å¤šæºæ”¯æŒé…ç½®
PLAYER_SUPPORT = {
    "PotPlayer": {
        "multi_source": True,
        "format": "stream-multi-url",
        "separator": "|",
        "note": "åœ¨æ’­æ”¾æ—¶æŒ‰Alt+Wå¯ä»¥åˆ‡æ¢æºï¼ŒIPv6æºä¼˜å…ˆæ’åˆ—"
    },
    "VLC": {
        "multi_source": True,
        "format": "stream-multi-url",
        "separator": "#",
        "note": "åœ¨æ’­æ”¾åˆ—è¡¨ä¸­ç‚¹å³é”®é€‰æ‹©ä¸åŒæºï¼ŒIPv6æºåœ¨å‰"
    },
    "TiviMate": {
        "multi_source": True,
        "format": "same-name",
        "separator": None,
        "note": "è‡ªåŠ¨åˆå¹¶ç›¸åŒåç§°çš„é¢‘é“ï¼Œæ’­æ”¾æ—¶è‡ªåŠ¨åˆ‡æ¢"
    },
    "Kodi": {
        "multi_source": True,
        "format": "m3u_plus",
        "separator": None,
        "note": "ä½¿ç”¨IPTV Simple Clientæ’ä»¶"
    }
}

# é»‘åå•ç®¡ç†å‡½æ•°
def load_blacklist():
    """åŠ è½½é»‘åå•"""
    blacklist = set()
    if os.path.exists(BLACKLIST_FILE):
        try:
            with open(BLACKLIST_FILE, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith("#"):
                        blacklist.add(line)
            print(f"ğŸ“‹ ä» {BLACKLIST_FILE} åŠ è½½äº† {len(blacklist)} ä¸ªé»‘åå•æ¡ç›®")
        except Exception as e:
            print(f"âš ï¸  è¯»å–é»‘åå•å¤±è´¥: {e}")
    else:
        print(f"ğŸ“ {BLACKLIST_FILE} æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶")
    return blacklist

def save_to_blacklist(slow_urls):
    """ä¿å­˜æ…¢é€ŸURLåˆ°é»‘åå•"""
    if not slow_urls:
        return
    
    # åŠ è½½ç°æœ‰é»‘åå•
    existing_blacklist = load_blacklist()
    
    # æ·»åŠ æ–°çš„æ…¢é€ŸURL
    existing_blacklist.update(slow_urls)
    
    try:
        with open(BLACKLIST_FILE, "w", encoding="utf-8") as f:
            f.write("# ç›´æ’­æºé»‘åå•\n")
            f.write("# è¯¥æ–‡ä»¶åŒ…å«å“åº”æ—¶é—´è¶…è¿‡6ç§’çš„æ…¢é€Ÿç›´æ’­æº\n")
            f.write("# æ¯è¡Œä¸€ä¸ªURLï¼Œä¸‹æ¬¡æ›´æ–°æ—¶ä¼šè·³è¿‡è¿™äº›æº\n")
            f.write("# ç”Ÿæˆæ—¶é—´: " + get_beijing_time() + "\n\n")
            
            # æ’åºåå†™å…¥
            for url in sorted(existing_blacklist):
                f.write(url + "\n")
        
        print(f"ğŸ“ å·²ä¿å­˜ {len(slow_urls)} ä¸ªæ…¢é€Ÿæºåˆ° {BLACKLIST_FILE}")
    except Exception as e:
        print(f"âŒ ä¿å­˜é»‘åå•å¤±è´¥: {e}")

def test_url_speed(url):
    """æµ‹è¯•URLé€Ÿåº¦ï¼Œè¿”å›å“åº”æ—¶é—´ï¼ˆç§’ï¼‰ï¼Œè¶…æ—¶è¿”å›None"""
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            "Accept": "*/*",
            "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
            "Connection": "close",
            "Cache-Control": "no-cache"
        }
        
        start_time = time.time()
        
        # ä½¿ç”¨stream=Trueï¼Œåªè·å–å¤´éƒ¨ä¿¡æ¯ï¼Œä¸ä¸‹è½½æ•´ä¸ªæ–‡ä»¶
        response = requests.get(url, headers=headers, timeout=SPEED_TEST_TIMEOUT, 
                               stream=True, allow_redirects=True)
        
        # åªè¯»å–ä¸€å°éƒ¨åˆ†æ•°æ®æ¥ç¡®è®¤è¿æ¥æ­£å¸¸
        response.close()
        
        end_time = time.time()
        response_time = end_time - start_time
        
        # æ£€æŸ¥HTTPçŠ¶æ€ç 
        if response.status_code >= 400:
            return None  # è¯·æ±‚å¤±è´¥
            
        return response_time
        
    except requests.exceptions.Timeout:
        return None  # è¶…æ—¶
    except requests.exceptions.ConnectionError:
        return None  # è¿æ¥é”™è¯¯
    except requests.exceptions.TooManyRedirects:
        return None  # é‡å®šå‘è¿‡å¤š
    except Exception as e:
        return None  # å…¶ä»–é”™è¯¯

def test_urls_with_progress(urls, blacklist):
    """å¹¶å‘æµ‹è¯•URLé€Ÿåº¦ï¼Œæ˜¾ç¤ºè¿›åº¦"""
    results = {}
    slow_urls = set()
    
    print(f"âš¡ å¼€å§‹é€Ÿåº¦æµ‹è¯•ï¼Œè¶…æ—¶æ—¶é—´: {SPEED_TEST_TIMEOUT}ç§’ï¼Œæœ€å¤§å¹¶å‘æ•°: {MAX_WORKERS}")
    print(f"ğŸ“Š éœ€è¦æµ‹è¯• {len(urls)} ä¸ªURL")
    
    # è¿‡æ»¤æ‰å·²ç»åœ¨é»‘åå•ä¸­çš„URL
    urls_to_test = [url for url in urls if url not in blacklist]
    
    if not urls_to_test:
        print("âœ… æ‰€æœ‰URLéƒ½åœ¨é»‘åå•ä¸­ï¼Œè·³è¿‡é€Ÿåº¦æµ‹è¯•")
        return results, slow_urls
    
    print(f"ğŸ” å®é™…éœ€è¦æµ‹è¯• {len(urls_to_test)} ä¸ªURL")
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æµ‹è¯•
    with concurrent.futures.ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤æ‰€æœ‰æµ‹è¯•ä»»åŠ¡
        future_to_url = {executor.submit(test_url_speed, url): url for url in urls_to_test}
        
        # è¿›åº¦ç»Ÿè®¡
        completed = 0
        total = len(urls_to_test)
        start_time = time.time()
        
        for future in concurrent.futures.as_completed(future_to_url):
            completed += 1
            url = future_to_url[future]
            
            try:
                speed = future.result()
                if speed is not None:
                    if speed <= SPEED_TEST_TIMEOUT:
                        results[url] = speed
                        
                        # æ¯æµ‹è¯•10ä¸ªURLæ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                        if completed % 10 == 0 or completed == total:
                            elapsed = time.time() - start_time
                            print(f"  â³ è¿›åº¦: {completed}/{total} ({completed/total*100:.1f}%) - "
                                  f"å·²ç”¨æ—¶: {elapsed:.1f}ç§’ - æœ€æ–°: {url[:50]}... - é€Ÿåº¦: {speed:.2f}ç§’")
                    else:
                        slow_urls.add(url)
                        print(f"  ğŸŒ æ…¢é€Ÿæº: {url[:60]}... - å“åº”æ—¶é—´: {speed:.2f}ç§’")
                else:
                    slow_urls.add(url)
                    print(f"  âŒ å¤±è´¥æº: {url[:60]}... - è¿æ¥å¤±è´¥")
                    
            except Exception as e:
                slow_urls.add(url)
                print(f"  âš ï¸  å¼‚å¸¸æº: {url[:60]}... - é”™è¯¯: {str(e)[:50]}")
    
    print(f"âœ… é€Ÿåº¦æµ‹è¯•å®Œæˆ")
    print(f"  å¿«é€Ÿæº: {len(results)} ä¸ª")
    print(f"  æ…¢é€Ÿæº: {len(slow_urls)} ä¸ª")
    
    return results, slow_urls

def get_beijing_time():
    """è·å–ä¸œå…«åŒºåŒ—äº¬æ—¶é—´"""
    utc_now = datetime.now(timezone.utc)
    beijing_time = utc_now.astimezone(timezone(timedelta(hours=8)))
    return beijing_time.strftime('%Y-%m-%d %H:%M:%S')

def chinese_to_arabic(chinese_num):
    """ä¸­æ–‡æ•°å­—è½¬é˜¿æ‹‰ä¼¯æ•°å­—"""
    if chinese_num in CHINESE_NUMBERS:
        return CHINESE_NUMBERS[chinese_num]
    return chinese_num

def standardize_cctv_name(name):
    """æ ‡å‡†åŒ–CCTVé¢‘é“åç§°ï¼Œç¡®ä¿CCTVå¤§å†™"""
    original_name = name
    
    # å°†cctvå°å†™è½¬ä¸ºå¤§å†™
    if 'cctv' in name.lower():
        name = re.sub(r'cctv', 'CCTV', name, flags=re.IGNORECASE)
    
    # é¦–å…ˆå°è¯•åŒ¹é…CCTV_MAPPINGä¸­çš„è§„åˆ™
    for pattern, replacement in CCTV_MAPPING.items():
        if re.match(pattern, name, re.IGNORECASE):
            if '{num}' in replacement:
                # æå–æ•°å­—éƒ¨åˆ†
                match = re.search(r'[\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+', name)
                if match:
                    num = chinese_to_arabic(match.group())
                    return replacement.replace('{num}', num)
            return replacement
    
    # å¤„ç†CCTV-æ•°å­—æ ¼å¼
    cctv_match = re.match(r'^CCTV[_\-\s]?([\dä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)(?:\s+(.+))?$', name, re.IGNORECASE)
    if cctv_match:
        num = chinese_to_arabic(cctv_match.group(1))
        suffix = cctv_match.group(2) or ""
        
        # æ ¹æ®æ•°å­—ç¡®å®šé¢‘é“åç§°
        cctv_names = {
            '1': 'ç»¼åˆ', '2': 'è´¢ç»', '3': 'ç»¼è‰º', '4': 'ä¸­æ–‡å›½é™…',
            '5': 'ä½“è‚²', '5+': 'ä½“è‚²èµ›äº‹', '6': 'ç”µå½±', '7': 'å›½é˜²å†›äº‹',
            '8': 'ç”µè§†å‰§', '9': 'çºªå½•', '10': 'ç§‘æ•™', '11': 'æˆæ›²',
            '12': 'ç¤¾ä¼šä¸æ³•', '13': 'æ–°é—»', '14': 'å°‘å„¿', '15': 'éŸ³ä¹',
            '16': 'å¥¥æ—åŒ¹å…‹', '17': 'å†œä¸šå†œæ‘'
        }
        
        if num in cctv_names:
            channel_name = cctv_names[num]
            return f"CCTV-{num} {channel_name}"
        else:
            if suffix:
                return f"CCTV-{num} {suffix}"
            else:
                return f"CCTV-{num}"
    
    # å¤„ç†å¤®è§†å¼€å¤´
    if name.startswith('å¤®è§†'):
        match = re.match(r'^å¤®è§†([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+)(?:\s+(.+))?$', name)
        if match:
            num = chinese_to_arabic(match.group(1))
            suffix = match.group(2) or ""
            return f"CCTV-{num} {suffix}"
    
    return original_name

def clean_channel_name(name):
    """æ·±åº¦æ¸…ç†é¢‘é“åç§°ï¼Œç§»é™¤å†—ä½™ä¿¡æ¯ï¼Œç»Ÿä¸€CCTVå¤§å†™"""
    original_name = name
    
    # æ·±åº¦æ¸…ç†ï¼šåº”ç”¨æ‰€æœ‰æ¸…ç†è§„åˆ™
    for pattern, replacement in CLEAN_RULES:
        name = re.sub(pattern, replacement, name, flags=re.IGNORECASE)
    
    # é¢å¤–æ¸…ç†ï¼šç§»é™¤é‡å¤è¯
    name = re.sub(r'\b(\w+)(?:\s+\1)+\b', r'\1', name)
    
    # æ ‡å‡†åŒ–CCTVåç§°
    if re.match(r'^(CCTV|å¤®è§†|ä¸­å¤®ç”µè§†å°)', name, re.IGNORECASE):
        name = standardize_cctv_name(name)
    
    # ç»Ÿä¸€å«è§†å‘½å
    if name.endswith('å«è§†') and len(name) > 2:
        # ç§»é™¤å«è§†å‰çš„å¤šä½™ç©ºæ ¼
        name = re.sub(r'\s+å«è§†$', 'å«è§†', name)
    
    # å¼ºåˆ¶å°†cctvè½¬ä¸ºCCTVï¼ˆå¤§å°å†™ç»Ÿä¸€ï¼‰
    if 'cctv' in name.lower():
        name = re.sub(r'cctv', 'CCTV', name, flags=re.IGNORECASE)
    
    # æœ€ç»ˆæ¸…ç†
    name = re.sub(r'\s+', ' ', name)  # åˆå¹¶å¤šä¸ªç©ºæ ¼
    name = name.strip()
    
    # å¦‚æœæ¸…ç†åä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹åç§°
    if not name or len(name) < 2:
        name = original_name
    
    return name

def get_channel_sort_key(channel_name, category):
    """è·å–é¢‘é“æ’åºé”®å€¼"""
    if category in CHANNEL_ORDER_RULES:
        if channel_name in CHANNEL_ORDER_RULES[category]:
            return (0, CHANNEL_ORDER_RULES[category][channel_name])
        else:
            # æŸ¥æ‰¾åŒ¹é…çš„æ¨¡å¼
            for pattern, order in CHANNEL_ORDER_RULES[category].items():
                if pattern in channel_name:
                    return (1, order, channel_name)
    
    # æŒ‰å­—æ¯é¡ºåºæ’åº
    return (2, channel_name)

def categorize_channel(channel_name):
    """ä¸ºé¢‘é“åˆ†ç±»ï¼Œæ”¯æŒçœä»½åˆ†ç±»"""
    # æŒ‰ä¼˜å…ˆçº§é¡ºåºåŒ¹é…åˆ†ç±»è§„åˆ™
    for category, patterns in CATEGORY_RULES.items():
        for pattern in patterns:
            try:
                if re.search(pattern, channel_name, re.IGNORECASE):
                    return category
            except re.error:
                # å¦‚æœæ­£åˆ™è¡¨è¾¾å¼æœ‰è¯¯ï¼Œå°è¯•ç›´æ¥å­—ç¬¦ä¸²åŒ¹é…
                if pattern.lower() in channel_name.lower():
                    return category
    
    # å°è¯•åŒ¹é…çœä»½åˆ†ç±»
    for province_full in PROVINCES:
        if province_full in channel_name:
            return province_full
    
    # å°è¯•åŒ¹é…çœä»½ç®€ç§°
    for abbr, full in PROVINCE_ABBR.items():
        if abbr in channel_name and len(abbr) >= 2:
            return full
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…åˆ°ä»»ä½•è§„åˆ™ï¼Œè¿”å›"å…¶ä»–å°"
    return "å…¶ä»–å°"

def fetch_m3u(url, retry=2):
    """è·å–M3Uæ–‡ä»¶ï¼Œæ”¯æŒé‡è¯•"""
    for attempt in range(retry + 1):
        try:
            headers = {
                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                "Accept": "text/plain,application/x-mpegURL,*/*",
                "Accept-Language": "zh-CN,zh;q=0.9,en;q=0.8",
                "Connection": "keep-alive",
                "Cache-Control": "no-cache"
            }
            response = requests.get(url, headers=headers, timeout=15)
            response.encoding = 'utf-8'
            
            if response.status_code == 200:
                return response.text
            else:
                print(f"âŒ è·å–å¤±è´¥ {url}: HTTP {response.status_code} (å°è¯• {attempt + 1}/{retry + 1})")
                if attempt < retry:
                    time.sleep(2)
                
        except requests.exceptions.Timeout:
            print(f"âŒ è¯·æ±‚è¶…æ—¶ {url} (å°è¯• {attempt + 1}/{retry + 1})")
            if attempt < retry:
                time.sleep(2)
        except requests.exceptions.ConnectionError:
            print(f"âŒ è¿æ¥é”™è¯¯ {url} (å°è¯• {attempt + 1}/{retry + 1})")
            if attempt < retry:
                time.sleep(2)
        except Exception as e:
            print(f"âŒ è¯·æ±‚é”™è¯¯ {url}: {e} (å°è¯• {attempt + 1}/{retry + 1})")
            if attempt < retry:
                time.sleep(2)
    
    return None

def parse_channels(content, source_url):
    """è§£æM3Uå†…å®¹ï¼Œè¿”å›é¢‘é“åˆ—è¡¨"""
    channels = []
    lines = content.split('\n')
    i = 0
    
    while i < len(lines):
        line = lines[i].strip()
        if line.startswith('#EXTINF:'):
            # æå–é¢‘é“åç§°
            name = "æœªçŸ¥é¢‘é“"
            match = re.search(r',([^,\n]+)$', line)
            if match:
                name = match.group(1).strip()
            
            # æå–åˆ†ç»„
            group = None
            match = re.search(r'group-title="([^"]+)"', line)
            if match:
                group = match.group(1).strip()
            
            # æå–logo
            logo = None
            match = re.search(r'tvg-logo="([^"]+)"', line)
            if match:
                logo = match.group(1).strip()
            
            # æå–æ¸…æ™°åº¦ä¿¡æ¯
            quality = "æœªçŸ¥"
            if re.search(r'4K|è¶…æ¸…|UHD|2160', name, re.IGNORECASE):
                quality = "4K"
            elif re.search(r'é«˜æ¸…|HD|1080|FHD', name, re.IGNORECASE):
                quality = "é«˜æ¸…"
            elif re.search(r'æ ‡æ¸…|SD|720', name, re.IGNORECASE):
                quality = "æ ‡æ¸…"
            elif re.search(r'æµç•…|360|480', name, re.IGNORECASE):
                quality = "æµç•…"
            
            # è·å–URL
            if i + 1 < len(lines):
                url = lines[i + 1].strip()
                if url and not url.startswith('#'):
                    # æ·±åº¦æ¸…ç†é¢‘é“åç§°
                    clean_name = clean_channel_name(name)
                    
                    channels.append({
                        'original_name': name,
                        'clean_name': clean_name,
                        'url': url,
                        'group': group,
                        'logo': logo,
                        'quality': quality,
                        'source': source_url,
                        'extinf_line': line
                    })
                    i += 1
        i += 1
    
    return channels

def merge_channels(all_channels, speed_test_results=None):
    """åˆå¹¶åŒåç”µè§†å°ï¼Œæ”¯æŒå¤šæºï¼ŒIPv6ä¼˜å…ˆæ’åºï¼Œè¿‡æ»¤é»‘åå•"""
    merged = {}
    
    for channel in all_channels:
        key = channel['clean_name']
        
        if key not in merged:
            # åˆ›å»ºæ–°çš„åˆå¹¶é¢‘é“
            merged[key] = {
                'clean_name': key,
                'original_names': [channel['original_name']],
                'sources': [{
                    'url': channel['url'],
                    'quality': channel['quality'],
                    'source': channel['source'],
                    'logo': channel['logo'],
                    'priority': 0,  # ç¨åè®¡ç®—
                    'is_ipv6': False,  # ç¨åè®¡ç®—
                    'speed': speed_test_results.get(channel['url'], None) if speed_test_results else None
                }],
                'logos': [],
                'categories': set(),
                'first_seen': channel
            }
            
            # æ”¶é›†logo
            if channel['logo']:
                merged[key]['logos'].append(channel['logo'])
            
            # ç¡®å®šåˆ†ç±»
            category = categorize_channel(key)
            merged[key]['categories'].add(category)
        else:
            # æ·»åŠ åˆ°ç°æœ‰é¢‘é“
            merged[key]['original_names'].append(channel['original_name'])
            
            # æ£€æŸ¥URLæ˜¯å¦å·²å­˜åœ¨ï¼Œé¿å…é‡å¤
            urls = [s['url'] for s in merged[key]['sources']]
            if channel['url'] not in urls:
                merged[key]['sources'].append({
                    'url': channel['url'],
                    'quality': channel['quality'],
                    'source': channel['source'],
                    'logo': channel['logo'],
                    'priority': 0,  # ç¨åè®¡ç®—
                    'is_ipv6': False,  # ç¨åè®¡ç®—
                    'speed': speed_test_results.get(channel['url'], None) if speed_test_results else None
                })
            
            # æ”¶é›†logo
            if channel['logo'] and channel['logo'] not in merged[key]['logos']:
                merged[key]['logos'].append(channel['logo'])
            
            # æ›´æ–°åˆ†ç±»
            category = categorize_channel(key)
            merged[key]['categories'].add(category)
    
    # ä¸ºæ¯ä¸ªé¢‘é“çš„æºè®¡ç®—ä¼˜å…ˆçº§å¹¶æ’åº
    for key in merged:
        # è®¡ç®—æ¯ä¸ªæºçš„ä¼˜å…ˆçº§å’ŒIPv6çŠ¶æ€
        for source in merged[key]['sources']:
            source['is_ipv6'] = is_ipv6_url(source['url'])
            source['priority'] = get_source_priority(source)
        
        # æŒ‰ä¼˜å…ˆçº§é™åºæ’åºï¼ˆä¼˜å…ˆçº§é«˜çš„åœ¨å‰ï¼ŒIPv6ä¼˜å…ˆï¼‰
        merged[key]['sources'].sort(key=lambda x: x['priority'], reverse=True)
        
        # ä¸ºæ¯ä¸ªåˆå¹¶åçš„é¢‘é“é€‰æ‹©ä¸€ä¸ªä¸»åˆ†ç±»
        categories = list(merged[key]['categories'])
        if categories:
            # ä¼˜å…ˆé€‰æ‹©é"å…¶ä»–å°"çš„åˆ†ç±»
            non_other = [c for c in categories if c != "å…¶ä»–å°"]
            if non_other:
                merged[key]['category'] = non_other[0]
            else:
                merged[key]['category'] = "å…¶ä»–å°"
        else:
            merged[key]['category'] = "å…¶ä»–å°"
    
    return merged

def generate_multi_source_m3u(merged_channels, categories, final_category_order, timestamp, output_file, mode="multi"):
    """
    ç”Ÿæˆæ”¯æŒå¤šæºçš„M3Uæ–‡ä»¶
    mode: 
      "multi" - å¤šæºåˆå¹¶æˆä¸€ä¸ªæ¡ç›®ï¼ˆPotPlayeræ ¼å¼ï¼‰
      "separate" - æ¯ä¸ªæºåˆ†å¼€æ¡ç›®ä½†ç›¸åŒåç§°
      "single" - åªä¿ç•™æœ€ä½³æº
    """
    try:
        with open(output_file, "w", encoding="utf-8") as f:
            f.write("#EXTM3U\n")
            if mode == "multi":
                f.write(f"# ç”µè§†ç›´æ’­æº - IPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆï¼ˆå¸¦é»‘åå•è¿‡æ»¤ï¼‰\n")
                f.write(f"# æ¯ä¸ªç”µè§†å°åªæ˜¾ç¤ºä¸€ä¸ªæ¡ç›®ï¼ŒIPv6æºä¼˜å…ˆæ’åˆ—\n")
                f.write(f"# æ’­æ”¾å™¨åˆ‡æ¢æºæ–¹æ³•ï¼šPotPlayeræŒ‰Alt+Wï¼ŒVLCå³é”®é€‰æ‹©æº\n")
                f.write(f"# æ’åºè§„åˆ™ï¼šIPv6æº > 4K > é«˜æ¸… > æ ‡æ¸… > æµç•…\n")
                f.write(f"# å·²è¿‡æ»¤é»‘åå•æ…¢é€Ÿæºï¼ˆå“åº”æ—¶é—´ > {SPEED_TEST_TIMEOUT}ç§’ï¼‰\n")
            elif mode == "separate":
                f.write(f"# ç”µè§†ç›´æ’­æº - IPv6ä¼˜å…ˆå¤šæºåˆ†ç¦»ç‰ˆï¼ˆå¸¦é»‘åå•è¿‡æ»¤ï¼‰\n")
                f.write(f"# åŒåç”µè§†å°æ˜¾ç¤ºä¸ºå¤šä¸ªæ¡ç›®ï¼ŒIPv6æºä¼˜å…ˆï¼Œæ’­æ”¾å™¨è‡ªåŠ¨åˆå¹¶\n")
                f.write(f"# å·²è¿‡æ»¤é»‘åå•æ…¢é€Ÿæºï¼ˆå“åº”æ—¶é—´ > {SPEED_TEST_TIMEOUT}ç§’ï¼‰\n")
            else:
                f.write(f"# ç”µè§†ç›´æ’­æº - IPv6ä¼˜å…ˆç²¾ç®€ç‰ˆï¼ˆå¸¦é»‘åå•è¿‡æ»¤ï¼‰\n")
                f.write(f"# æ¯ä¸ªç”µè§†å°åªä¿ç•™æœ€ä½³æºï¼ˆIPv6ä¼˜å…ˆï¼‰\n")
                f.write(f"# å·²è¿‡æ»¤é»‘åå•æ…¢é€Ÿæºï¼ˆå“åº”æ—¶é—´ > {SPEED_TEST_TIMEOUT}ç§’ï¼‰\n")
            
            f.write(f"# æ›´æ–°æ—¶é—´(åŒ—äº¬æ—¶é—´): {timestamp}\n")
            f.write(f"# ç”µè§†å°æ€»æ•°: {len(merged_channels)}\n")
            f.write(f"# åŸå§‹é¢‘é“æ•°: {len(all_channels)}\n")
            f.write(f"# æ•°æ®æº: {len(sources)} ä¸ª (æˆåŠŸ: {success_sources}, å¤±è´¥: {len(failed_sources)})\n")
            f.write(f"# ç‰¹ç‚¹: ç§»é™¤æŠ€æœ¯å‚æ•°ï¼Œç»Ÿä¸€å¤®è§†é¢‘é“å‘½åï¼ŒæŒ‰çœä»½åˆ†ç±»åœ°æ–¹å°ï¼ŒIPv6ä¼˜å…ˆï¼Œé»‘åå•è¿‡æ»¤\n")
            f.write(f"# æºæ–‡ä»¶: sources.txt\n")
            f.write(f"# é»‘åå•: {BLACKLIST_FILE}\n\n")
            
            # æŒ‰åˆ†ç±»é¡ºåºå†™å…¥
            for category in final_category_order:
                cat_channels = categories[category]
                if cat_channels:
                    # å¯¹é¢‘é“è¿›è¡Œæ’åº
                    sorted_channels = sorted(
                        cat_channels,
                        key=lambda x: get_channel_sort_key(x['clean_name'], category)
                    )
                    
                    f.write(f"\n# åˆ†ç±»: {category} ({len(cat_channels)}ä¸ªç”µè§†å°)\n")
                    
                    for channel in sorted_channels:
                        # é€‰æ‹©ä¸»logoï¼ˆç¬¬ä¸€ä¸ªéç©ºçš„logoï¼‰
                        main_logo = channel['logos'][0] if channel['logos'] else ""
                        source_count = len(channel['sources'])
                        
                        # ç»Ÿè®¡IPv6æºæ•°é‡
                        ipv6_count = sum(1 for s in channel['sources'] if s.get('is_ipv6', False))
                        
                        # ç»Ÿè®¡å¿«é€Ÿæºæ•°é‡ï¼ˆé€Ÿåº¦ä¿¡æ¯ï¼‰
                        fast_sources = [s for s in channel['sources'] if s.get('speed') and s['speed'] <= 2.0]
                        fast_count = len(fast_sources)
                        
                        if mode == "multi":
                            # PotPlayer/VLCå¤šæºæ ¼å¼ï¼šä¸€ä¸ªæ¡ç›®åŒ…å«å¤šä¸ªURLï¼Œç”¨"|"åˆ†éš”
                            source_desc = []
                            if ipv6_count > 0:
                                source_desc.append(f"{ipv6_count}IPv6")
                            if fast_count > 0:
                                source_desc.append(f"{fast_count}å¿«é€Ÿ")
                            if source_count > ipv6_count:
                                source_desc.append(f"{source_count}æº")
                            
                            if source_desc:
                                display_name = f"{channel['clean_name']} [{'+'.join(source_desc)}]"
                            else:
                                display_name = f"{channel['clean_name']} [{source_count}æº]"
                            
                            # æ”¶é›†æ‰€æœ‰URLï¼ˆå·²æŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
                            urls = []
                            qualities = []
                            ipv6_sources = []
                            ipv4_sources = []
                            
                            for source in channel['sources']:
                                if source.get('is_ipv6', False):
                                    ipv6_sources.append(source)
                                else:
                                    ipv4_sources.append(source)
                            
                            # ç¡®ä¿IPv6æºåœ¨å‰é¢
                            sorted_sources = ipv6_sources + ipv4_sources
                            
                            for source in sorted_sources:
                                urls.append(source['url'])
                                if source['quality'] != "æœªçŸ¥":
                                    qualities.append(source['quality'])
                            
                            # ç”Ÿæˆå¤šæºURL
                            multi_url = "|".join(urls)
                            
                            # å†™å…¥æ¡ç›®
                            line = "#EXTINF:-1"
                            line += f' tvg-name="{channel["clean_name"]}"'
                            line += f' group-title="{category}"'
                            if main_logo:
                                line += f' tvg-logo="{main_logo}"'
                            if qualities:
                                quality_desc = "/".join(sorted(set(qualities), key=lambda x: ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"].index(x) if x in ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"] else 10))
                                line += f' tvg-quality="{quality_desc}"'
                            if ipv6_count > 0:
                                line += f' tvg-ipv6="true"'
                            line += f',{display_name}\n'
                            line += f"{multi_url}\n"
                            f.write(line)
                            
                        elif mode == "separate":
                            # TiviMate/Kodiæ ¼å¼ï¼šç›¸åŒåç§°çš„å¤šä¸ªæ¡ç›®ï¼ŒIPv6æºä¼˜å…ˆ
                            display_name = channel['clean_name']
                            
                            # åˆ†ç¦»IPv6å’ŒIPv4æº
                            ipv6_sources = []
                            ipv4_sources = []
                            for source in channel['sources']:
                                if source.get('is_ipv6', False):
                                    ipv6_sources.append(source)
                                else:
                                    ipv4_sources.append(source)
                            
                            # ç¡®ä¿IPv6æºåœ¨å‰é¢
                            sorted_sources = ipv6_sources + ipv4_sources
                            
                            for i, source in enumerate(sorted_sources, 1):
                                source_type = "IPv6" if source.get('is_ipv6', False) else "IPv4"
                                speed_info = ""
                                if source.get('speed'):
                                    speed_info = f" ({source['speed']:.1f}s)"
                                
                                line = "#EXTINF:-1"
                                line += f' tvg-name="{channel["clean_name"]}"'
                                line += f' group-title="{category}"'
                                if main_logo:
                                    line += f' tvg-logo="{main_logo}"'
                                if source['quality'] != "æœªçŸ¥":
                                    line += f' tvg-quality="{source["quality"]}"'
                                if source.get('is_ipv6', False):
                                    line += f' tvg-ipv6="true"'
                                if source_count > 1:
                                    line += f',{display_name} [{source_type}æº{i}{speed_info}]\n'
                                else:
                                    line += f',{display_name}{speed_info}\n'
                                line += f"{source['url']}\n"
                                f.write(line)
                                
                        else:  # mode == "single"
                            # ç²¾ç®€ç‰ˆï¼šåªä¿ç•™æœ€ä½³æºï¼ˆIPv6ä¼˜å…ˆï¼‰
                            display_name = channel['clean_name']
                            
                            # é€‰æ‹©æœ€ä½³æºï¼ˆä¼˜å…ˆé€‰æ‹©IPv6å¿«é€Ÿæºï¼‰
                            best_source = None
                            
                            # é¦–å…ˆæ‰¾IPv6å¿«é€Ÿæº
                            for source in channel['sources']:
                                if source.get('is_ipv6', False) and source.get('speed') and source['speed'] <= 2.0:
                                    best_source = source
                                    break
                            
                            # ç„¶åæ‰¾IPv6é«˜æ¸…æº
                            if not best_source:
                                for source in channel['sources']:
                                    if source.get('is_ipv6', False) and source['quality'] == "é«˜æ¸…":
                                        best_source = source
                                        break
                            
                            # ç„¶åæ‰¾IPv4å¿«é€Ÿæº
                            if not best_source:
                                for source in channel['sources']:
                                    if not source.get('is_ipv6', False) and source.get('speed') and source['speed'] <= 2.0:
                                        best_source = source
                                        break
                            
                            # ç„¶åæ‰¾IPv4é«˜æ¸…æº
                            if not best_source:
                                for source in channel['sources']:
                                    if not source.get('is_ipv6', False) and source['quality'] == "é«˜æ¸…":
                                        best_source = source
                                        break
                            
                            # æœ€åé€‰ç¬¬ä¸€ä¸ªæº
                            if not best_source:
                                best_source = channel['sources'][0]
                            
                            line = "#EXTINF:-1"
                            line += f' tvg-name="{channel["clean_name"]}"'
                            line += f' group-title="{category}"'
                            if main_logo:
                                line += f' tvg-logo="{main_logo}"'
                            if best_source['quality'] != "æœªçŸ¥":
                                line += f' tvg-quality="{best_source["quality"]}"'
                            if best_source.get('is_ipv6', False):
                                line += f' tvg-ipv6="true"'
                                display_name = f"{display_name} [IPv6]"
                            if best_source.get('speed'):
                                line += f' tvg-speed="{best_source["speed"]:.1f}s"'
                                display_name = f"{display_name} ({best_source['speed']:.1f}s)"
                            line += f',{display_name}\n'
                            line += f"{best_source['url']}\n"
                            f.write(line)
        
        print(f"  âœ… {output_file} ç”ŸæˆæˆåŠŸ")
        return True
    except Exception as e:
        print(f"  âŒ ç”Ÿæˆ{output_file}å¤±è´¥: {e}")
        return False

# ä¸»æ”¶é›†è¿‡ç¨‹
print("ğŸš€ å¼€å§‹é‡‡é›†ç”µè§†ç›´æ’­æº...")

# 1. åŠ è½½é»‘åå•
print("ğŸ“‹ åŠ è½½é»‘åå•...")
blacklist = load_blacklist()

print(f"ğŸ“‹ æ•°æ®æºåˆ—è¡¨ (ä»sources.txtåŠ è½½):")
for i, source in enumerate(sources, 1):
    print(f"  {i:2d}. {source}")

all_channels = []
success_sources = 0
failed_sources = []

# 2. æ”¶é›†æ‰€æœ‰é¢‘é“çš„åŸå§‹æ•°æ®
print("\nğŸ“¡ å¼€å§‹æ”¶é›†é¢‘é“æ•°æ®...")
for idx, source_url in enumerate(sources, 1):
    print(f"\n[{idx}/{len(sources)}] å¤„ç†: {source_url}")
    
    content = fetch_m3u(source_url)
    if not content:
        failed_sources.append(source_url)
        print("   âŒ æ— æ³•è·å–å†…å®¹ï¼Œè·³è¿‡")
        continue
    
    channels = parse_channels(content, source_url)
    
    # ç»Ÿè®¡é¢‘é“åç§°å˜åŒ–
    changed_count = 0
    for channel in channels:
        if channel['original_name'] != channel['clean_name']:
            changed_count += 1
    
    print(f"   âœ… è§£æåˆ° {len(channels)} ä¸ªé¢‘é“ ({changed_count}ä¸ªå·²ç²¾ç®€)")
    
    if changed_count > 0 and len(channels) <= 10:
        for channel in channels[:5]:
            if channel['original_name'] != channel['clean_name']:
                print(f"      '{channel['original_name']}' -> '{channel['clean_name']}'")
    
    all_channels.extend(channels)
    success_sources += 1
    
    # é¿å…è¯·æ±‚è¿‡å¿«
    if idx < len(sources):
        time.sleep(1)

print(f"\n{'='*50}")
print(f"âœ… é‡‡é›†å®Œæˆç»Ÿè®¡:")
print(f"   æˆåŠŸæºæ•°: {success_sources}/{len(sources)}")
print(f"   å¤±è´¥æºæ•°: {len(failed_sources)}")
print(f"   æ€»è®¡é‡‡é›†: {len(all_channels)} ä¸ªåŸå§‹é¢‘é“")

if len(failed_sources) > 0:
    print(f"\nâš ï¸  å¤±è´¥çš„æº:")
    for failed in failed_sources:
        print(f"   - {failed}")

if len(all_channels) == 0:
    print("\nâŒ æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•é¢‘é“ï¼Œé€€å‡º")
    sys.exit(1)

# 3. æå–æ‰€æœ‰å”¯ä¸€çš„URLè¿›è¡Œé€Ÿåº¦æµ‹è¯•
print("\nğŸ“Š æå–æ‰€æœ‰å”¯ä¸€URL...")
all_urls = set()
for channel in all_channels:
    all_urls.add(channel['url'])

print(f"   å‘ç° {len(all_urls)} ä¸ªå”¯ä¸€URL")

# 4. è¿›è¡Œé€Ÿåº¦æµ‹è¯•
print("\nâš¡ å¼€å§‹é€Ÿåº¦æµ‹è¯•ï¼ˆè¿‡æ»¤é»‘åå•ä¸­çš„URLï¼‰...")
speed_test_results, slow_urls = test_urls_with_progress(all_urls, blacklist)

# 5. ä¿å­˜æ–°çš„æ…¢é€ŸURLåˆ°é»‘åå•
if slow_urls:
    print(f"\nğŸ“ å‘ç° {len(slow_urls)} ä¸ªæ…¢é€Ÿæºï¼Œä¿å­˜åˆ°é»‘åå•...")
    save_to_blacklist(slow_urls)
else:
    print("\nâœ… æ²¡æœ‰å‘ç°æ–°çš„æ…¢é€Ÿæº")

# 6. è¿‡æ»¤æ‰é»‘åå•ä¸­çš„é¢‘é“ï¼ˆåŒ…æ‹¬ä¹‹å‰é»‘åå•å’Œæœ¬æ¬¡å‘ç°çš„æ…¢é€Ÿæºï¼‰
print("\nğŸš« è¿‡æ»¤é»‘åå•ä¸­çš„é¢‘é“...")
filtered_channels = []
blacklisted_count = 0

for channel in all_channels:
    if channel['url'] in blacklist or channel['url'] in slow_urls:
        blacklisted_count += 1
    else:
        filtered_channels.append(channel)

print(f"   åŸå§‹é¢‘é“æ•°: {len(all_channels)}")
print(f"   è¿‡æ»¤åé¢‘é“æ•°: {len(filtered_channels)}")
print(f"   é»‘åå•è¿‡æ»¤æ•°: {blacklisted_count}")

if len(filtered_channels) == 0:
    print("\nâŒ æ‰€æœ‰é¢‘é“éƒ½è¢«é»‘åå•è¿‡æ»¤ï¼Œé€€å‡º")
    sys.exit(1)

# 7. åˆå¹¶åŒåç”µè§†å°
print("\nğŸ”„ æ­£åœ¨åˆå¹¶åŒåç”µè§†å°...")
merged_channels = merge_channels(filtered_channels, speed_test_results)
print(f"   åˆå¹¶å: {len(merged_channels)} ä¸ªå”¯ä¸€ç”µè§†å°")

# 8. æ˜¾ç¤ºå¤šæºç»Ÿè®¡å’ŒIPv6ç»Ÿè®¡
multi_source_count = sum(1 for c in merged_channels.values() if len(c['sources']) > 1)
single_source_count = len(merged_channels) - multi_source_count
ipv6_channel_count = sum(1 for c in merged_channels.values() if any(s.get('is_ipv6', False) for s in c['sources']))
fast_channel_count = sum(1 for c in merged_channels.values() if any(s.get('speed') and s['speed'] <= 2.0 for s in c['sources']))

print(f"   å¤šæºç”µè§†å°: {multi_source_count} ä¸ª")
print(f"   å•æºç”µè§†å°: {single_source_count} ä¸ª")
print(f"   å«IPv6æºç”µè§†å°: {ipv6_channel_count} ä¸ª")
print(f"   å«å¿«é€Ÿæºç”µè§†å°: {fast_channel_count} ä¸ª")

# æ˜¾ç¤ºä¸€äº›å¤šæºç¤ºä¾‹
print("\nğŸ“ IPv6å¤šæºç”µè§†å°ç¤ºä¾‹:")
ipv6_multi_examples = [(k, v) for k, v in merged_channels.items() 
                      if any(s.get('is_ipv6', False) for s in v['sources'])][:5]
for clean_name, data in ipv6_multi_examples:
    source_count = len(data['sources'])
    ipv6_count = sum(1 for s in data['sources'] if s.get('is_ipv6', False))
    fast_count = sum(1 for s in data['sources'] if s.get('speed') and s['speed'] <= 2.0)
    qualities = [s['quality'] for s in data['sources']]
    quality_desc = "/".join(set(qualities))
    print(f"   {clean_name}: {ipv6_count}IPv6+{source_count-ipv6_count}IPv4 [{quality_desc}] å¿«é€Ÿæº:{fast_count}")

# 9. ç»Ÿè®¡åˆ†ç±»æ•°é‡
category_stats = {}
for channel in merged_channels.values():
    category = channel['category']
    if category in category_stats:
        category_stats[category] += 1
    else:
        category_stats[category] = 1

print("\nğŸ“Š åˆ†ç±»ç»Ÿè®¡:")
for category, count in sorted(category_stats.items()):
    print(f"   {category}: {count} ä¸ªç”µè§†å°")

# 10. ç”Ÿæˆæ–‡ä»¶ - ä½¿ç”¨åŒ—äº¬æ—¶é—´
timestamp = get_beijing_time()
print(f"\nğŸ“… å½“å‰åŒ—äº¬æ—¶é—´: {timestamp}")

# 11. æŒ‰åˆ†ç±»ç»„ç»‡é¢‘é“
categories = {}
for channel in merged_channels.values():
    category = channel['category']
    if category not in categories:
        categories[category] = []
    categories[category].append(channel)

# ç¡®å®šåˆ†ç±»é¡ºåºï¼ˆå›ºå®šåˆ†ç±»åœ¨å‰ï¼Œçœä»½åˆ†ç±»åœ¨åï¼ŒæŒ‰æ‹¼éŸ³æ’åºï¼‰
fixed_categories = ["å¤®è§†", "å«è§†", "æ™¯åŒºé¢‘é“", "å°‘å„¿å°", "ç»¼è‰ºå°", 
                   "æ¸¯æ¾³å°", "ä½“è‚²å°", "å½±è§†å°", "å…¶ä»–å°"]

# åˆ†ç¦»çœä»½åˆ†ç±»
province_categories = []
other_categories = []
for category in categories.keys():
    if category in fixed_categories:
        continue
    elif category in PROVINCES or any(province in category for province in PROVINCES):
        province_categories.append(category)
    else:
        other_categories.append(category)

# æŒ‰æ‹¼éŸ³æ’åºçœä»½åˆ†ç±»
province_categories.sort()

# æœ€ç»ˆåˆ†ç±»é¡ºåº
final_category_order = fixed_categories + province_categories + other_categories

# ç¡®ä¿æ¯ä¸ªåˆ†ç±»éƒ½å­˜åœ¨ï¼ˆå³ä½¿ä¸ºç©ºï¼‰
for category in final_category_order:
    if category not in categories:
        categories[category] = []

# åˆ›å»ºè¾“å‡ºç›®å½•
Path("categories").mkdir(exist_ok=True)
Path("merged").mkdir(exist_ok=True)

print("\nğŸ¯ æ’­æ”¾å™¨å¤šæºæ”¯æŒä¿¡æ¯:")
for player, info in PLAYER_SUPPORT.items():
    if info['multi_source']:
        print(f"   âœ… {player}: {info['note']}")

# 12. ç”Ÿæˆå¤šæºåˆå¹¶ç‰ˆM3Uï¼ˆPotPlayer/VLCæ ¼å¼ï¼‰
print("\nğŸ“„ ç”Ÿæˆ live_sources.m3uï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ - PotPlayer/VLCæ ¼å¼ï¼‰...")
generate_multi_source_m3u(
    merged_channels, categories, final_category_order, 
    timestamp, "live_sources.m3u", mode="multi"
)

# 13. ç”Ÿæˆå¤šæºåˆ†ç¦»ç‰ˆM3Uï¼ˆTiviMate/Kodiæ ¼å¼ï¼‰
print("\nğŸ“„ ç”Ÿæˆ merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3uï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆ†ç¦»ç‰ˆ - TiviMate/Kodiæ ¼å¼ï¼‰...")
generate_multi_source_m3u(
    merged_channels, categories, final_category_order,
    timestamp, "merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3u", mode="separate"
)

# 14. ç”Ÿæˆç²¾ç®€ç‰ˆM3Uï¼ˆæ¯ä¸ªç”µè§†å°åªä¿ç•™æœ€ä½³æºï¼‰
print("\nğŸ“„ ç”Ÿæˆ merged/ç²¾ç®€ç‰ˆ.m3uï¼ˆIPv6ä¼˜å…ˆå•æºç²¾ç®€ç‰ˆï¼‰...")
generate_multi_source_m3u(
    merged_channels, categories, final_category_order,
    timestamp, "merged/ç²¾ç®€ç‰ˆ.m3u", mode="single"
)

# 15. ç”Ÿæˆåˆ†ç±»M3Uæ–‡ä»¶ï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶æ ¼å¼ï¼‰
print("\nğŸ“„ ç”Ÿæˆåˆ†ç±»æ–‡ä»¶ï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶æ ¼å¼ï¼‰...")
for category in final_category_order:
    cat_channels = categories[category]
    if cat_channels:
        try:
            # å¯¹é¢‘é“è¿›è¡Œæ’åº
            sorted_channels = sorted(
                cat_channels,
                key=lambda x: get_channel_sort_key(x['clean_name'], category)
            )
            
            # åˆ›å»ºå®‰å…¨çš„æ–‡ä»¶å
            safe_category_name = category.replace('/', '_').replace('\\', '_')
            filename = f"categories/{safe_category_name}.m3u"
            
            with open(filename, "w", encoding="utf-8") as f:
                f.write("#EXTM3U\n")
                f.write(f"# {category}é¢‘é“åˆ—è¡¨ï¼ˆIPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆï¼Œå¸¦é»‘åå•è¿‡æ»¤ï¼‰\n")
                f.write(f"# æ›´æ–°æ—¶é—´(åŒ—äº¬æ—¶é—´): {timestamp}\n")
                f.write(f"# ç”µè§†å°æ•°é‡: {len(cat_channels)}\n")
                f.write(f"# è¯´æ˜: æ¯ä¸ªç”µè§†å°åŒ…å«å¤šä¸ªæºï¼ŒIPv6æºä¼˜å…ˆï¼ŒPotPlayeræŒ‰Alt+Wåˆ‡æ¢\n")
                f.write(f"# å·²è¿‡æ»¤é»‘åå•æ…¢é€Ÿæºï¼ˆå“åº”æ—¶é—´ > {SPEED_TEST_TIMEOUT}ç§’ï¼‰\n\n")
                
                for channel in sorted_channels:
                    # é€‰æ‹©ä¸»logoï¼ˆç¬¬ä¸€ä¸ªéç©ºçš„logoï¼‰
                    main_logo = channel['logos'][0] if channel['logos'] else ""
                    source_count = len(channel['sources'])
                    
                    # ç»Ÿè®¡IPv6æºæ•°é‡
                    ipv6_count = sum(1 for s in channel['sources'] if s.get('is_ipv6', False))
                    
                    # PotPlayer/VLCå¤šæºæ ¼å¼
                    source_desc = []
                    if ipv6_count > 0:
                        source_desc.append(f"{ipv6_count}IPv6")
                    if source_count > ipv6_count:
                        source_desc.append(f"{source_count-ipv6_count}IPv4")
                    
                    if source_desc:
                        display_name = f"{channel['clean_name']} [{'+'.join(source_desc)}]"
                    else:
                        display_name = f"{channel['clean_name']} [{source_count}æº]"
                    
                    # æ”¶é›†æ‰€æœ‰URLï¼ˆIPv6ä¼˜å…ˆï¼‰
                    urls = []
                    qualities = []
                    ipv6_sources = []
                    ipv4_sources = []
                    
                    for source in channel['sources']:
                        if source.get('is_ipv6', False):
                            ipv6_sources.append(source)
                        else:
                            ipv4_sources.append(source)
                    
                    # ç¡®ä¿IPv6æºåœ¨å‰é¢
                    sorted_sources = ipv6_sources + ipv4_sources
                    
                    for source in sorted_sources:
                        urls.append(source['url'])
                        if source['quality'] != "æœªçŸ¥":
                            qualities.append(source['quality'])
                    
                    # ç”Ÿæˆå¤šæºURL
                    multi_url = "|".join(urls)
                    
                    # å†™å…¥æ¡ç›®
                    line = "#EXTINF:-1"
                    line += f' tvg-name="{channel["clean_name"]}"'
                    line += f' group-title="{category}"'
                    if main_logo:
                        line += f' tvg-logo="{main_logo}"'
                    if qualities:
                        quality_desc = "/".join(sorted(set(qualities), key=lambda x: ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"].index(x) if x in ["4K","é«˜æ¸…","æ ‡æ¸…","æµç•…","æœªçŸ¥"] else 10))
                        line += f' tvg-quality="{quality_desc}"'
                    if ipv6_count > 0:
                        line += f' tvg-ipv6="true"'
                    line += f',{display_name}\n'
                    line += f"{multi_url}\n"
                    f.write(line)
            
            print(f"  âœ… ç”Ÿæˆ {filename}")
        except Exception as e:
            print(f"  âŒ ç”Ÿæˆ {filename} å¤±è´¥: {e}")

# 16. ç”Ÿæˆåˆå¹¶çš„JSONæ–‡ä»¶ï¼ˆåŒ…å«æ‰€æœ‰æºä¿¡æ¯ï¼‰
print("\nğŸ“„ ç”Ÿæˆ channels.json...")
try:
    # åˆ›å»ºé¢‘é“åˆ—è¡¨
    channel_list = []
    for clean_name, channel_data in sorted(merged_channels.items()):
        # å‡†å¤‡æºä¿¡æ¯
        sources_info = []
        for i, source in enumerate(channel_data['sources'], 1):
            sources_info.append({
                'index': i,
                'url': source['url'],
                'quality': source['quality'],
                'source': source['source'],
                'logo': source['logo'] if source['logo'] else "",
                'is_ipv6': source.get('is_ipv6', False),
                'priority': source.get('priority', 0),
                'speed': source.get('speed')
            })
        
        # ç»Ÿè®¡IPv6æºæ•°é‡
        ipv6_count = sum(1 for s in sources_info if s.get('is_ipv6', False))
        
        # ç»Ÿè®¡å¿«é€Ÿæºæ•°é‡
        fast_count = sum(1 for s in sources_info if s.get('speed') and s['speed'] <= 2.0)
        
        # é¢‘é“ä¿¡æ¯
        channel_info = {
            'clean_name': clean_name,
            'original_names': list(set(channel_data['original_names'])),  # å»é‡
            'category': channel_data['category'],
            'source_count': len(channel_data['sources']),
            'ipv6_source_count': ipv6_count,
            'fast_source_count': fast_count,
            'logos': channel_data['logos'],
            'sources': sources_info
        }
        channel_list.append(channel_info)
    
    # é»‘åå•ç»Ÿè®¡
    blacklist_stats = {
        'total_blacklisted': len(blacklist) + len(slow_urls),
        'previously_blacklisted': len(blacklist),
        'newly_blacklisted': len(slow_urls)
    }
    
    # åˆ›å»ºJSONæ•°æ®
    json_data = {
        'last_updated': timestamp,
        'total_channels': len(merged_channels),
        'original_channel_count': len(all_channels),
        'filtered_channel_count': len(filtered_channels),
        'blacklisted_channel_count': blacklisted_count,
        'sources_count': len(sources),
        'success_sources': success_sources,
        'failed_sources': failed_sources,
        'multi_source_channels': multi_source_count,
        'single_source_channels': single_source_count,
        'ipv6_channels': ipv6_channel_count,
        'fast_channels': fast_channel_count,
        'blacklist_stats': blacklist_stats,
        'speed_test_timeout': SPEED_TEST_TIMEOUT,
        'category_stats': category_stats,
        'sorting_rules': {
            'ipv6_priority': 100,
            '4k_priority': 40,
            'hd_priority': 30,
            'sd_priority': 20,
            'fluent_priority': 10
        },
        'channels': channel_list,
        'player_support': PLAYER_SUPPORT,
        'source_file': 'sources.txt',
        'blacklist_file': BLACKLIST_FILE
    }
    
    # å†™å…¥æ–‡ä»¶
    with open("channels.json", "w", encoding="utf-8") as f:
        json.dump(json_data, f, ensure_ascii=False, indent=2, default=str)
    
    print(f"  âœ… channels.json ç”ŸæˆæˆåŠŸï¼ŒåŒ…å« {len(merged_channels)} ä¸ªç”µè§†å°çš„è¯¦ç»†ä¿¡æ¯")
except Exception as e:
    print(f"  âŒ ç”Ÿæˆchannels.jsonå¤±è´¥: {e}")

print(f"\nğŸ‰ æ‰€æœ‰æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
print(f"ğŸ“Š ç»Ÿè®¡:")
print(f"  - ç”µè§†å°æ€»æ•°: {len(merged_channels)}")
print(f"  - å¤šæºç”µè§†å°: {multi_source_count}")
print(f"  - å•æºç”µè§†å°: {single_source_count}")
print(f"  - å«IPv6æºç”µè§†å°: {ipv6_channel_count}")
print(f"  - å«å¿«é€Ÿæºç”µè§†å°: {fast_channel_count}")
print(f"  - åŸå§‹é¢‘é“æ•°: {len(all_channels)}")
print(f"  - è¿‡æ»¤åé¢‘é“æ•°: {len(filtered_channels)}")
print(f"  - é»‘åå•è¿‡æ»¤æ•°: {blacklisted_count}")
print(f"  - æ•°æ®æº: {len(sources)}")
print(f"  - é»‘åå•æ¡ç›®: {len(blacklist) + len(slow_urls)}")
print(f"ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
print(f"  - live_sources.m3u (IPv6ä¼˜å…ˆå¤šæºåˆå¹¶ç‰ˆ - PotPlayer/VLCæ ¼å¼)")
print(f"  - merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3u (IPv6ä¼˜å…ˆå¤šæºåˆ†ç¦»ç‰ˆ - TiviMate/Kodiæ ¼å¼)")
print(f"  - merged/ç²¾ç®€ç‰ˆ.m3u (IPv6ä¼˜å…ˆå•æºç²¾ç®€ç‰ˆ)")
print(f"  - channels.json (è¯¦ç»†æ•°æ®)")
print(f"  - categories/*.m3u (åˆ†ç±»åˆ—è¡¨)")
print(f"  - {BLACKLIST_FILE} (æ…¢é€Ÿæºé»‘åå•)")
print(f"\nğŸ® æ’­æ”¾å™¨ä½¿ç”¨è¯´æ˜:")
print(f"  1. PotPlayer/VLC: ä½¿ç”¨ live_sources.m3uï¼Œæ’­æ”¾æ—¶æŒ‰Alt+Wåˆ‡æ¢æº")
print(f"  2. TiviMate/Kodi: ä½¿ç”¨ merged/å¤šæºåˆ†ç¦»ç‰ˆ.m3uï¼Œè‡ªåŠ¨åˆå¹¶ç›¸åŒåç§°é¢‘é“")
print(f"  3. å…¶ä»–æ’­æ”¾å™¨: ä½¿ç”¨ merged/ç²¾ç®€ç‰ˆ.m3uï¼Œæ¯ä¸ªç”µè§†å°IPv6æºä¼˜å…ˆ")
print(f"\nğŸ”¢ æ’åºä¼˜å…ˆçº§: IPv6æº > 4Kæº > é«˜æ¸…æº > æ ‡æ¸…æº > æµç•…æº")
print(f"âš¡ é€Ÿåº¦è¦æ±‚: å“åº”æ—¶é—´ â‰¤ {SPEED_TEST_TIMEOUT}ç§’ï¼Œæ…¢é€Ÿæºå·²åŠ å…¥é»‘åå•")