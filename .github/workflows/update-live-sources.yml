name: Update Live TV Sources

on:
  schedule:
    # æ¯å¤©UTCæ—¶é—´18:00è¿è¡Œï¼ˆåŒ—äº¬æ—¶é—´å‡Œæ™¨2ç‚¹ï¼‰
    - cron: '0 18 * * *'
  workflow_dispatch:  # æ”¯æŒæ‰‹åŠ¨è§¦å‘
  push:
    branches: [ main ]
    paths: 
      - 'sources.txt'
      - '.github/workflows/update-live-sources.yml'
      - 'scripts/collect_sources.py'

jobs:
  collect-and-organize:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.LIVEIPTV }}
        fetch-depth: 0  # è·å–æ‰€æœ‰å†å²è®°å½•

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests tqdm

    - name: Create scripts directory
      run: |
        mkdir -p scripts

    - name: Create collection script
      run: |
        cat > scripts/collect_sources.py << 'EOF'
#!/usr/bin/env python3
"""
è‡ªåŠ¨é‡‡é›†å¹¶å½’ç±»ç”µè§†ç›´æ’­æº
"""

import requests
import re
import time
from datetime import datetime
from pathlib import Path
from collections import defaultdict
import hashlib
import json
import os
import sys

# è¦é‡‡é›†çš„æºåˆ—è¡¨
SOURCES = [
    "https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv6.m3u",
    "https://raw.githubusercontent.com/chao921125/source/refs/heads/main/iptv/index.m3u"
]

# å¯ä»¥æ·»åŠ æ›´å¤šæº
ADDITIONAL_SOURCES_FILE = "sources.txt"

# åˆ†ç±»è§„åˆ™ï¼ˆæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…é¢‘é“åç§°ï¼‰
CATEGORY_RULES = {
    "å¤®è§†": [
        r"CCTV[-_\s]?\d+", r"CCTV[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+",
        r"å¤®è§†[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+", r"ä¸­å¤®ç”µè§†å°", r"CCTV1", r"CCTV2"
    ],
    "å«è§†": [
        r"å«è§†", r"æ¹–å—å«è§†", r"æµ™æ±Ÿå«è§†", r"æ±Ÿè‹å«è§†", r"ä¸œæ–¹å«è§†",
        r"åŒ—äº¬å«è§†", r"å¤©æ´¥å«è§†", r"å®‰å¾½å«è§†", r"å±±ä¸œå«è§†", r"å¹¿ä¸œå«è§†",
        r"æ·±åœ³å«è§†", r"é»‘é¾™æ±Ÿå«è§†", r"è¾½å®å«è§†", r"æ¹–åŒ—å«è§†", r"æ²³å—å«è§†"
    ],
    "åœ°æ–¹å°": [
        r"åœ°æ–¹", r"éƒ½å¸‚", r"æ°‘ç”Ÿ", r"æ–°é—»", r"å…¬å…±", r"ç”Ÿæ´»",
        r"æ•™è‚²", r"å°‘å„¿", r"ç»¼è‰º", r"ç»æµ", r"æ³•åˆ¶", r"å†œä¸š"
    ],
    "æ¸¯æ¾³å°": [
        r"å‡¤å‡°", r"ç¿¡ç¿ ", r"æ˜ç ", r"TVB", r"ATV", r"æ¾³è§†",
        r"æ¾³é—¨", r"é¦™æ¸¯", r"å°æ¹¾", r"ä¸­å¤©", r"ä¸œæ£®", r"åè§†",
        r"æ°‘è§†", r"ä¸‰ç«‹", r"æ— çº¿"
    ],
    "ä½“è‚²": [
        r"ä½“è‚²", r"NBA", r"è¶³çƒ", r"ç¯®çƒ", r"é«˜å°”å¤«", r"ç½‘çƒ",
        r"ä¹’ç¾½", r"æå‡»", r"èµ›è½¦", r"å¥¥è¿"
    ],
    "ç”µå½±": [
        r"ç”µå½±", r"å½±é™¢", r"å½±è§†é¢‘é“", r"å¥½è±å", r"CHC"
    ],
    "éŸ³ä¹": [
        r"éŸ³ä¹", r"MTV", r"æ¼”å”±ä¼š", r"Kæ­Œ", r"æˆæ›²"
    ],
    "å›½é™…": [
        r"BBC", r"CNN", r"NHK", r"DW", r"æ³•å›½", r"å¾·å›½",
        r"ä¿„ç½—æ–¯", r"éŸ©å›½", r"æ—¥æœ¬", r"ç¾å›½"
    ]
}

class Channel:
    """é¢‘é“ç±»"""
    def __init__(self, name, url, group=None, logo=None):
        self.name = name.strip()
        self.url = url.strip()
        self.group = group
        self.logo = logo
        self.hash = hashlib.md5(f"{self.name}{self.url}".encode()).hexdigest()
    
    def __eq__(self, other):
        return self.hash == other.hash
    
    def __hash__(self):
        return int(self.hash, 16)
    
    def to_m3u_line(self):
        """è½¬æ¢ä¸ºM3Uæ ¼å¼è¡Œ"""
        line = f'#EXTINF:-1'
        if self.group:
            line += f' group-title="{self.group}"'
        if self.logo:
            line += f' tvg-logo="{self.logo}"'
        line += f',{self.name}\n{self.url}\n'
        return line

class SourceCollector:
    """æºæ”¶é›†å™¨"""
    
    def __init__(self):
        self.all_channels = set()
        self.collected_count = 0
        self.processed_count = 0
        
    def fetch_source(self, url):
        """è·å–å•ä¸ªæº"""
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=30)
            response.raise_for_status()
            response.encoding = 'utf-8'
            return response.text
        except Exception as e:
            print(f"âŒ è·å–æºå¤±è´¥ {url}: {e}")
            return None
    
    def parse_m3u(self, content, source_name):
        """è§£æM3Uå†…å®¹"""
        channels = []
        lines = content.split('\n')
        i = 0
        
        while i < len(lines):
            if lines[i].startswith('#EXTINF'):
                # è§£æEXTINFè¡Œ
                extinf = lines[i]
                channel_name = self.extract_channel_name(extinf)
                group = self.extract_group(extinf)
                logo = self.extract_logo(extinf)
                
                # è·å–URL
                if i + 1 < len(lines) and lines[i + 1].strip() and not lines[i + 1].startswith('#'):
                    url = lines[i + 1].strip()
                    if url and self.is_valid_url(url):
                        channel = Channel(channel_name, url, group, logo)
                        channels.append(channel)
                        i += 1
            i += 1
        
        return channels
    
    def extract_channel_name(self, extinf_line):
        """ä»EXTINFè¡Œæå–é¢‘é“åç§°"""
        # åŒ¹é…æ ¼å¼: #EXTINF:-1,Channel Name
        match = re.search(r',([^,\n]+)$', extinf_line)
        if match:
            return match.group(1).strip()
        
        # å°è¯•ä»tvg-nameæå–
        match = re.search(r'tvg-name="([^"]+)"', extinf_line)
        if match:
            return match.group(1).strip()
        
        # æœ€åå°è¯•æå–é¢‘é“å
        match = re.search(r',([^,]+)$', extinf_line)
        if match:
            return match.group(1).strip()
        
        return "æœªçŸ¥é¢‘é“"
    
    def extract_group(self, extinf_line):
        """ä»EXTINFè¡Œæå–åˆ†ç»„"""
        match = re.search(r'group-title="([^"]+)"', extinf_line)
        if match:
            return match.group(1).strip()
        return None
    
    def extract_logo(self, extinf_line):
        """ä»EXTINFè¡Œæå–logo"""
        match = re.search(r'tvg-logo="([^"]+)"', extinf_line)
        if match:
            return match.group(1).strip()
        return None
    
    def is_valid_url(self, url):
        """éªŒè¯URLæ˜¯å¦æœ‰æ•ˆ"""
        if not url or url.startswith('#'):
            return False
            
        patterns = [
            r'^https?://',
            r'^rtmp://',
            r'^rtsp://',
            r'^udp://',
            r'^http-flv://',
            r'^webrtc://'
        ]
        for pattern in patterns:
            if re.match(pattern, url, re.IGNORECASE):
                return True
        return False
    
    def categorize_channel(self, channel_name):
        """æ ¹æ®è§„åˆ™å½’ç±»é¢‘é“"""
        channel_name_lower = channel_name.lower()
        
        for category, patterns in CATEGORY_RULES.items():
            for pattern in patterns:
                if re.search(pattern, channel_name, re.IGNORECASE):
                    return category
        
        # é»˜è®¤åˆ†ç±»
        if any(keyword in channel_name_lower for keyword in ['æµ‹è¯•', 'test']):
            return 'æµ‹è¯•'
        return 'å…¶ä»–'
    
    def collect_all_sources(self):
        """æ”¶é›†æ‰€æœ‰æº"""
        print("ğŸš€ å¼€å§‹é‡‡é›†ç›´æ’­æº...")
        
        # ä»æ–‡ä»¶è¯»å–é¢å¤–æº
        if Path(ADDITIONAL_SOURCES_FILE).exists():
            with open(ADDITIONAL_SOURCES_FILE, 'r', encoding='utf-8') as f:
                additional_sources = [line.strip() for line in f if line.strip() and not line.startswith('#')]
                SOURCES.extend(additional_sources)
        
        all_channels = set()
        
        for idx, source_url in enumerate(SOURCES, 1):
            print(f"\nğŸ“¡ [{idx}/{len(SOURCES)}] æ­£åœ¨å¤„ç†: {source_url}")
            content = self.fetch_source(source_url)
            if content:
                channels = self.parse_m3u(content, source_url)
                new_count = len(channels)
                self.collected_count += new_count
                before_merge = len(all_channels)
                all_channels.update(channels)
                after_merge = len(all_channels)
                added = after_merge - before_merge
                print(f"   âœ… é‡‡é›†åˆ° {new_count} ä¸ªé¢‘é“ï¼Œæ–°å¢ {added} ä¸ª")
            else:
                print(f"   âŒ è·å–å¤±è´¥")
            
            if idx < len(SOURCES):
                time.sleep(1)  # é¿å…è¯·æ±‚è¿‡å¿«
        
        self.all_channels = all_channels
        self.processed_count = len(all_channels)
        print(f"\nğŸ“Š é‡‡é›†å®Œæˆï¼")
        print(f"   å…±é‡‡é›†: {self.collected_count} ä¸ªé¢‘é“")
        print(f"   å»é‡å: {self.processed_count} ä¸ªé¢‘é“")
        
        return len(all_channels) > 0
    
    def generate_output_files(self):
        """ç”Ÿæˆæ‰€æœ‰è¾“å‡ºæ–‡ä»¶"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # æŒ‰åˆ†ç±»ç»„ç»‡é¢‘é“
        categorized = defaultdict(list)
        for channel in self.all_channels:
            category = self.categorize_channel(channel.name)
            # æ›´æ–°åˆ†ç»„ä¿¡æ¯
            channel.group = category
            categorized[category].append(channel)
        
        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        Path('categories').mkdir(exist_ok=True)
        
        # ç”Ÿæˆå®Œæ•´çš„M3Uæ–‡ä»¶
        self.generate_m3u_file(categorized, timestamp)
        
        # ç”Ÿæˆåˆ†ç±»æ–‡ä»¶
        self.generate_category_files(categorized, timestamp)
        
        # ç”ŸæˆJSONæ–‡ä»¶
        self.generate_json_file(categorized, timestamp)
        
        # ç”ŸæˆREADME
        self.generate_readme(categorized, timestamp)
        
        # ç”ŸæˆHTMLé¡µé¢
        self.generate_html_file(categorized, timestamp)
        
        return True
    
    def generate_m3u_file(self, categorized, timestamp):
        """ç”Ÿæˆå®Œæ•´çš„M3Uæ–‡ä»¶"""
        with open('live_sources.m3u', 'w', encoding='utf-8') as f:
            f.write('#EXTM3U x-tvg-url=""\n')
            f.write(f'# Generated by GitHub Actions at {timestamp}\n')
            f.write(f'# Total Channels: {self.processed_count}\n')
            f.write(f'# Sources: {len(SOURCES)}\n\n')
            
            # æŒ‰åˆ†ç±»å†™å…¥
            for category in sorted(categorized.keys()):
                channels = sorted(categorized[category], key=lambda x: x.name)
                f.write(f'\n# åˆ†ç±»: {category} ({len(channels)}ä¸ªé¢‘é“)\n')
                for channel in channels:
                    f.write(channel.to_m3u_line())
    
    def generate_category_files(self, categorized, timestamp):
        """ç”Ÿæˆåˆ†ç±»M3Uæ–‡ä»¶"""
        for category, channels in categorized.items():
            channels = sorted(channels, key=lambda x: x.name)
            with open(f'categories/{category}.m3u', 'w', encoding='utf-8') as f:
                f.write('#EXTM3U\n')
                f.write(f'# åˆ†ç±»: {category} ({len(channels)}ä¸ªé¢‘é“)\n')
                f.write(f'# æ›´æ–°æ—¶é—´: {timestamp}\n\n')
                for channel in channels:
                    f.write(channel.to_m3u_line())
    
    def generate_json_file(self, categorized, timestamp):
        """ç”ŸæˆJSONæ–‡ä»¶"""
        channel_list = []
        for channel in sorted(self.all_channels, key=lambda x: x.name):
            channel_list.append({
                'name': channel.name,
                'url': channel.url,
                'category': channel.group,
                'logo': channel.logo
            })
        
        with open('channels.json', 'w', encoding='utf-8') as f:
            json.dump({
                'last_updated': timestamp,
                'total_channels': self.processed_count,
                'sources_count': len(SOURCES),
                'channels': channel_list
            }, f, ensure_ascii=False, indent=2)
    
    def generate_readme(self, categorized, timestamp):
        """ç”ŸæˆREADMEæ–‡ä»¶"""
        readme_content = f"""# ğŸ“º ç”µè§†ç›´æ’­æºæ”¶é›†é¡¹ç›®

è‡ªåŠ¨æ”¶é›†æ•´ç†çš„ç”µè§†ç›´æ’­æºï¼Œæ¯æ—¥è‡ªåŠ¨æ›´æ–°ã€‚

## ğŸ“Š ç»Ÿè®¡æ•°æ®
- **æœ€åæ›´æ–°**: {timestamp}
- **é¢‘é“æ€»æ•°**: {self.processed_count}
- **æ•°æ®æº**: {len(SOURCES)} ä¸ª

## ğŸ“ æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶å | æè¿° |
|--------|------|
| `live_sources.m3u` | å®Œæ•´çš„ç›´æ’­æºæ–‡ä»¶ï¼ˆæ‰€æœ‰é¢‘é“ï¼‰ |
| `channels.json` | é¢‘é“ä¿¡æ¯JSONæ ¼å¼ |
| `categories/` | æŒ‰åˆ†ç±»åˆ†å¼€çš„M3Uæ–‡ä»¶ç›®å½• |
| `sources.txt` | è‡ªå®šä¹‰æºåˆ—è¡¨ï¼ˆä¸€è¡Œä¸€ä¸ªURLï¼‰ |
| `index.html` | ç½‘é¡µæ’­æ”¾ç•Œé¢ |

## ğŸ“‚ é¢‘é“åˆ†ç±»ç»Ÿè®¡

| åˆ†ç±» | é¢‘é“æ•°é‡ |
|------|----------|
"""

        for category in sorted(categorized.keys()):
            count = len(categorized[category])
            readme_content += f"| {category} | {count} |\n"

        readme_content += f"""
| **æ€»è®¡** | **{self.processed_count}** |

## ğŸ“¡ æ•°æ®æºåˆ—è¡¨

"""

        for i, source in enumerate(SOURCES, 1):
            readme_content += f"{i}. {source}\n"

        readme_content += """

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹æ³•1ï¼šç›´æ¥æ’­æ”¾
1. ä¸‹è½½ `live_sources.m3u` æ–‡ä»¶
2. ç”¨æ’­æ”¾å™¨æ‰“å¼€ï¼ˆæ”¯æŒVLCã€PotPlayerã€IINAã€nPlayerç­‰ï¼‰

### æ–¹æ³•2ï¼šæŒ‰åˆ†ç±»ä½¿ç”¨
1. è¿›å…¥ `categories/` ç›®å½•
2. ä¸‹è½½éœ€è¦çš„åˆ†ç±»æ–‡ä»¶ï¼ˆå¦‚ `å¤®è§†.m3u`ï¼‰
3. ç”¨æ’­æ”¾å™¨æ‰“å¼€

### æ–¹æ³•3ï¼šåœ¨çº¿æŸ¥çœ‹
è®¿é—® [index.html](index.html) å¯ä»¥åœ¨çº¿æŸ¥çœ‹é¢‘é“åˆ—è¡¨

## ğŸ”§ è‡ªå®šä¹‰é…ç½®

### æ·»åŠ æ›´å¤šæº
ç¼–è¾‘ `sources.txt` æ–‡ä»¶ï¼Œæ¯è¡Œæ·»åŠ ä¸€ä¸ªM3UæºURLï¼š

\`\`\`
# ç¤ºä¾‹
https://example.com/live.m3u
https://github.com/user/repo/raw/main/live.m3u
\`\`\`

## âš™ï¸ è‡ªåŠ¨æ›´æ–°

æœ¬é¡¹ç›®ä½¿ç”¨ GitHub Actions è‡ªåŠ¨æ›´æ–°ï¼š
- **å®šæ—¶æ›´æ–°**: æ¯å¤© UTC æ—¶é—´ 18:00ï¼ˆåŒ—äº¬æ—¶é—´å‡Œæ™¨2ç‚¹ï¼‰
- **æ‰‹åŠ¨è§¦å‘**: åœ¨ GitHub Actions é¡µé¢ç‚¹å‡» "Run workflow"
- **æ–‡ä»¶è§¦å‘**: ä¿®æ”¹ `sources.txt` åè‡ªåŠ¨è§¦å‘

## âš ï¸ å…è´£å£°æ˜

æœ¬é¡¹ç›®æ”¶é›†çš„ç›´æ’­æºæ¥è‡ªå…¬å¼€ç½‘ç»œï¼Œä»…ä¾›å­¦ä¹ å’Œæµ‹è¯•ä½¿ç”¨ã€‚
"""

        with open('README.md', 'w', encoding='utf-8') as f:
            f.write(readme_content)
    
    def generate_html_file(self, categorized, timestamp):
        """ç”ŸæˆHTMLé¡µé¢"""
        html = f'''<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ç”µè§†ç›´æ’­æºæ’­æ”¾åˆ—è¡¨</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 10px; margin-bottom: 30px; }}
        h1 {{ margin: 0; }}
        .stats {{ display: flex; gap: 20px; margin: 20px 0; flex-wrap: wrap; }}
        .stat {{ background: white; color: #333; padding: 15px; border-radius: 8px; flex: 1; min-width: 200px; }}
        .category {{ margin: 25px 0; padding: 20px; background: #f8f9fa; border-radius: 10px; border-left: 5px solid #667eea; }}
        .channels {{ display: grid; grid-template-columns: repeat(auto-fill, minmax(300px, 1fr)); gap: 10px; margin-top: 15px; }}
        .channel {{ padding: 10px; background: white; border-radius: 5px; border: 1px solid #ddd; }}
        .btn {{ display: inline-block; background: #667eea; color: white; padding: 10px 15px; text-decoration: none; border-radius: 5px; margin: 5px; }}
        .btn:hover {{ background: #5a67d8; }}
        footer {{ margin-top: 40px; padding-top: 20px; border-top: 1px solid #ddd; text-align: center; color: #666; }}
        @media (max-width: 768px) {{
            .stats {{ flex-direction: column; }}
            .channels {{ grid-template-columns: 1fr; }}
        }}
    </style>
</head>
<body>
    <header>
        <h1>ğŸ“º ç”µè§†ç›´æ’­æºæ’­æ”¾åˆ—è¡¨</h1>
        <p>è‡ªåŠ¨æ”¶é›†æ•´ç†çš„ç”µè§†ç›´æ’­æºï¼Œæ”¯æŒå¤šç§æ’­æ”¾å™¨</p>
    </header>
    
    <div class="stats">
        <div class="stat">
            <h3>æœ€åæ›´æ–°</h3>
            <p>{timestamp}</p>
        </div>
        <div class="stat">
            <h3>é¢‘é“æ€»æ•°</h3>
            <p>{self.processed_count} ä¸ª</p>
        </div>
        <div class="stat">
            <h3>æ•°æ®æº</h3>
            <p>{len(SOURCES)} ä¸ª</p>
        </div>
    </div>
    
    <div>
        <h2>ğŸ“¥ ä¸‹è½½æ’­æ”¾åˆ—è¡¨</h2>
        <a href="live_sources.m3u" class="btn">å®Œæ•´åˆ—è¡¨ (æ‰€æœ‰é¢‘é“)</a>
        <a href="channels.json" class="btn">JSON æ ¼å¼æ•°æ®</a>
'''

        for category in sorted(categorized.keys()):
            if len(categorized[category]) > 0:
                html += f'        <a href="categories/{category}.m3u" class="btn">{category} åˆ—è¡¨</a>\n'

        html += '''    </div>
    
    <h2>ğŸ“‚ é¢‘é“åˆ†ç±»</h2>
'''

        for category in sorted(categorized.keys()):
            channels = categorized[category]
            html += f'''    <div class="category">
        <h3>{category} ({len(channels)}ä¸ªé¢‘é“)</h3>
        <div class="channels">
'''

            for channel in sorted(channels[:15], key=lambda x: x.name):
                html += f'''            <div class="channel">
                <strong>{channel.name}</strong><br>
                <button onclick="window.open('{channel.url}', '_blank')" style="margin-top: 5px;">æ’­æ”¾</button>
            </div>
'''

            if len(channels) > 15:
                html += f'''            <div class="channel" style="text-align: center;">
                ... è¿˜æœ‰ {len(channels) - 15} ä¸ªé¢‘é“
            </div>
'''

            html += '''        </div>
    </div>
'''

        html += f'''    
    <footer>
        <p>è‡ªåŠ¨æ›´æ–°äº GitHub Actions | æœ€åæ›´æ–°: {timestamp}</p>
        <p>ä½¿ç”¨ VLCã€PotPlayerã€IINA ç­‰æ’­æ”¾å™¨æ‰“å¼€ M3U æ–‡ä»¶å³å¯æ’­æ”¾</p>
    </footer>
    
    <script>
        function playChannel(url) {{
            window.open(url, '_blank');
        }}
    </script>
</body>
</html>'''

        with open('index.html', 'w', encoding='utf-8') as f:
            f.write(html)

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ç”µè§†ç›´æ’­æºè‡ªåŠ¨é‡‡é›†å·¥å…·")
    print("=" * 60)
    
    collector = SourceCollector()
    
    try:
        has_data = collector.collect_all_sources()
        
        if has_data and collector.processed_count > 0:
            collector.generate_output_files()
            print("\nâœ… æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼")
            print(f"   å®Œæ•´æ–‡ä»¶: live_sources.m3u")
            print(f"   åˆ†ç±»æ–‡ä»¶: categories/*.m3u")
            print(f"   JSONæ•°æ®: channels.json")
            print(f"   ç½‘é¡µç•Œé¢: index.html")
            print(f"   ç»Ÿè®¡ä¿¡æ¯: README.md")
            print(f"\nğŸ‰ é‡‡é›†æˆåŠŸï¼å…±å¤„ç† {collector.processed_count} ä¸ªé¢‘é“")
            
            # è®¾ç½®GitHub Actionsè¾“å‡º
            if 'GITHUB_OUTPUT' in os.environ:
                with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                    print(f'changed=true', file=fh)
                    print(f'channels={collector.processed_count}', file=fh)
            else:
                # æœ¬åœ°è¿è¡Œæ—¶ä¹Ÿè¾“å‡º
                print(f"\nğŸ“ è¾“å‡ºä¿¡æ¯:")
                print(f"changed=true")
                print(f"channels={collector.processed_count}")
        else:
            print("\nâŒ æœªé‡‡é›†åˆ°ä»»ä½•æœ‰æ•ˆé¢‘é“")
            if 'GITHUB_OUTPUT' in os.environ:
                with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                    print(f'changed=false', file=fh)
    
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        if 'GITHUB_OUTPUT' in os.environ:
            with open(os.environ['GITHUB_OUTPUT'], 'a') as fh:
                print(f'changed=false', file=fh)
        sys.exit(1)

if __name__ == "__main__":
    main()
EOF

    - name: Create requirements.txt
      run: |
        cat > scripts/requirements.txt << 'EOF'
requests>=2.31.0
EOF

    - name: Create sources.txt file
      run: |
        cat > sources.txt << 'EOF'
# åœ¨æ­¤æ·»åŠ è‡ªå®šä¹‰ç›´æ’­æºURLï¼ˆä¸€è¡Œä¸€ä¸ªï¼‰
# ç¤ºä¾‹ï¼š
# https://raw.githubusercontent.com/å…¶ä»–æº/ç›´æ’­æº.m3u

https://raw.githubusercontent.com/fanmingming/live/main/tv/m3u/ipv6.m3u
https://raw.githubusercontent.com/chao921125/source/refs/heads/main/iptv/index.m3u
EOF

    - name: Run collection script
      id: collect
      env:
        GITHUB_OUTPUT: ${{ github.action_path }}/outputs.txt
      run: |
        cd scripts
        python collect_sources.py
        # è¯»å–è¾“å‡º
        if [ -f ../live_sources.m3u ]; then
          echo "changed=true" >> $GITHUB_OUTPUT
          echo "CHANGED=true" >> $GITHUB_ENV
        else
          echo "changed=false" >> $GITHUB_OUTPUT
          echo "CHANGED=false" >> $GITHUB_ENV
        fi

    - name: Check generated files
      run: |
        echo "ç”Ÿæˆçš„æ–‡ä»¶åˆ—è¡¨:"
        ls -la *.m3u *.json *.html *.md 2>/dev/null || true
        echo -e "\ncategoriesç›®å½•:"
        ls -la categories/ 2>/dev/null || true

    - name: Commit and push changes
      if: env.CHANGED == 'true'
      run: |
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git config --global user.name "github-actions[bot]"
        git add -A
        git commit -m "ğŸ“º Update live TV sources $(date '+%Y-%m-%d %H:%M:%S')
        
        é¢‘é“æ€»æ•°: $(cat channels.json 2>/dev/null | grep -o '"total_channels":[0-9]*' | cut -d: -f2 || echo 0)
        æ›´æ–°æ—¶é—´: $(date '+%Y-%m-%d %H:%M:%S')" || echo "No changes to commit"
        
        # ä½¿ç”¨PATè¿›è¡Œæ¨é€
        git push https://x-access-token:${{ secrets.LIVEIPTV }}@github.com/${{ github.repository }}.git HEAD:main

    - name: Show success message
      if: env.CHANGED == 'true'
      run: |
        echo "âœ… æˆåŠŸæ›´æ–°ç›´æ’­æºï¼"
        echo "ğŸ“Š æŸ¥çœ‹ç”Ÿæˆçš„ç›´æ’­æº: https://github.com/${{ github.repository }}/blob/main/live_sources.m3u"
        echo "ğŸŒ ç½‘é¡µé¢„è§ˆ: https://${{ github.repository_owner }}.github.io/$(echo ${{ github.repository }} | cut -d/ -f2)/"

    - name: Show failure message
      if: env.CHANGED == 'false'
      run: |
        echo "âŒ æœªé‡‡é›†åˆ°ç›´æ’­æºï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–æºåœ°å€"