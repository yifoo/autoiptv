#!/usr/bin/env python3
"""
é»‘ç™½åå•ç®¡ç†æ¨¡å—
"""

import os
import re
from urllib.parse import urlparse
from datetime import datetime, timezone, timedelta

BLACKLIST_FILE = "blacklist.txt"

def get_beijing_time():
    """è·å–ä¸œå…«åŒºåŒ—äº¬æ—¶é—´"""
    utc_now = datetime.now(timezone.utc)
    beijing_time = utc_now.astimezone(timezone(timedelta(hours=8)))
    return beijing_time.strftime('%Y-%m-%d %H:%M:%S')

def load_whitelist(config):
    """åŠ è½½ç™½åå•ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼šè§„åˆ™ã€å®Œæ•´URLã€é¢‘é“å®šä¹‰"""
    if not config['ENABLE_WHITELIST']:
        print("ğŸ“‹ ç™½åå•åŠŸèƒ½å·²ç¦ç”¨ï¼Œè·³è¿‡åŠ è½½")
        return {'patterns': set(), 'urls': set(), 'channels': []}
    
    whitelist_file = config['WHITELIST_FILE']
    whitelist_data = {
        'patterns': set(),  # è§„åˆ™æ¨¡å¼
        'urls': set(),      # å®Œæ•´URL
        'channels': []      # å®Œæ•´é¢‘é“å®šä¹‰
    }
    
    if not os.path.exists(whitelist_file):
        print(f"ğŸ“ {whitelist_file} æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºç©ºç™½åå•")
        # åˆ›å»ºç©ºç™½çš„ç™½åå•æ–‡ä»¶
        try:
            with open(whitelist_file, "w", encoding="utf-8") as f:
                f.write("# ç›´æ’­æºç™½åå•\n")
                f.write("# è¯¥æ–‡ä»¶åŒ…å«æ°¸ä¸åˆ é™¤çš„ç›´æ’­æº\n")
                f.write("# æ”¯æŒæ ¼å¼:\n")
                f.write("# 1. è§„åˆ™åŒ¹é…: *example.com* (åŒ¹é…æ‰€æœ‰åŒ…å«example.comçš„URL)\n")
                f.write("# 2. å®Œæ•´URL: https://example.com/live.m3u8\n")
                f.write("# 3. é¢‘é“å®šä¹‰: url=https://example.com/live.m3u8, name=é¢‘é“åç§°, group=åˆ†ç»„, logo=logo.png\n")
                f.write("# 4. æ­£åˆ™è¡¨è¾¾å¼: /.*cctv.*\\.m3u8/\n")
                f.write("# ç”Ÿæˆæ—¶é—´: " + get_beijing_time() + "\n")
                f.write("# é…ç½®æ–‡ä»¶: config.txt\n\n")
                f.write("# ç¤ºä¾‹:\n")
                f.write("# *cctv.com*\n")
                f.write("# https://example.com/important-stream.m3u8\n")
                f.write("# url=https://example.com/live.m3u8, name=æµ‹è¯•é¢‘é“, group=æµ‹è¯•åˆ†ç»„, logo=http://example.com/logo.png\n")
                f.write("# /.*4k.*\\.m3u8/\n")
                f.write("\n")
            print(f"âœ… å·²åˆ›å»ºç©ºç™½ç™½åå•æ–‡ä»¶ {whitelist_file}")
        except Exception as e:
            print(f"âŒ åˆ›å»ºç™½åå•æ–‡ä»¶å¤±è´¥: {e}")
        return whitelist_data
    
    try:
        with open(whitelist_file, "r", encoding="utf-8") as f:
            for line_num, line in enumerate(f, 1):
                line = line.strip()
                if not line or line.startswith("#"):
                    continue
                
                # å¤„ç†é¢‘é“å®šä¹‰æ ¼å¼ï¼šurl=..., name=..., group=..., logo=...
                if line.startswith("url="):
                    try:
                        # è§£æé¢‘é“å®šä¹‰
                        params = {}
                        for part in line.split(','):
                            part = part.strip()
                            if '=' in part:
                                key, value = part.split('=', 1)
                                params[key.strip()] = value.strip()
                        
                        if 'url' in params:
                            url = params['url']
                            name = params.get('name', 'ç™½åå•é¢‘é“')
                            group = params.get('group', 'ç™½åå•')
                            logo = params.get('logo', '')
                            quality = params.get('quality', 'æœªçŸ¥')
                            
                            channel_info = {
                                'url': url,
                                'name': name,
                                'group': group,
                                'logo': logo,
                                'quality': quality,
                                'is_whitelist': True
                            }
                            whitelist_data['channels'].append(channel_info)
                            whitelist_data['urls'].add(url)
                            print(f"   âœ… åŠ è½½ç™½åå•é¢‘é“: {name} - {url[:50]}...")
                    except Exception as e:
                        print(f"âš ï¸  ç™½åå•ç¬¬{line_num}è¡Œè§£æå¤±è´¥: {line} - {e}")
                
                # å¤„ç†å®Œæ•´URL
                elif line.startswith("http://") or line.startswith("https://"):
                    whitelist_data['urls'].add(line)
                    # å¦‚æœæ˜¯ç›´æ’­æºURLï¼Œä¹Ÿè‡ªåŠ¨åˆ›å»ºé¢‘é“
                    if any(ext in line.lower() for ext in ['.m3u8', '.m3u', '.ts', '.flv', '.rtmp', '.rtsp']):
                        # ä»URLä¸­æå–é¢‘é“åç§°
                        try:
                            parsed = urlparse(line)
                            hostname = parsed.netloc
                            name = f"ç™½åå•-{hostname}"
                            
                            channel_info = {
                                'url': line,
                                'name': name,
                                'group': 'ç™½åå•',
                                'logo': '',
                                'quality': 'æœªçŸ¥',
                                'is_whitelist': True
                            }
                            whitelist_data['channels'].append(channel_info)
                        except:
                            pass
                
                # å¤„ç†æ­£åˆ™è¡¨è¾¾å¼
                elif line.startswith('/') and line.endswith('/'):
                    whitelist_data['patterns'].add(line)
                
                # å¤„ç†é€šé…ç¬¦è§„åˆ™
                else:
                    whitelist_data['patterns'].add(line)
        
        print(f"âœ… ä» {whitelist_file} åŠ è½½ç™½åå•:")
        print(f"   è§„åˆ™æ•°é‡: {len(whitelist_data['patterns'])} ä¸ª")
        print(f"   URLæ•°é‡: {len(whitelist_data['urls'])} ä¸ª")
        print(f"   é¢‘é“æ•°é‡: {len(whitelist_data['channels'])} ä¸ª")
        
        # æ˜¾ç¤ºç™½åå•å†…å®¹ï¼ˆæœ€å¤šæ˜¾ç¤º10æ¡ï¼‰
        if whitelist_data['patterns'] and len(whitelist_data['patterns']) <= 10:
            print(f"   è§„åˆ™å†…å®¹:")
            for item in sorted(whitelist_data['patterns']):
                print(f"     - {item}")
        
    except Exception as e:
        print(f"âš ï¸  è¯»å–ç™½åå•å¤±è´¥: {e}")
    
    return whitelist_data

def is_in_whitelist(url, whitelist_data, config):
    """æ£€æŸ¥URLæ˜¯å¦åœ¨ç™½åå•ä¸­"""
    if not config['ENABLE_WHITELIST'] or not whitelist_data:
        return False
    
    url_lower = url.lower()
    
    # æ£€æŸ¥å®Œæ•´URLåŒ¹é…
    if url in whitelist_data['urls']:
        return True
    
    # æ£€æŸ¥è§„åˆ™åŒ¹é…
    for pattern in whitelist_data['patterns']:
        pattern_lower = pattern.lower()
        
        # é€šé…ç¬¦åŒ¹é…
        if pattern.startswith('*') and pattern.endswith('*'):
            pattern_clean = pattern[1:-1]
            if pattern_clean in url_lower:
                return True
        
        # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…ï¼ˆä»¥/å¼€å¤´å’Œç»“å°¾ï¼‰
        elif pattern.startswith('/') and pattern.endswith('/'):
            try:
                regex_pattern = pattern[1:-1]
                if re.search(regex_pattern, url_lower):
                    return True
            except re.error:
                continue  # æ­£åˆ™è¡¨è¾¾å¼æœ‰è¯¯ï¼Œè·³è¿‡
        
        # éƒ¨åˆ†åŒ¹é…ï¼ˆåŒ…å«å…³ç³»ï¼‰
        elif pattern_lower in url_lower:
            return True
    
    return False

def load_blacklist(config):
    """åŠ è½½é»‘åå•"""
    if not config['ENABLE_BLACKLIST']:
        return set()
    
    blacklist = set()
    if os.path.exists(BLACKLIST_FILE):
        try:
            with open(BLACKLIST_FILE, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if line and not line.startswith("#"):
                        blacklist.add(line)
            print(f"ğŸ“‹ ä» {BLACKLIST_FILE} åŠ è½½äº† {len(blacklist)} ä¸ªé»‘åå•æ¡ç›®")
        except Exception as e:
            print(f"âš ï¸  è¯»å–é»‘åå•å¤±è´¥: {e}")
    else:
        print(f"ğŸ“ {BLACKLIST_FILE} æ–‡ä»¶ä¸å­˜åœ¨")
    return blacklist

def save_to_blacklist(slow_urls, config, reason="å“åº”æ—¶é—´è¶…è¿‡é˜ˆå€¼"):
    """ä¿å­˜æ…¢é€ŸURLåˆ°é»‘åå•"""
    if not config['ENABLE_BLACKLIST'] or not slow_urls:
        return
    
    # åŠ è½½ç°æœ‰é»‘åå•
    existing_blacklist = load_blacklist(config)
    
    # æ·»åŠ æ–°çš„æ…¢é€ŸURL
    existing_blacklist.update(slow_urls)
    
    try:
        with open(BLACKLIST_FILE, "w", encoding="utf-8") as f:
            f.write("# ç›´æ’­æºé»‘åå•\n")
            f.write("# è¯¥æ–‡ä»¶åŒ…å«æµ‹è¯•å¤±è´¥çš„ç›´æ’­æº\n")
            f.write("# æ¯è¡Œä¸€ä¸ªURLï¼Œä¸‹æ¬¡æ›´æ–°æ—¶ä¼šè·³è¿‡è¿™äº›æº\n")
            f.write("# ç”Ÿæˆæ—¶é—´: " + get_beijing_time() + "\n")
            f.write(f"# è¿‡æ»¤åŸå› : {reason}\n")
            f.write(f"# é…ç½®æ–‡ä»¶: config.txt\n")
            f.write(f"# é»‘åå•åŠŸèƒ½: {'å¯ç”¨' if config['ENABLE_BLACKLIST'] else 'ç¦ç”¨'}\n\n")
            
            # æŒ‰åŸŸååˆ†ç»„æ’åº
            url_groups = {}
            for url in existing_blacklist:
                try:
                    parsed = urlparse(url)
                    domain = parsed.netloc
                    if domain not in url_groups:
                        url_groups[domain] = []
                    url_groups[domain].append(url)
                except:
                    if 'unknown' not in url_groups:
                        url_groups['unknown'] = []
                    url_groups['unknown'].append(url)
            
            # æŒ‰åŸŸåæ’åºå†™å…¥
            for domain in sorted(url_groups.keys()):
                if domain == 'unknown':
                    f.write(f"\n# æœªçŸ¥åŸŸå\n")
                else:
                    f.write(f"\n# åŸŸå: {domain}\n")
                
                for url in sorted(url_groups[domain]):
                    f.write(url + "\n")
        
        print(f"ğŸ“ å·²ä¿å­˜ {len(slow_urls)} ä¸ªæ…¢é€Ÿæºåˆ° {BLACKLIST_FILE}")
    except Exception as e:
        print(f"âŒ ä¿å­˜é»‘åå•å¤±è´¥: {e}")